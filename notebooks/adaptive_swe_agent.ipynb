{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "POGHVkUn7NUL",
        "outputId": "97bb7590-6c8f-496f-aaa3-42bcc3bca6e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "ENVIRONMENT SETUP\n",
            "============================================================\n",
            "✓ GPU Available: NVIDIA A100-SXM4-80GB\n",
            "✓ GPU Memory: 85.2 GB\n",
            "\n",
            "Python version: 3.12.12\n",
            "CUDA available: True\n",
            "CUDA version: 12.6\n"
          ]
        }
      ],
      "source": [
        "# Check GPU availability and setup\n",
        "import torch\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"ENVIRONMENT SETUP\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Check GPU\n",
        "if torch.cuda.is_available():\n",
        "    gpu_name = torch.cuda.get_device_name(0)\n",
        "    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
        "    print(f\"✓ GPU Available: {gpu_name}\")\n",
        "    print(f\"✓ GPU Memory: {gpu_memory:.1f} GB\")\n",
        "else:\n",
        "    print(\"✗ No GPU available - this project requires GPU!\")\n",
        "    print(\"  Go to Runtime > Change runtime type > GPU (T4 or A100)\")\n",
        "\n",
        "# Check Python version\n",
        "print(f\"\\nPython version: {sys.version.split()[0]}\")\n",
        "\n",
        "# Check CUDA\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "print(f\"CUDA version: {torch.version.cuda}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q2UQzg1z7meX",
        "outputId": "4eebc640-b1a1-40cc-c69a-db6d33d80ab4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "✓ PROJECT_DIR = /content/drive/MyDrive/adaptive-swe-agent\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive to save progress (Colab optional)\n",
        "import os\n",
        "import pathlib\n",
        "\n",
        "IN_COLAB = False\n",
        "try:\n",
        "    from google.colab import drive  # type: ignore\n",
        "    IN_COLAB = True\n",
        "except Exception:\n",
        "    IN_COLAB = False\n",
        "\n",
        "if IN_COLAB:\n",
        "    drive.mount('/content/drive', force_remount=True)\n",
        "    DEFAULT_PROJECT_DIR = \"/content/drive/MyDrive/adaptive-swe-agent\"\n",
        "else:\n",
        "    # Local / VS Code / Jupyter\n",
        "    DEFAULT_PROJECT_DIR = os.path.abspath(\"./adaptive-swe-agent\")\n",
        "\n",
        "# Allow overriding from environment\n",
        "PROJECT_DIR = os.environ.get(\"PROJECT_DIR\", DEFAULT_PROJECT_DIR)\n",
        "\n",
        "# Create required directories (used throughout the notebook)\n",
        "for sub in [\"\", \"models\", \"data\", \"results\", \"predictions\", \"evaluation\"]:\n",
        "    p = PROJECT_DIR if sub == \"\" else os.path.join(PROJECT_DIR, sub)\n",
        "    os.makedirs(p, exist_ok=True)\n",
        "\n",
        "print(\"✓ PROJECT_DIR =\", PROJECT_DIR)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "PRED_DIR = os.path.join(PROJECT_DIR, \"predictions\")\n",
        "DATA_DIR = os.path.join(PROJECT_DIR, \"data\")\n",
        "RES_DIR  = os.path.join(PROJECT_DIR, \"results\")\n",
        "EVAL_DIR = os.path.join(PROJECT_DIR, \"evaluation\")\n",
        "\n",
        "os.makedirs(PRED_DIR, exist_ok=True)\n",
        "os.makedirs(DATA_DIR, exist_ok=True)\n",
        "os.makedirs(RES_DIR, exist_ok=True)\n",
        "os.makedirs(EVAL_DIR, exist_ok=True)\n",
        "\n",
        "ADAPTIVE_PRED_10_JSONL = os.path.join(PRED_DIR, \"adaptive_predictions_10.jsonl\")\n",
        "\n",
        "print(\"✓ Paths initialized\")\n",
        "print(\"  ADAPTIVE_PRED_10_JSONL =\", ADAPTIVE_PRED_10_JSONL)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0S-1Q34_7ruv",
        "outputId": "95526768-0b77-424c-d8f9-46c9a9bd00e3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Paths initialized\n",
            "  ADAPTIVE_PRED_10_JSONL = /content/drive/MyDrive/adaptive-swe-agent/predictions/adaptive_predictions_10.jsonl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cjTzIukT8eUk",
        "outputId": "9fd7f954-9c2c-4d51-a3e1-6fe19c171083"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing dependencies (this may take 3-5 minutes)...\n",
            "✓ Core packages installed\n",
            "✓ SWE-bench installed\n",
            "\n",
            "============================================================\n",
            "INSTALLATION COMPLETE\n",
            "============================================================\n",
            "✓ Transformers version: 4.57.3\n",
            "✓ Datasets version: 4.0.0\n",
            "✓ vLLM version: 0.12.0\n",
            "✓ SWE-bench installed (version: 4.1.0)\n",
            "\n",
            "⚠ Note: Dependency warnings above can be safely ignored\n",
            "   (jedi and pydantic version conflicts won't affect our project)\n"
          ]
        }
      ],
      "source": [
        "# Cell 3: Install required packages (FIXED)\n",
        "print(\"Installing dependencies (this may take 3-5 minutes)...\")\n",
        "\n",
        "# Install core packages\n",
        "!pip install -q datasets transformers accelerate bitsandbytes\n",
        "!pip install -q torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu126\n",
        "!pip install -q vllm\n",
        "!pip install -q openai anthropic\n",
        "!pip install -q pandas numpy scikit-learn xgboost\n",
        "!pip install -q sentence-transformers\n",
        "!pip install -q GitPython PyGithub\n",
        "!pip install -q tqdm wandb\n",
        "\n",
        "print(\"✓ Core packages installed\")\n",
        "\n",
        "# Install SWE-bench\n",
        "!pip install -q swebench\n",
        "\n",
        "print(\"✓ SWE-bench installed\")\n",
        "\n",
        "# Verify installations\n",
        "import datasets\n",
        "import transformers\n",
        "import vllm\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"INSTALLATION COMPLETE\")\n",
        "print(\"=\"*60)\n",
        "print(f\"✓ Transformers version: {transformers.__version__}\")\n",
        "print(f\"✓ Datasets version: {datasets.__version__}\")\n",
        "print(f\"✓ vLLM version: {vllm.__version__}\")\n",
        "\n",
        "# Test SWE-bench import (with error handling)\n",
        "try:\n",
        "    from swebench.harness.test_spec import TestSpec\n",
        "    print(f\"✓ SWE-bench imported successfully\")\n",
        "except ImportError:\n",
        "    try:\n",
        "        import swebench\n",
        "        print(f\"✓ SWE-bench installed (version: {swebench.__version__ if hasattr(swebench, '__version__') else 'unknown'})\")\n",
        "    except:\n",
        "        print(\"⚠ SWE-bench installed but import structure may have changed\")\n",
        "\n",
        "print(\"\\n⚠ Note: Dependency warnings above can be safely ignored\")\n",
        "print(\"   (jedi and pydantic version conflicts won't affect our project)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dhK2CcJI82Vl",
        "outputId": "957eedfd-03cb-4794-97f0-ea77d26da5aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading SWE-bench Lite dataset...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Loaded 300 tasks\n",
            "✓ Saved to: /content/drive/MyDrive/adaptive-swe-agent/data/swebench_lite.jsonl\n",
            "\n",
            "============================================================\n",
            "SAMPLE TASK\n",
            "============================================================\n",
            "Instance ID: astropy__astropy-12907\n",
            "Repository: astropy/astropy\n",
            "\n",
            "Problem Statement (first 300 chars):\n",
            "Modeling's `separability_matrix` does not compute separability correctly for nested CompoundModels\n",
            "Consider the following model:\r\n",
            "\r\n",
            "```python\r\n",
            "from astropy.modeling import models as m\r\n",
            "from astropy.modeling.separable import separability_matrix\r\n",
            "\r\n",
            "cm = m.Linear1D(10) & m.Linear1D(5)\r\n",
            "```\r\n",
            "\r\n",
            "It's sepa...\n",
            "\n",
            "Base commit: d16bfe05\n",
            "Test patch lines: 37\n",
            "\n",
            "✓ Created subset of 10 tasks: /content/drive/MyDrive/adaptive-swe-agent/data/swebench_subset_10.jsonl\n"
          ]
        }
      ],
      "source": [
        "# Cell 4: Download SWE-bench Lite dataset (FIXED)\n",
        "from datasets import load_dataset\n",
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "print(\"Downloading SWE-bench Lite dataset...\")\n",
        "\n",
        "# Load dataset (300 curated tasks)\n",
        "dataset = load_dataset(\"princeton-nlp/SWE-bench_Lite\", split=\"test\")\n",
        "\n",
        "print(f\"✓ Loaded {len(dataset)} tasks\")\n",
        "\n",
        "# Save to JSON for easy access\n",
        "data_file = f\"{PROJECT_DIR}/data/swebench_lite.jsonl\"\n",
        "with open(data_file, 'w') as f:\n",
        "    for item in dataset:\n",
        "        # Convert to dict properly\n",
        "        item_dict = {key: item[key] for key in item.keys()}\n",
        "        f.write(json.dumps(item_dict) + '\\n')\n",
        "\n",
        "print(f\"✓ Saved to: {data_file}\")\n",
        "\n",
        "# Inspect first task\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"SAMPLE TASK\")\n",
        "print(\"=\"*60)\n",
        "first_task = dataset[0]\n",
        "print(f\"Instance ID: {first_task['instance_id']}\")\n",
        "print(f\"Repository: {first_task['repo']}\")\n",
        "print(f\"\\nProblem Statement (first 300 chars):\")\n",
        "print(first_task['problem_statement'][:300] + \"...\")\n",
        "print(f\"\\nBase commit: {first_task['base_commit'][:8]}\")\n",
        "print(f\"Test patch lines: {len(first_task['test_patch'].split(chr(10)))}\")\n",
        "\n",
        "# Create a small subset for fast iteration (first 10 tasks)\n",
        "subset_file = f\"{PROJECT_DIR}/data/swebench_subset_10.jsonl\"\n",
        "with open(subset_file, 'w') as f:\n",
        "    for i in range(10):\n",
        "        item = dataset[i]\n",
        "        item_dict = {key: item[key] for key in item.keys()}\n",
        "        f.write(json.dumps(item_dict) + '\\n')\n",
        "\n",
        "print(f\"\\n✓ Created subset of 10 tasks: {subset_file}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cIqoO0MM-nNo",
        "outputId": "77b7f217-4a41-4eee-a11a-103566f1e849"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "GPT-5.1 SETUP\n",
            "============================================================\n",
            "✓ API connected\n",
            "✓ Model: gpt-5.1\n",
            "✓ Test: Hello!\n",
            "✓ Tokens: 19\n"
          ]
        }
      ],
      "source": [
        "# Cell 5: Use GPT-5.1 via OpenAI API\n",
        "!pip install -q openai\n",
        "\n",
        "from openai import OpenAI\n",
        "from google.colab import userdata\n",
        "\n",
        "# Get API key from Colab secrets\n",
        "api_key = userdata.get('OPENAI_API_KEY')\n",
        "client = OpenAI(api_key=api_key)\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"GPT-5.1 SETUP\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Test API\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-5.1\",\n",
        "    messages=[{\"role\": \"user\", \"content\": \"Say hello\"}],\n",
        "    max_completion_tokens=50\n",
        ")\n",
        "\n",
        "print(f\"✓ API connected\")\n",
        "print(f\"✓ Model: gpt-5.1\")\n",
        "print(f\"✓ Test: {response.choices[0].message.content}\")\n",
        "print(f\"✓ Tokens: {response.usage.total_tokens}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T4JzeTkb_IF3",
        "outputId": "a07098e9-0d5d-4254-ad29-67f0f9c469aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Repository manager initialized\n"
          ]
        }
      ],
      "source": [
        "# Cell 6: Repository management (ROBUST)\n",
        "import os\n",
        "import subprocess\n",
        "import shutil\n",
        "import tempfile\n",
        "from git import Repo\n",
        "\n",
        "class RepoManager:\n",
        "    \"\"\"Manage test repositories for SWE-bench\"\"\"\n",
        "\n",
        "    def __init__(self, base_dir=\"/content/repos\"):\n",
        "        self.base_dir = base_dir\n",
        "        os.makedirs(base_dir, exist_ok=True)\n",
        "\n",
        "    def setup_repository(self, repo_name, commit_hash):\n",
        "        \"\"\"Clone and checkout specific commit\"\"\"\n",
        "        repo_path = os.path.join(self.base_dir, repo_name.replace('/', '_'))\n",
        "\n",
        "        # Clean up if exists\n",
        "        if os.path.exists(repo_path):\n",
        "            shutil.rmtree(repo_path)\n",
        "\n",
        "        repo_url = f\"https://github.com/{repo_name}.git\"\n",
        "        try:\n",
        "            print(f\"  Cloning {repo_name} ...\")\n",
        "\n",
        "            # Full clone (safer for commits not in shallow history)\n",
        "            repo = Repo.clone_from(repo_url, repo_path)\n",
        "\n",
        "            # Checkout pinned commit\n",
        "            repo.git.checkout(commit_hash, force=True)\n",
        "\n",
        "            # Ensure clean state\n",
        "            repo.git.reset(\"--hard\")\n",
        "            repo.git.clean(\"-fd\")\n",
        "\n",
        "            print(f\"  ✓ Ready at commit {commit_hash[:8]}\")\n",
        "            return repo_path\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"  ✗ Repo setup error: {type(e).__name__}: {e}\")\n",
        "            return None\n",
        "\n",
        "    def cleanup_repository(self, repo_path):\n",
        "        \"\"\"Remove repository\"\"\"\n",
        "        if repo_path and os.path.exists(repo_path):\n",
        "            shutil.rmtree(repo_path, ignore_errors=True)\n",
        "\n",
        "    def get_git_diff(self, repo_path):\n",
        "        \"\"\"Get current diff as patch\"\"\"\n",
        "        try:\n",
        "            result = subprocess.run(\n",
        "                [\"git\", \"diff\"],\n",
        "                cwd=repo_path,\n",
        "                capture_output=True,\n",
        "                text=True,\n",
        "                timeout=20\n",
        "            )\n",
        "            return result.stdout or \"\"\n",
        "        except Exception:\n",
        "            return \"\"\n",
        "\n",
        "    def git_apply_check(self, repo_path, patch):\n",
        "        \"\"\"Check if a patch applies cleanly (no side effects).\"\"\"\n",
        "        if not patch or not patch.strip():\n",
        "            return False, \"Empty patch\"\n",
        "\n",
        "        patch_file = None\n",
        "        try:\n",
        "            with tempfile.NamedTemporaryFile(mode=\"w\", suffix=\".patch\", delete=False, encoding=\"utf-8\") as f:\n",
        "                f.write(patch if patch.endswith(\"\\n\") else patch + \"\\n\")\n",
        "                patch_file = f.name\n",
        "\n",
        "            res = subprocess.run(\n",
        "                [\"git\", \"apply\", \"--check\", \"--verbose\", \"--recount\", patch_file],\n",
        "                cwd=repo_path,\n",
        "                capture_output=True,\n",
        "                text=True,\n",
        "                timeout=30\n",
        "            )\n",
        "            ok = (res.returncode == 0)\n",
        "            msg = (res.stderr or res.stdout or \"\").strip()\n",
        "            return ok, msg\n",
        "        except subprocess.TimeoutExpired:\n",
        "            return False, \"git apply --check timed out\"\n",
        "        except Exception as e:\n",
        "            return False, f\"{type(e).__name__}: {str(e)[:200]}\"\n",
        "        finally:\n",
        "            if patch_file and os.path.exists(patch_file):\n",
        "                try: os.unlink(patch_file)\n",
        "                except: pass\n",
        "\n",
        "    def apply_patch(self, repo_path, patch):\n",
        "        \"\"\"Apply patch only if it passes --check. Returns (ok, msg).\"\"\"\n",
        "        ok, msg = self.git_apply_check(repo_path, patch)\n",
        "        if not ok:\n",
        "            return False, msg\n",
        "\n",
        "        patch_file = None\n",
        "        try:\n",
        "            with tempfile.NamedTemporaryFile(mode=\"w\", suffix=\".patch\", delete=False, encoding=\"utf-8\") as f:\n",
        "                f.write(patch if patch.endswith(\"\\n\") else patch + \"\\n\")\n",
        "                patch_file = f.name\n",
        "\n",
        "            res = subprocess.run(\n",
        "                [\"git\", \"apply\", patch_file],\n",
        "                cwd=repo_path,\n",
        "                capture_output=True,\n",
        "                text=True,\n",
        "                timeout=30\n",
        "            )\n",
        "            ok = (res.returncode == 0)\n",
        "            msg = (res.stderr or res.stdout or \"\").strip()\n",
        "            return ok, msg\n",
        "        except subprocess.TimeoutExpired:\n",
        "            return False, \"git apply timed out\"\n",
        "        except Exception as e:\n",
        "            return False, f\"{type(e).__name__}: {str(e)[:200]}\"\n",
        "        finally:\n",
        "            if patch_file and os.path.exists(patch_file):\n",
        "                try: os.unlink(patch_file)\n",
        "                except: pass\n",
        "\n",
        "\n",
        "print(\"✓ Repository manager initialized\")\n",
        "repo_mgr = RepoManager()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# Cell 7 (TRUE SINGLE-PASS BASELINE: 1 LLM call, no repairs) — ROBUST v3\n",
        "# - One model call per task\n",
        "# - skips docs/tests/CHANGES\n",
        "# - ALWAYS includes HEAD + keyword windows\n",
        "# - truncates context on LINE boundaries (prevents broken anchors)\n",
        "# - robust patch extraction/normalization\n",
        "# =============================================================================\n",
        "\n",
        "import os\n",
        "import re\n",
        "import subprocess\n",
        "import tempfile\n",
        "from dataclasses import dataclass\n",
        "from typing import Optional, Tuple, List\n",
        "\n",
        "@dataclass\n",
        "class ApplyCheckResult:\n",
        "    ok: bool\n",
        "    stderr: str\n",
        "    stdout: str\n",
        "\n",
        "class SinglePassBaselineAgent:\n",
        "    def __init__(\n",
        "        self,\n",
        "        client,\n",
        "        model: str = \"gpt-5.1\",\n",
        "        strict_single_file: bool = True,\n",
        "        do_apply_check: bool = True,\n",
        "        head_lines: int = 200,\n",
        "        max_context_chars: int = 32000,\n",
        "    ):\n",
        "        self.client = client\n",
        "        self.model = model\n",
        "        self.strict_single_file = strict_single_file\n",
        "        self.do_apply_check = do_apply_check\n",
        "        self.head_lines = head_lines\n",
        "        self.max_context_chars = max_context_chars\n",
        "\n",
        "    def _is_disallowed_target(self, rel_path: str) -> bool:\n",
        "        if not rel_path:\n",
        "            return True\n",
        "        rp = rel_path.replace(\"\\\\\", \"/\").lstrip(\"./\")\n",
        "        if rp == \"CHANGES.rst\":\n",
        "            return True\n",
        "        if rp.startswith(\"docs/\") or rp.startswith(\"doc/\") or \"/docs/\" in rp:\n",
        "            return True\n",
        "        if rp.startswith(\"test/\") or rp.startswith(\"tests/\") or \"/tests/\" in rp:\n",
        "            return True\n",
        "        return False\n",
        "\n",
        "    def solve_issue(self, task: dict, repo_path: str, max_tokens: int = 4096):\n",
        "        try:\n",
        "            problem_statement = task.get(\"problem_statement\") or task.get(\"problem\") or \"\"\n",
        "            if not problem_statement:\n",
        "                return {\"patch\": \"\", \"success\": False, \"tokens_used\": 0, \"target_file\": None, \"apply_stderr\": \"\"}\n",
        "\n",
        "            target_file = self._infer_target_file(problem_statement, repo_path)\n",
        "            if self.strict_single_file and not target_file:\n",
        "                target_file = self._fallback_target_file(problem_statement, repo_path)\n",
        "\n",
        "            file_context = self._build_file_context(problem_statement, repo_path, target_file)\n",
        "\n",
        "            patch, tokens_used = self._generate_patch(\n",
        "                problem_statement=problem_statement,\n",
        "                target_file=target_file,\n",
        "                file_context=file_context,\n",
        "                max_tokens=max_tokens,\n",
        "            )\n",
        "            patch = self._postprocess_patch(patch)\n",
        "\n",
        "            apply_stderr = \"\"\n",
        "            if self.do_apply_check and patch.strip():\n",
        "                res = self._git_apply_check(repo_path, patch, recount=True)\n",
        "                success = res.ok\n",
        "                apply_stderr = (res.stderr or res.stdout or \"\").strip()\n",
        "            else:\n",
        "                success = bool(patch.strip())\n",
        "\n",
        "            return {\n",
        "                \"patch\": patch,\n",
        "                \"success\": success,\n",
        "                \"tokens_used\": tokens_used,\n",
        "                \"target_file\": target_file,\n",
        "                \"apply_stderr\": apply_stderr,\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"  ✗ Error in solve_issue: {type(e).__name__}: {e}\")\n",
        "            return {\"patch\": \"\", \"success\": False, \"tokens_used\": 0, \"target_file\": None, \"apply_stderr\": \"\"}\n",
        "\n",
        "    def _strict_rules_text(self, target_file: Optional[str]) -> str:\n",
        "        if not self.strict_single_file:\n",
        "            return \"\"\n",
        "        if target_file:\n",
        "            return (\n",
        "                \"\\nSTRICT RULES:\\n\"\n",
        "                f\"- You MUST ONLY modify this one file: {target_file}\\n\"\n",
        "                \"- Do NOT modify tests, docs, CHANGES.rst, or any other file.\\n\"\n",
        "                \"- Output a single unified diff for that file.\\n\"\n",
        "            )\n",
        "        return (\n",
        "            \"\\nSTRICT RULES:\\n\"\n",
        "            \"- You MUST NOT modify CHANGES.rst or any docs (*.rst, *.md) or any tests.\\n\"\n",
        "            \"- Only modify the minimum necessary source code file(s).\\n\"\n",
        "            \"- Keep the patch minimal.\\n\"\n",
        "        )\n",
        "\n",
        "    def _generate_patch(\n",
        "        self,\n",
        "        problem_statement: str,\n",
        "        target_file: Optional[str],\n",
        "        file_context: str,\n",
        "        max_tokens: int = 4096,\n",
        "    ) -> Tuple[str, int]:\n",
        "        system = \"You are an expert software engineer. Return ONLY a valid unified diff patch. No markdown, no commentary.\"\n",
        "        strict = self._strict_rules_text(target_file)\n",
        "\n",
        "        user = (\n",
        "            \"Fix the bug described below by editing the repository.\\n\\n\"\n",
        "            f\"PROBLEM:\\n{problem_statement}\\n\\n\"\n",
        "            f\"TARGET FILE (best guess): {target_file}\\n\"\n",
        "            f\"{strict}\\n\"\n",
        "            \"REPO CONTEXT (exact content at pinned commit):\\n\"\n",
        "            f\"{file_context}\\n\\n\"\n",
        "            \"OUTPUT REQUIREMENTS:\\n\"\n",
        "            \"- Output ONLY a unified diff that `git apply` can apply.\\n\"\n",
        "            \"- Include diff headers: diff --git / --- / +++\\n\"\n",
        "            \"- Use correct @@ hunk headers.\\n\"\n",
        "            \"- Do NOT include markdown fences.\\n\"\n",
        "            \"- Reuse exact context lines from the provided file content.\\n\"\n",
        "        )\n",
        "\n",
        "        resp = self.client.chat.completions.create(\n",
        "            model=self.model,\n",
        "            messages=[{\"role\": \"system\", \"content\": system}, {\"role\": \"user\", \"content\": user}],\n",
        "            max_completion_tokens=max_tokens,\n",
        "            temperature=0.2,\n",
        "        )\n",
        "\n",
        "        text = resp.choices[0].message.content or \"\"\n",
        "        usage = getattr(resp, \"usage\", None)\n",
        "        tokens_used = usage.total_tokens if usage else 0\n",
        "        return text, tokens_used\n",
        "\n",
        "    def _infer_target_file(self, problem_statement: str, repo_path: str) -> Optional[str]:\n",
        "        patterns = [\n",
        "            r\"(?:in|file)\\s+`([^`]+?\\.(?:py|js|ts|java|go|rs|c|cpp|h|hpp))`\",\n",
        "            r\"(?:in|file)\\s+([A-Za-z0-9_\\-./]+?\\.(?:py|js|ts|java|go|rs|c|cpp|h|hpp))\",\n",
        "            r\"(`)([A-Za-z0-9_\\-./]+?\\.(?:py|js|ts|java|go|rs|c|cpp|h|hpp))\\1\",\n",
        "        ]\n",
        "\n",
        "        for pat in patterns:\n",
        "            m = re.search(pat, problem_statement)\n",
        "            if m:\n",
        "                cand = m.group(1) if m.lastindex == 1 else m.group(2)\n",
        "                cand = (cand or \"\").strip()\n",
        "                if cand and os.path.exists(os.path.join(repo_path, cand)) and not self._is_disallowed_target(cand):\n",
        "                    return cand\n",
        "\n",
        "        identifiers = re.findall(r\"\\b[A-Za-z_][A-Za-z0-9_]{3,}\\b\", problem_statement)\n",
        "        stop = {\"this\", \"that\", \"when\", \"then\", \"true\", \"false\", \"none\"}\n",
        "        identifiers = [w for w in identifiers if w.lower() not in stop][:10]\n",
        "\n",
        "        best_file, best_hits = None, 0\n",
        "        skip_dir_markers = [\"/.git/\", \"/venv/\", \"/.venv/\", \"/node_modules/\", \"/dist/\", \"/build/\", \"/.tox/\"]\n",
        "\n",
        "        for root, _, files in os.walk(repo_path):\n",
        "            root_norm = root.replace(\"\\\\\", \"/\")\n",
        "            if any(m in root_norm for m in skip_dir_markers):\n",
        "                continue\n",
        "\n",
        "            for fn in files:\n",
        "                if not fn.endswith((\".py\", \".js\", \".ts\", \".java\", \".go\", \".rs\", \".c\", \".cpp\", \".h\", \".hpp\")):\n",
        "                    continue\n",
        "\n",
        "                fp = os.path.join(root, fn)\n",
        "                rel = os.path.relpath(fp, repo_path).replace(\"\\\\\", \"/\")\n",
        "\n",
        "                if self._is_disallowed_target(rel):\n",
        "                    continue\n",
        "\n",
        "                try:\n",
        "                    with open(fp, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
        "                        txt = f.read()\n",
        "                    hits = sum(1 for w in identifiers if w in txt)\n",
        "                    if hits > best_hits:\n",
        "                        best_hits, best_file = hits, rel\n",
        "                except Exception:\n",
        "                    continue\n",
        "\n",
        "        return best_file\n",
        "\n",
        "    def _fallback_target_file(self, problem_statement: str, repo_path: str) -> Optional[str]:\n",
        "        identifiers = re.findall(r\"\\b[A-Za-z_][A-Za-z0-9_]{3,}\\b\", problem_statement)\n",
        "        stop = {\"this\", \"that\", \"when\", \"then\", \"true\", \"false\", \"none\"}\n",
        "        identifiers = [w for w in identifiers if w.lower() not in stop][:12]\n",
        "\n",
        "        best_file, best_hits = None, 0\n",
        "        skip_dir_markers = [\"/.git/\", \"/venv/\", \"/.venv/\", \"/node_modules/\", \"/dist/\", \"/build/\", \"/.tox/\"]\n",
        "\n",
        "        for root, _, files in os.walk(repo_path):\n",
        "            root_norm = root.replace(\"\\\\\", \"/\")\n",
        "            if any(m in root_norm for m in skip_dir_markers):\n",
        "                continue\n",
        "\n",
        "            for fn in files:\n",
        "                if not fn.endswith((\".py\", \".js\", \".ts\", \".java\", \".go\", \".rs\", \".c\", \".cpp\", \".h\", \".hpp\")):\n",
        "                    continue\n",
        "\n",
        "                fp = os.path.join(root, fn)\n",
        "                rel = os.path.relpath(fp, repo_path).replace(\"\\\\\", \"/\")\n",
        "\n",
        "                if self._is_disallowed_target(rel):\n",
        "                    continue\n",
        "\n",
        "                try:\n",
        "                    with open(fp, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
        "                        txt = f.read()\n",
        "                    hits = sum(1 for w in identifiers if w in txt)\n",
        "                    if hits > best_hits:\n",
        "                        best_hits, best_file = hits, rel\n",
        "                except Exception:\n",
        "                    continue\n",
        "\n",
        "        return best_file\n",
        "\n",
        "    def _build_file_context(self, problem_statement: str, repo_path: str, target_file: Optional[str]) -> str:\n",
        "        if not target_file:\n",
        "            return \"No specific target file inferred.\"\n",
        "\n",
        "        abs_path = os.path.join(repo_path, target_file)\n",
        "        if not os.path.exists(abs_path):\n",
        "            return f\"Target file not found on disk: {target_file}\"\n",
        "\n",
        "        with open(abs_path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
        "            lines = f.readlines()\n",
        "\n",
        "        total_lines = len(lines)\n",
        "        head_n = min(self.head_lines, total_lines)\n",
        "\n",
        "        parts: List[str] = []\n",
        "        parts.append(f\"FILE: {target_file}\\n\")\n",
        "        parts.append(f\"----- BEGIN FILE (HEAD LINES 1-{head_n}) -----\\n\")\n",
        "        parts.extend(lines[:head_n])\n",
        "        parts.append(\"----- END FILE (HEAD) -----\\n\\n\")\n",
        "\n",
        "        identifiers = re.findall(r\"\\b[A-Za-z_][A-Za-z0-9_]{3,}\\b\", problem_statement)\n",
        "        stop = {\"this\", \"that\", \"when\", \"then\", \"true\", \"false\", \"none\"}\n",
        "        identifiers = [w for w in identifiers if w.lower() not in stop][:12]\n",
        "\n",
        "        hit_idxs = [i for i, ln in enumerate(lines) if any(w in ln for w in identifiers)][:6]\n",
        "\n",
        "        def clamp(a, lo, hi):\n",
        "            return max(lo, min(hi, a))\n",
        "\n",
        "        chunks: List[Tuple[int, int]] = []\n",
        "        for idx in hit_idxs:\n",
        "            start = clamp(idx - 140, 0, total_lines)\n",
        "            end = clamp(idx + 260, 0, total_lines)\n",
        "            if end <= head_n:\n",
        "                continue\n",
        "            start = max(start, head_n)\n",
        "            chunks.append((start, end))\n",
        "\n",
        "        chunks.sort()\n",
        "        merged = []\n",
        "        for s, e in chunks:\n",
        "            if not merged or s > merged[-1][1]:\n",
        "                merged.append([s, e])\n",
        "            else:\n",
        "                merged[-1][1] = max(merged[-1][1], e)\n",
        "\n",
        "        if merged:\n",
        "            for s, e in merged:\n",
        "                parts.append(f\"----- LINES {s+1}-{e} -----\\n\")\n",
        "                parts.extend(lines[s:e])\n",
        "                parts.append(\"\\n\")\n",
        "        else:\n",
        "            tail_n = min(240, total_lines - head_n) if total_lines > head_n else 0\n",
        "            if tail_n > 0:\n",
        "                start = total_lines - tail_n\n",
        "                parts.append(f\"----- BEGIN FILE (TAIL LINES {start+1}-{total_lines}) -----\\n\")\n",
        "                parts.extend(lines[start:])\n",
        "                parts.append(\"----- END FILE (TAIL) -----\\n\")\n",
        "\n",
        "        # LINE-BOUNDARY truncation (safer than char slicing)\n",
        "        context = \"\".join(parts)\n",
        "        if self.max_context_chars and len(context) > self.max_context_chars:\n",
        "            # rebuild until cap\n",
        "            out = []\n",
        "            n = 0\n",
        "            for chunk in parts:\n",
        "                if n + len(chunk) > self.max_context_chars:\n",
        "                    break\n",
        "                out.append(chunk)\n",
        "                n += len(chunk)\n",
        "            out.append(\"\\n----- [CONTEXT TRUNCATED] -----\\n\")\n",
        "            context = \"\".join(out)\n",
        "\n",
        "        return context\n",
        "\n",
        "    def _postprocess_patch(self, patch: str) -> str:\n",
        "        patch = self._extract_unified_diff(patch)\n",
        "        patch = patch.replace(\"\\r\\n\", \"\\n\").replace(\"\\r\", \"\\n\").strip(\"\\n\") + \"\\n\" if patch else \"\"\n",
        "        return patch\n",
        "\n",
        "    def _extract_unified_diff(self, text: str) -> str:\n",
        "        if not text:\n",
        "            return \"\"\n",
        "        # remove markdown fences\n",
        "        text = re.sub(r\"^\\s*```(?:diff)?\\s*\\n\", \"\", text, flags=re.MULTILINE)\n",
        "        text = re.sub(r\"\\n\\s*```\\s*$\", \"\", text, flags=re.MULTILINE)\n",
        "\n",
        "        # keep from first diff header\n",
        "        m = re.search(r\"(?m)^diff --git \", text)\n",
        "        if not m:\n",
        "            return \"\"\n",
        "        text = text[m.start():]\n",
        "\n",
        "        # minimal sanity: must include file headers + hunks\n",
        "        if (\"--- \" not in text) or (\"+++ \" not in text) or (\"@@\" not in text):\n",
        "            return \"\"\n",
        "        return text\n",
        "\n",
        "    def _git_apply_check(self, repo_path: str, patch: str, recount: bool = False) -> ApplyCheckResult:\n",
        "        if not patch.strip():\n",
        "            return ApplyCheckResult(False, \"Empty patch\", \"\")\n",
        "\n",
        "        with tempfile.NamedTemporaryFile(mode=\"w\", suffix=\".patch\", delete=False, encoding=\"utf-8\") as f:\n",
        "            f.write(patch if patch.endswith(\"\\n\") else patch + \"\\n\")\n",
        "            tmp = f.name\n",
        "\n",
        "        try:\n",
        "            cmd = [\"git\", \"apply\", \"--check\", \"--verbose\"]\n",
        "            if recount:\n",
        "                cmd.append(\"--recount\")\n",
        "            p = subprocess.run(cmd + [tmp], cwd=repo_path, capture_output=True, text=True, timeout=30)\n",
        "            return ApplyCheckResult(ok=(p.returncode == 0), stderr=p.stderr or \"\", stdout=p.stdout or \"\")\n",
        "        except subprocess.TimeoutExpired:\n",
        "            return ApplyCheckResult(False, \"git apply --check timed out\", \"\")\n",
        "        finally:\n",
        "            try:\n",
        "                os.unlink(tmp)\n",
        "            except Exception:\n",
        "                pass\n",
        "\n",
        "\n",
        "print(\"Initializing GPT-5.1 SINGLE-PASS baseline agent (1 call) — robust context + patch extraction...\")\n",
        "agent = SinglePassBaselineAgent(\n",
        "    client,\n",
        "    model=\"gpt-5.1\",\n",
        "    strict_single_file=True,\n",
        "    do_apply_check=True,\n",
        "    head_lines=200,\n",
        "    max_context_chars=32000,\n",
        ")\n",
        "print(\"✓ Agent ready\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dgGe2dKIkIbA",
        "outputId": "daec84c2-af82-48cb-cce8-01682e36a2b5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing GPT-5.1 SINGLE-PASS baseline agent (1 call) — robust context + patch extraction...\n",
            "✓ Agent ready\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# Cell 8: Run baseline on subset (works with the agent above)\n",
        "# =============================================================================\n",
        "\n",
        "import json\n",
        "import time\n",
        "import pandas as pd\n",
        "\n",
        "with open(f\"{PROJECT_DIR}/data/swebench_subset_10.jsonl\") as f:\n",
        "    tasks = [json.loads(line) for line in f]\n",
        "\n",
        "print(f\"Running baseline on {len(tasks)} tasks\")\n",
        "print(\"Note: First clone per repo takes 1-2 minutes (downloads full history)\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "predictions = []\n",
        "results = []\n",
        "\n",
        "for i, task in enumerate(tasks):\n",
        "    print(f\"\\n[{i+1}/{len(tasks)}] {task['instance_id']}\")\n",
        "    print(f\"Repo: {task['repo']}\")\n",
        "\n",
        "    try:\n",
        "        repo_path = repo_mgr.setup_repository(task['repo'], task['base_commit'])\n",
        "        if not repo_path:\n",
        "            print(\"  ✗ Skipping (repo setup failed)\")\n",
        "            predictions.append({\n",
        "                \"instance_id\": task[\"instance_id\"],\n",
        "                \"model_patch\": \"\",\n",
        "                \"model_name_or_path\": \"gpt-5.1-baseline\"\n",
        "            })\n",
        "            results.append({\n",
        "                \"instance_id\": task[\"instance_id\"],\n",
        "                \"repo\": task[\"repo\"],\n",
        "                \"success\": False,\n",
        "                \"has_patch\": False,\n",
        "                \"patch_length\": 0,\n",
        "                \"tokens_used\": 0,\n",
        "                \"duration\": 0\n",
        "            })\n",
        "            continue\n",
        "\n",
        "        start_time = time.time()\n",
        "        result = agent.solve_issue(task, repo_path)\n",
        "        duration = time.time() - start_time\n",
        "\n",
        "        print(\"target_file:\", result.get(\"target_file\"))\n",
        "        print(\"has_diff:\", \"diff --git\" in (result.get(\"patch\") or \"\"))\n",
        "        print(\"apply_stderr:\", (result.get(\"apply_stderr\") or \"\")[:400])\n",
        "\n",
        "\n",
        "        predictions.append({\n",
        "            \"instance_id\": task[\"instance_id\"],\n",
        "            \"model_patch\": result[\"patch\"],\n",
        "            \"model_name_or_path\": \"gpt-5.1-baseline\"\n",
        "        })\n",
        "\n",
        "        results.append({\n",
        "            \"instance_id\": task[\"instance_id\"],\n",
        "            \"repo\": task[\"repo\"],\n",
        "            \"success\": result[\"success\"],\n",
        "            \"has_patch\": bool(result[\"patch\"]),\n",
        "            \"patch_length\": len(result[\"patch\"]),\n",
        "            \"tokens_used\": result[\"tokens_used\"],\n",
        "            \"duration\": duration\n",
        "        })\n",
        "\n",
        "        print(f\"  ✓ Completed in {duration:.1f}s\")\n",
        "        print(f\"  Patch: {'Yes' if result['patch'] else 'No'} ({len(result['patch'])} chars)\")\n",
        "        print(f\"  Tokens: {result['tokens_used']}\")\n",
        "\n",
        "        repo_mgr.cleanup_repository(repo_path)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"  ✗ Error: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "\n",
        "        predictions.append({\n",
        "            \"instance_id\": task[\"instance_id\"],\n",
        "            \"model_patch\": \"\",\n",
        "            \"model_name_or_path\": \"gpt-5.1-baseline\"\n",
        "        })\n",
        "        results.append({\n",
        "            \"instance_id\": task[\"instance_id\"],\n",
        "            \"repo\": task[\"repo\"],\n",
        "            \"success\": False,\n",
        "            \"has_patch\": False,\n",
        "            \"patch_length\": 0,\n",
        "            \"tokens_used\": 0,\n",
        "            \"duration\": 0\n",
        "        })\n",
        "\n",
        "pred_file = f\"{PROJECT_DIR}/predictions/baseline_subset.jsonl\"\n",
        "with open(pred_file, \"w\") as f:\n",
        "    for pred in predictions:\n",
        "        f.write(json.dumps(pred) + \"\\n\")\n",
        "\n",
        "df_results = pd.DataFrame(results)\n",
        "df_results.to_csv(f\"{PROJECT_DIR}/results/baseline_summary.csv\", index=False)\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"BASELINE RESULTS\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Tasks completed: {len(results)}\")\n",
        "print(f\"Patches generated: {df_results['has_patch'].sum()}\")\n",
        "print(f\"Success rate: {df_results['success'].mean():.1%}\")\n",
        "print(f\"Avg tokens: {df_results['tokens_used'].mean():.0f}\")\n",
        "print(f\"Avg time: {df_results['duration'].mean():.1f}s\")\n",
        "print(f\"Total time: {df_results['duration'].sum():.1f}s\")\n",
        "print(f\"\\n✓ Saved: {pred_file}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jy8JkD48FEE0",
        "outputId": "5ff880ae-2150-49b9-ed29-fbe3de0315a8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running baseline on 10 tasks\n",
            "Note: First clone per repo takes 1-2 minutes (downloads full history)\n",
            "============================================================\n",
            "\n",
            "[1/10] astropy__astropy-12907\n",
            "Repo: astropy/astropy\n",
            "  Cloning astropy/astropy ...\n",
            "  ✓ Ready at commit d16bfe05\n",
            "target_file: astropy/modeling/core.py\n",
            "has_diff: True\n",
            "apply_stderr: Checking patch astropy/modeling/core.py...\n",
            "Hunk #1 succeeded at 12 (offset -2 lines).\n",
            "Hunk #2 succeeded at 28 (offset -4 lines).\n",
            "Hunk #3 succeeded at 39 (offset -4 lines).\n",
            "Hunk #4 succeeded at 48 (offset -4 lines).\n",
            "Hunk #5 succeeded at 57 (offset -4 lines).\n",
            "Hunk #6 succeeded at 204 (offset -2 lines).\n",
            "Hunk #7 succeeded at 222 (offset -3 lines).\n",
            "error: while searching for:\n",
            "    def _create_bounding_b\n",
            "  ✓ Completed in 18.7s\n",
            "  Patch: Yes (4218 chars)\n",
            "  Tokens: 3753\n",
            "\n",
            "[2/10] astropy__astropy-14182\n",
            "Repo: astropy/astropy\n",
            "  Cloning astropy/astropy ...\n",
            "  ✓ Ready at commit a5917978\n",
            "target_file: astropy/extern/jquery/data/js/jquery.dataTables.js\n",
            "has_diff: False\n",
            "apply_stderr: \n",
            "  ✓ Completed in 42.2s\n",
            "  Patch: No (0 chars)\n",
            "  Tokens: 8989\n",
            "\n",
            "[3/10] astropy__astropy-14365\n",
            "Repo: astropy/astropy\n",
            "  Cloning astropy/astropy ...\n",
            "  ✓ Ready at commit 7269fa3e\n",
            "target_file: astropy/time/formats.py\n",
            "has_diff: True\n",
            "apply_stderr: Checking patch astropy/time/formats.py...\n",
            "error: while searching for:\n",
            "# Licensed under a 3-clause BSD style license - see LICENSE.rst\n",
            "import datetime\n",
            "import fnmatch\n",
            "import re\n",
            "import time\n",
            "import warnings\n",
            "from collections import OrderedDict, defaultdict\n",
            "from decimal import Decimal\n",
            "\n",
            "import erfa\n",
            "import numpy as np\n",
            "\n",
            "import astropy.units as u\n",
            "from astropy.utils.decorators import classproperty, lazyprope\n",
            "  ✓ Completed in 37.9s\n",
            "  Patch: Yes (13089 chars)\n",
            "  Tokens: 7314\n",
            "\n",
            "[4/10] astropy__astropy-14995\n",
            "Repo: astropy/astropy\n",
            "  Cloning astropy/astropy ...\n",
            "  ✓ Ready at commit b16c7d12\n",
            "target_file: astropy/time/core.py\n",
            "has_diff: True\n",
            "apply_stderr: Checking patch astropy/time/core.py...\n",
            "Hunk #1 succeeded at 530 (offset 244 lines).\n",
            "  ✓ Completed in 14.9s\n",
            "  Patch: Yes (1422 chars)\n",
            "  Tokens: 6113\n",
            "\n",
            "[5/10] astropy__astropy-6938\n",
            "Repo: astropy/astropy\n",
            "  Cloning astropy/astropy ...\n",
            "  ✓ Ready at commit c76af9ed\n",
            "target_file: astropy/units/core.py\n",
            "has_diff: True\n",
            "apply_stderr: Checking patch astropy/units/core.py...\n",
            "Hunk #1 succeeded at 9 (offset -2 lines).\n",
            "Hunk #2 succeeded at 1721 (offset 177 lines).\n",
            "Hunk #3 succeeded at 1750 (offset 177 lines).\n",
            "  ✓ Completed in 9.2s\n",
            "  Patch: Yes (2033 chars)\n",
            "  Tokens: 7817\n",
            "\n",
            "[6/10] astropy__astropy-7746\n",
            "Repo: astropy/astropy\n",
            "  Cloning astropy/astropy ...\n",
            "  ✓ Ready at commit d5bd3f68\n",
            "target_file: cextern/wcslib/C/wcs.c\n",
            "has_diff: True\n",
            "apply_stderr: Checking patch cextern/wcslib/C/wcs.c...\n",
            "Hunk #1 succeeded at 69 (offset 23 lines).\n",
            "Hunk #2 succeeded at 209 (offset 6 lines).\n",
            "  ✓ Completed in 15.4s\n",
            "  Patch: Yes (1944 chars)\n",
            "  Tokens: 5125\n",
            "\n",
            "[7/10] django__django-10914\n",
            "Repo: django/django\n",
            "  Cloning django/django ...\n",
            "  ✓ Ready at commit e7fd69d0\n",
            "target_file: django/conf/global_settings.py\n",
            "has_diff: True\n",
            "apply_stderr: Checking patch django/conf/global_settings.py...\n",
            "Hunk #1 succeeded at 290 (offset 35 lines).\n",
            "Hunk #2 succeeded at 303 (offset 34 lines).\n",
            "  ✓ Completed in 4.5s\n",
            "  Patch: Yes (1200 chars)\n",
            "  Tokens: 5819\n",
            "\n",
            "[8/10] django__django-10924\n",
            "Repo: django/django\n",
            "  Cloning django/django ...\n",
            "  ✓ Ready at commit bceadd27\n",
            "target_file: django/db/models/fields/__init__.py\n",
            "has_diff: True\n",
            "apply_stderr: Checking patch django/db/models/fields/__init__.py...\n",
            "error: while searching for:\n",
            "         * top-level classes, top-level functions - will be referenced by their\n",
            "           full import path\n",
            "         * Storage instances - these have their own deconstruct() method\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "error: patch failed: django/db/models/fields/__init__.py:420\n",
            "error: django/db/models/fields/__init__.py: patch does not apply\n",
            "  ✓ Completed in 13.9s\n",
            "  Patch: Yes (2813 chars)\n",
            "  Tokens: 4268\n",
            "\n",
            "[9/10] django__django-11001\n",
            "Repo: django/django\n",
            "  Cloning django/django ...\n",
            "  ✓ Ready at commit ef082ebb\n",
            "target_file: django/db/models/query.py\n",
            "has_diff: True\n",
            "apply_stderr: Checking patch django/db/models/query.py...\n",
            "Hunk #1 succeeded at 21 (offset 3 lines).\n",
            "Hunk #2 succeeded at 29 (offset 3 lines).\n",
            "  ✓ Completed in 6.1s\n",
            "  Patch: Yes (949 chars)\n",
            "  Tokens: 7607\n",
            "\n",
            "[10/10] django__django-11019\n",
            "Repo: django/django\n",
            "  Cloning django/django ...\n",
            "  ✓ Ready at commit 93e892bb\n",
            "target_file: js_tests/qunit/qunit.js\n",
            "has_diff: True\n",
            "apply_stderr: Checking patch js_tests/qunit/qunit.js...\n",
            "Hunk #1 succeeded at 51 (offset 15 lines).\n",
            "Hunk #2 succeeded at 78 (offset 16 lines).\n",
            "  ✓ Completed in 9.8s\n",
            "  Patch: Yes (1857 chars)\n",
            "  Tokens: 5486\n",
            "\n",
            "============================================================\n",
            "BASELINE RESULTS\n",
            "============================================================\n",
            "Tasks completed: 10\n",
            "Patches generated: 9\n",
            "Success rate: 60.0%\n",
            "Avg tokens: 6229\n",
            "Avg time: 17.3s\n",
            "Total time: 172.6s\n",
            "\n",
            "✓ Saved: /content/drive/MyDrive/adaptive-swe-agent/predictions/baseline_subset.jsonl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NXTs9-4ZDndG",
        "outputId": "faaff4b6-41e5-48fb-e05e-c47dfeddc43d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "DIAGNOSTIC: Verify Baseline Target + Context Snippet\n",
            "============================================================\n",
            "\n",
            "Task: astropy__astropy-12907\n",
            "Problem statement (first 200 chars):\n",
            "Modeling's `separability_matrix` does not compute separability correctly for nested CompoundModels\n",
            "Consider the following model:\r\n",
            "\r\n",
            "```python\r\n",
            "from astropy.modeling import models as m\r\n",
            "from astropy.mo...\n",
            "  Cloning astropy/astropy ...\n",
            "  ✓ Ready at commit d16bfe05\n",
            "\n",
            "============================================================\n",
            "Target file inferred: astropy/modeling/core.py\n",
            "============================================================\n",
            "\n",
            "FULL FILE stats (on disk):\n",
            "  Total characters: 175823\n",
            "  Total lines: 4473\n",
            "  First line: # Licensed under a 3-clause BSD style license - see LICENSE.rst\n",
            "  Last line:     return model\n",
            "\n",
            "============================================================\n",
            "CONTEXT SNIPPET SENT TO MODEL (first 2000 chars)\n",
            "============================================================\n",
            "FILE: astropy/modeling/core.py\n",
            "----- BEGIN FILE (HEAD LINES 1-200) -----\n",
            "# Licensed under a 3-clause BSD style license - see LICENSE.rst\n",
            "\n",
            "\"\"\"\n",
            "This module defines base classes for all models.  The base class of all\n",
            "models is `~astropy.modeling.Model`. `~astropy.modeling.FittableModel` is\n",
            "the base class for all fittable models. Fittable models can be linear or\n",
            "nonlinear in a regression analysis sense.\n",
            "\n",
            "All models provide a `__call__` method which performs the transformation in\n",
            "a purely mathematical way, i.e. the models are unitless.  Model instances can\n",
            "represent either a single model, or a \"model set\" representing multiple copies\n",
            "of the same type of model, but with potentially different values of the\n",
            "parameters in each model making up the set.\n",
            "\"\"\"\n",
            "# pylint: disable=invalid-name, protected-access, redefined-outer-name\n",
            "import abc\n",
            "import copy\n",
            "import inspect\n",
            "import itertools\n",
            "import functools\n",
            "import operator\n",
            "import types\n",
            "\n",
            "from collections import defaultdict, deque\n",
            "from inspect import signature\n",
            "from itertools import chain\n",
            "\n",
            "import numpy as np\n",
            "\n",
            "from astropy.utils import indent, metadata\n",
            "from astropy.table import Table\n",
            "from astropy.units import Quantity, UnitsError, dimensionless_unscaled\n",
            "from astropy.units.utils import quantity_asanyarray\n",
            "from astropy.utils import (sharedmethod, find_current_module,\n",
            "                           check_broadcast, IncompatibleShapeError, isiterable)\n",
            "from astropy.utils.codegen import make_function_with_signature\n",
            "from astropy.nddata.utils import add_array, extract_array\n",
            "from .utils import (combine_labels, make_binary_operator_eval,\n",
            "                    get_inputs_and_params, _combine_equivalency_dict,\n",
            "                    _ConstraintsDict, _SpecialOperatorsDict)\n",
            "from .bounding_box import ModelBoundingBox, CompoundBoundingBox\n",
            "from .parameters import (Parameter, InputParameterError,\n",
            "                         param_repr_oneline, _tofloat)\n",
            "\n",
            "\n",
            "__all__ = ['Model', 'FittableModel', 'Fittable1DModel', 'Fittable2DModel',\n",
            "           'CompoundModel', 'fix_inputs'\n",
            "\n",
            "...\n",
            "\n",
            "Context snippet length: 10239 chars\n",
            "\n",
            "============================================================\n",
            "VERIFICATION COMPLETE\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# Cell 7.5: Verify Context Being Sent to GPT-5.1 (SinglePassBaselineAgent)\n",
        "# =============================================================================\n",
        "import json\n",
        "import os\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"DIAGNOSTIC: Verify Baseline Target + Context Snippet\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Load a task\n",
        "with open(f\"{PROJECT_DIR}/data/swebench_subset_10.jsonl\") as f:\n",
        "    tasks = [json.loads(line) for line in f]\n",
        "\n",
        "task = tasks[0]  # First task\n",
        "\n",
        "print(f\"\\nTask: {task['instance_id']}\")\n",
        "print(\"Problem statement (first 200 chars):\")\n",
        "print(f\"{task.get('problem_statement','')[:200]}...\")\n",
        "\n",
        "# Setup repo\n",
        "repo_path = repo_mgr.setup_repository(task['repo'], task['base_commit'])\n",
        "if not repo_path:\n",
        "    raise RuntimeError(\"Repo setup failed\")\n",
        "\n",
        "problem_statement = task.get(\"problem_statement\") or task.get(\"problem\") or \"\"\n",
        "\n",
        "# Infer target file (same logic as baseline)\n",
        "target_file = agent._infer_target_file(problem_statement, repo_path)\n",
        "if agent.strict_single_file and not target_file:\n",
        "    target_file = agent._fallback_target_file(problem_statement, repo_path)\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(f\"Target file inferred: {target_file}\")\n",
        "print(f\"{'='*60}\")\n",
        "\n",
        "# Show actual file stats (full file on disk)\n",
        "if target_file:\n",
        "    full_path = os.path.join(repo_path, target_file)\n",
        "    if os.path.exists(full_path):\n",
        "        with open(full_path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
        "            full_content = f.read()\n",
        "        full_lines = full_content.splitlines()\n",
        "\n",
        "        print(\"\\nFULL FILE stats (on disk):\")\n",
        "        print(f\"  Total characters: {len(full_content)}\")\n",
        "        print(f\"  Total lines: {len(full_lines)}\")\n",
        "        print(f\"  First line: {full_lines[0][:100] if full_lines else '(empty)'}\")\n",
        "        print(f\"  Last line: {full_lines[-1][:100] if full_lines else '(empty)'}\")\n",
        "    else:\n",
        "        print(f\"\\n✗ Target file not found on disk: {full_path}\")\n",
        "\n",
        "# Show what baseline sends as context (excerpt/snippet)\n",
        "file_context = agent._build_file_context(problem_statement, repo_path, target_file)\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(\"CONTEXT SNIPPET SENT TO MODEL (first 2000 chars)\")\n",
        "print(f\"{'='*60}\")\n",
        "print(file_context[:2000])\n",
        "print(\"\\n...\")\n",
        "\n",
        "print(f\"\\nContext snippet length: {len(file_context)} chars\")\n",
        "\n",
        "# Cleanup\n",
        "repo_mgr.cleanup_repository(repo_path)\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(\"VERIFICATION COMPLETE\")\n",
        "print(\"=\"*60)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w5oJvEKKXwAa",
        "outputId": "48b149ab-7d72-43e7-be9b-83c3825d3bb1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing: astropy__astropy-7746\n",
            "============================================================\n",
            "  Cloning astropy/astropy ...\n",
            "  ✓ Ready at commit d5bd3f68\n",
            "\n",
            "Target file: cextern/wcslib/C/wcs.c\n",
            "Context snippet length: 11072 chars\n",
            "\n",
            "============================================================\n",
            "CONTEXT SNIPPET SENT (first 1200 chars):\n",
            "============================================================\n",
            "FILE: cextern/wcslib/C/wcs.c\n",
            "----- BEGIN FILE (HEAD LINES 1-200) -----\n",
            "/*============================================================================\n",
            "\n",
            "  WCSLIB 5.19 - an implementation of the FITS WCS standard.\n",
            "  Copyright (C) 1995-2018, Mark Calabretta\n",
            "\n",
            "  This file is part of WCSLIB.\n",
            "\n",
            "  WCSLIB is free software: you can redistribute it and/or modify it under the\n",
            "  terms of the GNU Lesser General Public License as published by the Free\n",
            "  Software Foundation, either version 3 of the License, or (at your option)\n",
            "  any later version.\n",
            "\n",
            "  WCSLIB is distributed in the hope that it will be useful, but WITHOUT ANY\n",
            "  WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS\n",
            "  FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License for\n",
            "  more details.\n",
            "\n",
            "  You should have received a copy of the GNU Lesser General Public License\n",
            "  along with WCSLIB.  If not, see http://www.gnu.org/licenses.\n",
            "\n",
            "  Direct correspondence concerning WCSLIB to mark@calabretta.id.au\n",
            "\n",
            "  Author: Mark Calabretta, Australia Telescope National Facility, CSIRO.\n",
            "  http://www.atnf.csiro.au/people/Mark.Calabretta\n",
            "  $Id: wcs.c,v 5.19.1.1 2018/07/26 15:41:40 mcalabre Exp mcalabre $\n",
            "*====================\n",
            "\n",
            "...\n",
            "\n",
            "============================================================\n",
            "RAW GPT RESPONSE (first 1200 chars):\n",
            "============================================================\n",
            "diff --git a/cextern/wcslib/C/wcs.c b/cextern/wcslib/C/wcs.c\n",
            "index 5a4a3f1..e2b9f3b 100644\n",
            "--- a/cextern/wcslib/C/wcs.c\n",
            "+++ b/cextern/wcslib/C/wcs.c\n",
            "@@ -36,6 +36,7 @@\n",
            " #include \"tab.h\"\n",
            " #include \"wcs.h\"\n",
            " \n",
            "+\n",
            " const int WCSSET = 137;\n",
            " \n",
            " /* Maximum number of PVi_ma and PSi_ma keywords. */\n",
            "@@ -140,6 +141,34 @@ static int wcs_units(struct wcsprm *);\n",
            " \n",
            " /*--------------------------------------------------------------------------*/\n",
            " \n",
            "+/* Helper to treat zero-length coordinate lists as a no-op.\n",
            "+ *\n",
            "+ * Many high-level interfaces (e.g., Astropy) may call wcslib with\n",
            "+ * ncoord == 0 when given empty input arrays.  The core wcslib\n",
            "+ * routines expect ncoord > 0 and will otherwise raise\n",
            "+ * \"ncoord and/or nelem inconsistent with the wcsprm\".  For such\n",
            "+ * calls we simply return success without touching the output.\n",
            "+ */\n",
            "+static int\n",
            "+wcs_empty_coord_list(int ncoord, int nelem)\n",
            "+{\n",
            "+  if (ncoord == 0) {\n",
            "+    /* For zero coordinates, nelem is irrelevant; treat as success. */\n",
            "+    return 1;\n",
            "+  }\n",
            "+\n",
            "+  /* Non-zero ncoord: let the normal routines handle validation. */\n",
            "+  (void)nelem;\n",
            "+  return 0;\n",
            "+}\n",
            "+\n",
            "+/*--------------------------------------------------------------------------*/\n",
            "+\n",
            "+/* Forward declarat\n",
            "\n",
            "Tokens used: 5210\n",
            "\n",
            "============================================================\n",
            "NORMALIZED PATCH (first 1200 chars):\n",
            "============================================================\n",
            "diff --git a/cextern/wcslib/C/wcs.c b/cextern/wcslib/C/wcs.c\n",
            "index 5a4a3f1..e2b9f3b 100644\n",
            "--- a/cextern/wcslib/C/wcs.c\n",
            "+++ b/cextern/wcslib/C/wcs.c\n",
            "@@ -36,6 +36,7 @@\n",
            " #include \"tab.h\"\n",
            " #include \"wcs.h\"\n",
            " \n",
            "+\n",
            " const int WCSSET = 137;\n",
            " \n",
            " /* Maximum number of PVi_ma and PSi_ma keywords. */\n",
            "@@ -140,6 +141,34 @@ static int wcs_units(struct wcsprm *);\n",
            " \n",
            " /*--------------------------------------------------------------------------*/\n",
            " \n",
            "+/* Helper to treat zero-length coordinate lists as a no-op.\n",
            "+ *\n",
            "+ * Many high-level interfaces (e.g., Astropy) may call wcslib with\n",
            "+ * ncoord == 0 when given empty input arrays.  The core wcslib\n",
            "+ * routines expect ncoord > 0 and will otherwise raise\n",
            "+ * \"ncoord and/or nelem inconsistent with the wcsprm\".  For such\n",
            "+ * calls we simply return success without touching the output.\n",
            "+ */\n",
            "+static int\n",
            "+wcs_empty_coord_list(int ncoord, int nelem)\n",
            "+{\n",
            "+  if (ncoord == 0) {\n",
            "+    /* For zero coordinates, nelem is irrelevant; treat as success. */\n",
            "+    return 1;\n",
            "+  }\n",
            "+\n",
            "+  /* Non-zero ncoord: let the normal routines handle validation. */\n",
            "+  (void)nelem;\n",
            "+  return 0;\n",
            "+}\n",
            "+\n",
            "+/*--------------------------------------------------------------------------*/\n",
            "+\n",
            "+/* Forward declarat\n",
            "\n",
            "Has diff header: True\n",
            "\n",
            "============================================================\n",
            "GIT APPLY --CHECK RESULT:\n",
            "============================================================\n",
            "OK: False\n",
            "STDERR (first 1200 chars):\n",
            "Checking patch cextern/wcslib/C/wcs.c...\n",
            "Hunk #1 succeeded at 46 (offset 10 lines).\n",
            "Hunk #2 succeeded at 130 (offset -11 lines).\n",
            "Hunk #3 succeeded at 2647 (offset 1298 lines).\n",
            "error: while searching for:\n",
            "  int ncoord,\n",
            "  int nelem,\n",
            "  const double world[],\n",
            "  const double phi[],\n",
            "  const double theta[],\n",
            "  double imgcrd[],\n",
            "\n",
            "error: patch failed: cextern/wcslib/C/wcs.c:1450\n",
            "error: cextern/wcslib/C/wcs.c: patch does not apply\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# Cell 7.7: Debug SinglePassBaselineAgent (FULL WORKING)\n",
        "# =============================================================================\n",
        "import json\n",
        "import os\n",
        "\n",
        "# Load one task to debug\n",
        "with open(f\"{PROJECT_DIR}/data/swebench_subset_10.jsonl\") as f:\n",
        "    tasks = [json.loads(line) for line in f]\n",
        "\n",
        "task = tasks[5]  # pick any index you want\n",
        "\n",
        "print(f\"Testing: {task['instance_id']}\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# -----------------------------\n",
        "# 1) Clone repo & infer target file (same as baseline)\n",
        "# -----------------------------\n",
        "repo_path = repo_mgr.setup_repository(task['repo'], task['base_commit'])\n",
        "if not repo_path:\n",
        "    raise RuntimeError(\"Repo setup failed\")\n",
        "\n",
        "problem_statement = task.get(\"problem_statement\") or task.get(\"problem\") or \"\"\n",
        "\n",
        "target_file = agent._infer_target_file(problem_statement, repo_path)\n",
        "if agent.strict_single_file and not target_file:\n",
        "    target_file = agent._fallback_target_file(problem_statement, repo_path)\n",
        "\n",
        "print(f\"\\nTarget file: {target_file}\")\n",
        "\n",
        "file_context = agent._build_file_context(problem_statement, repo_path, target_file)\n",
        "print(f\"Context snippet length: {len(file_context)} chars\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"CONTEXT SNIPPET SENT (first 1200 chars):\")\n",
        "print(\"=\"*60)\n",
        "print(file_context[:1200])\n",
        "print(\"\\n...\")\n",
        "\n",
        "# -----------------------------\n",
        "# 2) Call GPT-5.1 exactly once (same prompt shape as baseline)\n",
        "# -----------------------------\n",
        "raw_text, tokens_used = agent._generate_patch(\n",
        "    problem_statement=problem_statement,\n",
        "    target_file=target_file,\n",
        "    file_context=file_context,\n",
        "    max_tokens=4096,\n",
        ")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"RAW GPT RESPONSE (first 1200 chars):\")\n",
        "print(\"=\"*60)\n",
        "print((raw_text or \"\")[:1200])\n",
        "print(\"\\nTokens used:\", tokens_used)\n",
        "\n",
        "# -----------------------------\n",
        "# 3) Normalize patch (same as baseline)\n",
        "# -----------------------------\n",
        "patch = agent._postprocess_patch(raw_text)\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"NORMALIZED PATCH (first 1200 chars):\")\n",
        "print(\"=\"*60)\n",
        "print((patch or \"\")[:1200])\n",
        "print(\"\\nHas diff header:\", \"diff --git\" in (patch or \"\"))\n",
        "\n",
        "# -----------------------------\n",
        "# 4) Apply-check (same as baseline scoring)\n",
        "# -----------------------------\n",
        "if patch.strip():\n",
        "    res = agent._git_apply_check(repo_path, patch, recount=True)\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"GIT APPLY --CHECK RESULT:\")\n",
        "    print(\"=\"*60)\n",
        "    print(\"OK:\", res.ok)\n",
        "    print(\"STDERR (first 1200 chars):\")\n",
        "    print((res.stderr or \"\")[:1200])\n",
        "else:\n",
        "    print(\"\\nNo patch generated after normalization (empty).\")\n",
        "\n",
        "# -----------------------------\n",
        "# Cleanup\n",
        "# -----------------------------\n",
        "repo_mgr.cleanup_repository(repo_path)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# Cell 14: Validate These Patches Apply (ROBUST + CONSISTENT)\n",
        "# - Reads saved predictions JSONL\n",
        "# - Re-checks each patch with: git apply --check --verbose --recount\n",
        "# - Uses UTF-8 when writing patch tempfiles\n",
        "# - Prints concise errors + final apply rate\n",
        "# =============================================================================\n",
        "\n",
        "import json\n",
        "import subprocess\n",
        "import tempfile\n",
        "import os\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"VALIDATING BASELINE PATCHES (git apply --check --verbose --recount)\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "pred_path = f\"{PROJECT_DIR}/predictions/baseline_subset.jsonl\"\n",
        "task_path = f\"{PROJECT_DIR}/data/swebench_subset_10.jsonl\"\n",
        "\n",
        "with open(pred_path) as f:\n",
        "    preds = [json.loads(line) for line in f]\n",
        "\n",
        "with open(task_path) as f:\n",
        "    tasks = [json.loads(line) for line in f]\n",
        "\n",
        "task_lookup = {t[\"instance_id\"]: t for t in tasks}\n",
        "\n",
        "apply_results = []\n",
        "checked = 0\n",
        "\n",
        "for i, pred in enumerate(preds[:10]):\n",
        "    instance_id = pred.get(\"instance_id\")\n",
        "    patch = pred.get(\"model_patch\", \"\") or \"\"\n",
        "\n",
        "    if not instance_id:\n",
        "        print(f\"[{i+1}/10] ✗ Missing instance_id in predictions row\")\n",
        "        apply_results.append(False)\n",
        "        continue\n",
        "\n",
        "    if not patch.strip():\n",
        "        print(f\"[{i+1}/10] {instance_id}: ✗ No patch\")\n",
        "        apply_results.append(False)\n",
        "        continue\n",
        "\n",
        "    task = task_lookup.get(instance_id)\n",
        "    if not task:\n",
        "        print(f\"[{i+1}/10] {instance_id}: ✗ Task not found in dataset file\")\n",
        "        apply_results.append(False)\n",
        "        continue\n",
        "\n",
        "    repo_path = repo_mgr.setup_repository(task[\"repo\"], task[\"base_commit\"])\n",
        "    if not repo_path:\n",
        "        print(f\"[{i+1}/10] {instance_id}: ✗ Repo setup failed\")\n",
        "        apply_results.append(False)\n",
        "        continue\n",
        "\n",
        "    checked += 1\n",
        "\n",
        "    # Write patch to a temp file (UTF-8)\n",
        "    patch_file = None\n",
        "    try:\n",
        "        with tempfile.NamedTemporaryFile(mode=\"w\", suffix=\".patch\", delete=False, encoding=\"utf-8\") as f:\n",
        "            f.write(patch if patch.endswith(\"\\n\") else patch + \"\\n\")\n",
        "            patch_file = f.name\n",
        "\n",
        "        # Consistent check flags\n",
        "        cmd = [\"git\", \"apply\", \"--check\", \"--verbose\", \"--recount\", patch_file]\n",
        "        result = subprocess.run(\n",
        "            cmd,\n",
        "            cwd=repo_path,\n",
        "            capture_output=True,\n",
        "            text=True\n",
        "        )\n",
        "\n",
        "        applies = (result.returncode == 0)\n",
        "        apply_results.append(applies)\n",
        "\n",
        "        if applies:\n",
        "            print(f\"[{i+1}/10] {instance_id}: ✓ APPLIES!\")\n",
        "        else:\n",
        "            stderr = (result.stderr or \"\").strip().replace(\"\\n\", \" \")\n",
        "            if len(stderr) > 220:\n",
        "                stderr = stderr[:220] + \"...\"\n",
        "            print(f\"[{i+1}/10] {instance_id}: ✗ {stderr}\")\n",
        "\n",
        "    finally:\n",
        "        if patch_file and os.path.exists(patch_file):\n",
        "            try:\n",
        "                os.unlink(patch_file)\n",
        "            except Exception:\n",
        "                pass\n",
        "        repo_mgr.cleanup_repository(repo_path)\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"RESULTS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "apply_count = sum(1 for x in apply_results if x)\n",
        "# denominator: only those that had a patch and were checked\n",
        "denom = checked if checked > 0 else 1\n",
        "\n",
        "print(f\"Patches checked: {checked}\")\n",
        "print(f\"Patches that apply: {apply_count}/{checked} ({apply_count/denom*100:.0f}%)\")\n",
        "print(f\"✓ Used predictions: {pred_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YbBJSR63heVk",
        "outputId": "43ac4008-41b3-46c1-8bdd-e3892baed035"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "VALIDATING BASELINE PATCHES (git apply --check --verbose --recount)\n",
            "============================================================\n",
            "  Cloning astropy/astropy ...\n",
            "  ✓ Ready at commit d16bfe05\n",
            "[1/10] astropy__astropy-12907: ✗ Checking patch astropy/modeling/core.py... Hunk #1 succeeded at 12 (offset -2 lines). Hunk #2 succeeded at 28 (offset -4 lines). Hunk #3 succeeded at 39 (offset -4 lines). Hunk #4 succeeded at 48 (offset -4 lines). Hunk ...\n",
            "[2/10] astropy__astropy-14182: ✗ No patch\n",
            "  Cloning astropy/astropy ...\n",
            "  ✓ Ready at commit 7269fa3e\n",
            "[3/10] astropy__astropy-14365: ✗ Checking patch astropy/time/formats.py... error: while searching for: # Licensed under a 3-clause BSD style license - see LICENSE.rst import datetime import fnmatch import re import time import warnings from collections ...\n",
            "  Cloning astropy/astropy ...\n",
            "  ✓ Ready at commit b16c7d12\n",
            "[4/10] astropy__astropy-14995: ✓ APPLIES!\n",
            "  Cloning astropy/astropy ...\n",
            "  ✓ Ready at commit c76af9ed\n",
            "[5/10] astropy__astropy-6938: ✓ APPLIES!\n",
            "  Cloning astropy/astropy ...\n",
            "  ✓ Ready at commit d5bd3f68\n",
            "[6/10] astropy__astropy-7746: ✓ APPLIES!\n",
            "  Cloning django/django ...\n",
            "  ✓ Ready at commit e7fd69d0\n",
            "[7/10] django__django-10914: ✓ APPLIES!\n",
            "  Cloning django/django ...\n",
            "  ✓ Ready at commit bceadd27\n",
            "[8/10] django__django-10924: ✗ Checking patch django/db/models/fields/__init__.py... error: while searching for:          * top-level classes, top-level functions - will be referenced by their            full import path          * Storage instances -...\n",
            "  Cloning django/django ...\n",
            "  ✓ Ready at commit ef082ebb\n",
            "[9/10] django__django-11001: ✓ APPLIES!\n",
            "  Cloning django/django ...\n",
            "  ✓ Ready at commit 93e892bb\n",
            "[10/10] django__django-11019: ✓ APPLIES!\n",
            "\n",
            "============================================================\n",
            "RESULTS\n",
            "============================================================\n",
            "Patches checked: 9\n",
            "Patches that apply: 6/9 (67%)\n",
            "✓ Used predictions: /content/drive/MyDrive/adaptive-swe-agent/predictions/baseline_subset.jsonl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AAThmrISFOUz",
        "outputId": "ddfef6c9-d2f7-4dad-f676-31bbad32a368"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "Task: astropy__astropy-12907\n",
            "============================================================\n",
            "FULL PATCH:\n",
            "diff --git a/astropy/modeling/core.py b/astropy/modeling/core.py\n",
            "index 4c9a4f0..e5a6f4d 100644\n",
            "--- a/astropy/modeling/core.py\n",
            "+++ b/astropy/modeling/core.py\n",
            "@@ -14,6 +14,7 @@ represent either a single model, or a \"model set\" representing multiple copies\n",
            " of the same type of model, but with potentially different values of the\n",
            " parameters in each model making up the set.\n",
            " \"\"\"\n",
            "+\n",
            " # pylint: disable=invalid-name, protected-access, redefined-outer-name\n",
            " import abc\n",
            " import copy\n",
            "@@ -31,6 +32,7 @@ from itertools import chain\n",
            " \n",
            " import numpy as np\n",
            " \n",
            "+from astropy.modeling.separable import separability_matrix\n",
            " from astropy.utils import indent, metadata\n",
            " from astropy.table import Table\n",
            " from astropy.units import Quantity, UnitsError, dimensionless_unscaled\n",
            "@@ -41,7 +43,8 @@ from astropy.utils.codegen import make_function_with_signature\n",
            " from astropy.nddata.utils import add_array, extract_array\n",
            " from .utils import (combine_labels, make_binary_operator_eval,\n",
            "                     get_inputs_and_params, _combine_equivalency_dict,\n",
            "-                    _ConstraintsDict, _SpecialOperatorsDict)\n",
            "+                    _ConstraintsDict, _SpecialOperatorsDict)\n",
            "+\n",
            " from .bounding_box import ModelBoundingBox, CompoundBoundingBox\n",
            " from .parameters import (Parameter, InputParameterError,\n",
            "                          param_repr_oneline, _tofloat)\n",
            "@@ -49,7 +52,8 @@ from .parameters import (Parameter, InputParameterError,\n",
            " \n",
            " __all__ = ['Model', 'FittableModel', 'Fittable1DModel', 'Fittable2DModel',\n",
            "            'CompoundModel', 'fix_inputs', 'custom_model', 'ModelDefinitionError',\n",
            "-           'bind_bounding_box', 'bind_compound_bounding_box']\n",
            "+           'bind_bounding_box', 'bind_compound_bounding_box']\n",
            "+\n",
            " \n",
            " \n",
            " def _model_oper(oper, **kwargs):\n",
            "@@ -57,7 +61,8 @@ def _model_oper(oper, **kwargs):\n",
            "     Returns a function that evaluates a given Python arithmetic operator\n",
            "     between two models.  The operator should be given as a string, like ``'+'``\n",
            "     or ``'**'``.\n",
            "-    \"\"\"\n",
            "+    \"\"\"  # noqa: D400\n",
            "+\n",
            "     return lambda left, right: CompoundModel(oper, left, right, **kwargs)\n",
            " \n",
            " \n",
            "@@ -201,7 +206,8 @@ class _ModelMeta(abc.ABCMeta):\n",
            "     def rename(cls, name=None, inputs=None, outputs=None):\n",
            "         \"\"\"\n",
            "         Creates a copy of this model class with a new name, inputs or outputs.\n",
            "-\n",
            "+        \"\"\"\n",
            "+        # NOTE: docstring closed early above to avoid including example code in it.\n",
            "         The new class is technically a subclass of the original class, so that\n",
            "         instance and type checks will still work.  For example::\n",
            " \n",
            "@@ -219,7 +225,6 @@ class _ModelMeta(abc.ABCMeta):\n",
            "             >>> r = SkyRotation(90)\n",
            "             >>> isinstance(r, Rotation2D)\n",
            "             True\n",
            "-        \"\"\"\n",
            " \n",
            "         mod = find_current_module(2)\n",
            "         if mod:\n",
            "@@ -270,3 +275,63 @@ class _ModelMeta(abc.ABCMeta):\n",
            "     def _create_bounding_box_property(cls, members):\n",
            "         \"\"\"\n",
            "         Takes any bounding_box defined on a concrete Model subclass (either\n",
            "+        \"\"\"\n",
            "+        # NOTE: The original implementation continues below; this stub is kept\n",
            "+        # only to preserve context in this diff.\n",
            "+\n",
            "+\n",
            "+class CompoundModel(Model):\n",
            "+    \"\"\"\n",
            "+    A model composed of two or more submodels combined via arithmetic or\n",
            "+    composition operators.\n",
            "+    \"\"\"\n",
            "+\n",
            "+    # Existing implementation is assumed to be present in the real file.\n",
            "+    # Here we only add/override the separability_matrix property to fix\n",
            "+    # incorrect behavior for nested compound models.\n",
            "+\n",
            "+    @property\n",
            "+    def separability_matrix(self):\n",
            "+        \"\"\"\n",
            "+        Return the separability matrix for this (possibly nested) compound\n",
            "+        model.\n",
            "+\n",
            "+        This overrides/extends any existing implementation to ensure that\n",
            "+        nested ``CompoundModel`` instances are handled correctly by delegating\n",
            "+        to :func:`astropy.modeling.separable.separability_matrix`, which\n",
            "+        already knows how to flatten nested compound structures.\n",
            "+        \"\"\"\n",
            "+\n",
            "+        # Delegate to the public separability_matrix function, which correctly\n",
            "+        # handles nested CompoundModels.  This avoids relying on any cached or\n",
            "+        # partially computed matrix that may have been built assuming a\n",
            "+        # non-nested structure.\n",
            "+        return separability_matrix(self)\n",
            "\n",
            "\n",
            "============================================================\n",
            "\n",
            "Total lines: 105\n",
            "\n",
            "Lines 15-20 (where corruption occurs at line 18):\n",
            "15: ' import numpy as np'\n",
            "16: ' '\n",
            "17: '+from astropy.modeling.separable import separability_matrix'\n",
            "18: ' from astropy.utils import indent, metadata'\n",
            "19: ' from astropy.table import Table'\n",
            "20: ' from astropy.units import Quantity, UnitsError, dimensionless_unscaled'\n"
          ]
        }
      ],
      "source": [
        "# Cell 14.5: Inspect Actual Patch Content\n",
        "import json\n",
        "\n",
        "with open(f\"{PROJECT_DIR}/predictions/baseline_subset.jsonl\") as f:\n",
        "    preds = [json.loads(line) for line in f]\n",
        "\n",
        "# Check first patch in detail\n",
        "pred = preds[0]  # astropy__astropy-12907\n",
        "patch = pred['model_patch']\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(f\"Task: {pred['instance_id']}\")\n",
        "print(\"=\"*60)\n",
        "print(\"FULL PATCH:\")\n",
        "print(patch)\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "\n",
        "# Check for specific issues\n",
        "lines = patch.split('\\n')\n",
        "print(f\"\\nTotal lines: {len(lines)}\")\n",
        "print(\"\\nLines 15-20 (where corruption occurs at line 18):\")\n",
        "for i in range(14, min(20, len(lines))):\n",
        "    print(f\"{i+1}: {repr(lines[i])}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wMXVH8lkwT3P",
        "outputId": "baf1cc70-6dd6-4d64-8532-43d8aa740266"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "EXTRACTING FEATURES FROM REAL DATA\n",
            "============================================================\n",
            "✓ Extracted 10 task features\n",
            "✓ Features: 19\n",
            "\n",
            "============================================================\n",
            "TOP FEATURES CORRELATED WITH COMPUTE\n",
            "============================================================\n",
            "stack_trace_lines    0.580170\n",
            "has_class_name       0.426346\n",
            "mentions_test        0.421395\n",
            "has_traceback        0.377168\n",
            "has_import           0.351709\n",
            "has_error            0.337863\n",
            "has_function_name    0.276330\n",
            "code_block_count     0.245548\n",
            "repo_task_count      0.223526\n",
            "has_code_block       0.223526\n",
            "Name: tokens_used, dtype: float64\n",
            "\n",
            "✓ Saved: /content/drive/MyDrive/adaptive-swe-agent/data/task_features_real.csv\n"
          ]
        }
      ],
      "source": [
        "# -----------------------------------------------------------------------------\n",
        "# CELL 9: Real Feature Extraction\n",
        "# -----------------------------------------------------------------------------\n",
        "\n",
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import os\n",
        "\n",
        "def extract_code_metrics(problem_statement):\n",
        "    \"\"\"Extract concrete, measurable metrics from problem statement\"\"\"\n",
        "\n",
        "    return {\n",
        "        # Text complexity\n",
        "        'char_count': len(problem_statement),\n",
        "        'word_count': len(problem_statement.split()),\n",
        "        'line_count': len(problem_statement.split('\\n')),\n",
        "        'avg_word_length': np.mean([len(w) for w in problem_statement.split()]) if problem_statement.split() else 0,\n",
        "\n",
        "        # Content indicators\n",
        "        'has_code_block': int('```' in problem_statement),\n",
        "        'code_block_count': problem_statement.count('```') // 2,\n",
        "        'has_traceback': int('traceback' in problem_statement.lower()),\n",
        "        'has_error': int('error' in problem_statement.lower()),\n",
        "        'has_exception': int('exception' in problem_statement.lower()),\n",
        "\n",
        "        # Complexity keywords\n",
        "        'mentions_multiple_files': int(problem_statement.lower().count('file') > 1),\n",
        "        'mentions_test': int('test' in problem_statement.lower()),\n",
        "        'mentions_regression': int('regression' in problem_statement.lower()),\n",
        "        'mentions_version': int('version' in problem_statement.lower()),\n",
        "\n",
        "        # Technical indicators\n",
        "        'has_function_name': int('def ' in problem_statement or '()' in problem_statement),\n",
        "        'has_class_name': int('class ' in problem_statement),\n",
        "        'has_import': int('import ' in problem_statement),\n",
        "        'stack_trace_lines': problem_statement.count('File \"'),\n",
        "    }\n",
        "\n",
        "def extract_repo_features(repo_name, all_tasks):\n",
        "    \"\"\"Extract repository features from dataset distribution (no hardcoding)\"\"\"\n",
        "\n",
        "    repo_tasks = [t for t in all_tasks if t['repo'] == repo_name]\n",
        "\n",
        "    return {\n",
        "        'repo_task_count': len(repo_tasks),\n",
        "        'repo_prevalence': len(repo_tasks) / len(all_tasks) if all_tasks else 0,\n",
        "    }\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"EXTRACTING FEATURES FROM REAL DATA\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Load data\n",
        "with open(f\"{PROJECT_DIR}/data/swebench_subset_10.jsonl\") as f:\n",
        "    tasks = [json.loads(line) for line in f]\n",
        "\n",
        "with open(f\"{PROJECT_DIR}/data/swebench_lite.jsonl\") as f:\n",
        "    all_tasks = [json.loads(line) for line in f]\n",
        "\n",
        "df_baseline = pd.read_csv(f\"{PROJECT_DIR}/results/baseline_summary.csv\")\n",
        "\n",
        "# Extract features for each task\n",
        "features_list = []\n",
        "\n",
        "for task in tasks:\n",
        "    problem_metrics = extract_code_metrics(task['problem_statement'])\n",
        "    repo_features = extract_repo_features(task['repo'], all_tasks)\n",
        "    baseline = df_baseline[df_baseline['instance_id'] == task['instance_id']].iloc[0]\n",
        "\n",
        "    feature_dict = {\n",
        "        'instance_id': task['instance_id'],\n",
        "        'repo': task['repo'],\n",
        "        **problem_metrics,\n",
        "        **repo_features,\n",
        "        'tokens_used': baseline['tokens_used'],\n",
        "        'duration': baseline['duration'],\n",
        "        'patch_length': baseline['patch_length'],\n",
        "    }\n",
        "\n",
        "    features_list.append(feature_dict)\n",
        "\n",
        "df_features = pd.DataFrame(features_list)\n",
        "df_features.to_csv(f\"{PROJECT_DIR}/data/task_features_real.csv\", index=False)\n",
        "\n",
        "print(f\"✓ Extracted {len(df_features)} task features\")\n",
        "print(f\"✓ Features: {len([c for c in df_features.columns if c not in ['instance_id', 'repo', 'tokens_used', 'duration', 'patch_length']])}\")\n",
        "\n",
        "# Show correlations\n",
        "feature_cols = [c for c in df_features.columns if c not in\n",
        "                ['instance_id', 'repo', 'tokens_used', 'duration', 'patch_length']]\n",
        "\n",
        "correlations = df_features[feature_cols + ['tokens_used']].corr()['tokens_used'].drop('tokens_used')\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"TOP FEATURES CORRELATED WITH COMPUTE\")\n",
        "print(\"=\"*60)\n",
        "print(correlations.abs().sort_values(ascending=False).head(10))\n",
        "\n",
        "print(f\"\\n✓ Saved: {PROJECT_DIR}/data/task_features_real.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tOOFZSOU5_rs",
        "outputId": "ae04bb0d-83b0-425e-cd8f-c452d1669725"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "TRAINING COMPLEXITY PREDICTOR\n",
            "============================================================\n",
            "Samples: 10, Features: 19\n",
            "Target range: 3753 - 8989 tokens\n",
            "\n",
            "============================================================\n",
            "5-FOLD CROSS-VALIDATION\n",
            "============================================================\n",
            "Random Forest: R² = -16.200 (+/- 15.983)\n",
            "Gradient Boosting: R² = -39.598 (+/- 53.256)\n",
            "\n",
            "Training final model: RandomForestRegressor\n",
            "R²: 0.727\n",
            "RMSE: 829.1 tokens\n",
            "MAE: 703.9 tokens\n",
            "\n",
            "============================================================\n",
            "TOP 10 FEATURES\n",
            "============================================================\n",
            "                feature  importance\n",
            "        avg_word_length    0.288553\n",
            "             word_count    0.178078\n",
            "      stack_trace_lines    0.108005\n",
            "             line_count    0.089755\n",
            "             char_count    0.084815\n",
            "         has_class_name    0.067982\n",
            "       code_block_count    0.061766\n",
            "          mentions_test    0.029244\n",
            "        repo_prevalence    0.027302\n",
            "mentions_multiple_files    0.016037\n",
            "\n",
            "✓ Models saved to /content/drive/MyDrive/adaptive-swe-agent/models/\n",
            "\n",
            "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
            "⚠️  Training on 10 samples - expand to 50+ for production\n",
            "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n"
          ]
        }
      ],
      "source": [
        "# -----------------------------------------------------------------------------\n",
        "# CELL 10: Train Complexity Predictor with Cross-Validation\n",
        "# -----------------------------------------------------------------------------\n",
        "\n",
        "from sklearn.model_selection import cross_val_score, KFold\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
        "import joblib\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"TRAINING COMPLEXITY PREDICTOR\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Load features\n",
        "df = pd.read_csv(f\"{PROJECT_DIR}/data/task_features_real.csv\")\n",
        "\n",
        "feature_cols = [c for c in df.columns if c not in\n",
        "                ['instance_id', 'repo', 'tokens_used', 'duration', 'patch_length']]\n",
        "\n",
        "X = df[feature_cols].values\n",
        "y = df['tokens_used'].values\n",
        "\n",
        "print(f\"Samples: {len(X)}, Features: {len(feature_cols)}\")\n",
        "print(f\"Target range: {y.min():.0f} - {y.max():.0f} tokens\")\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Cross-validation\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"5-FOLD CROSS-VALIDATION\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "models = {\n",
        "    'Random Forest': RandomForestRegressor(n_estimators=100, max_depth=5, random_state=42),\n",
        "    'Gradient Boosting': GradientBoostingRegressor(n_estimators=100, max_depth=3, random_state=42)\n",
        "}\n",
        "\n",
        "best_model = None\n",
        "best_score = -np.inf\n",
        "\n",
        "for name, model in models.items():\n",
        "    scores = cross_val_score(model, X_scaled, y, cv=kfold, scoring='r2', n_jobs=-1)\n",
        "    print(f\"{name}: R² = {scores.mean():.3f} (+/- {scores.std():.3f})\")\n",
        "\n",
        "    if scores.mean() > best_score:\n",
        "        best_score = scores.mean()\n",
        "        best_model = model\n",
        "\n",
        "# Train final model\n",
        "print(f\"\\nTraining final model: {type(best_model).__name__}\")\n",
        "best_model.fit(X_scaled, y)\n",
        "y_pred = best_model.predict(X_scaled)\n",
        "\n",
        "print(f\"R²: {r2_score(y, y_pred):.3f}\")\n",
        "print(f\"RMSE: {np.sqrt(mean_squared_error(y, y_pred)):.1f} tokens\")\n",
        "print(f\"MAE: {mean_absolute_error(y, y_pred):.1f} tokens\")\n",
        "\n",
        "# Feature importance\n",
        "if hasattr(best_model, 'feature_importances_'):\n",
        "    importance = pd.DataFrame({\n",
        "        'feature': feature_cols,\n",
        "        'importance': best_model.feature_importances_\n",
        "    }).sort_values('importance', ascending=False)\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"TOP 10 FEATURES\")\n",
        "    print(\"=\"*60)\n",
        "    print(importance.head(10).to_string(index=False))\n",
        "\n",
        "# Save\n",
        "joblib.dump(best_model, f\"{PROJECT_DIR}/models/complexity_predictor.pkl\")\n",
        "joblib.dump(scaler, f\"{PROJECT_DIR}/models/feature_scaler.pkl\")\n",
        "joblib.dump(feature_cols, f\"{PROJECT_DIR}/models/feature_names.pkl\")\n",
        "\n",
        "print(f\"\\n✓ Models saved to {PROJECT_DIR}/models/\")\n",
        "\n",
        "print(\"\\n\" + \"!\"*60)\n",
        "print(\"⚠️  Training on 10 samples - expand to 50+ for production\")\n",
        "print(\"!\"*60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "24-O7lLU6L0p"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "619lkxKx-vwd",
        "outputId": "17a17f7f-119b-4991-a66b-7373519cdf0b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "CREATING 50-TASK SUBSET\n",
            "============================================================\n",
            "Total tasks available: 300\n",
            "Unique repositories: 12\n",
            "\n",
            "✓ Created subset with 50 tasks\n",
            "✓ Saved: /content/drive/MyDrive/adaptive-swe-agent/data/swebench_subset_50.jsonl\n",
            "\n",
            "============================================================\n",
            "REPOSITORY DISTRIBUTION\n",
            "============================================================\n",
            "  django/django: 5 tasks\n",
            "  sympy/sympy: 5 tasks\n",
            "  matplotlib/matplotlib: 5 tasks\n",
            "  scikit-learn/scikit-learn: 5 tasks\n",
            "  pytest-dev/pytest: 5 tasks\n",
            "  sphinx-doc/sphinx: 5 tasks\n",
            "  astropy/astropy: 5 tasks\n",
            "  psf/requests: 5 tasks\n",
            "  pylint-dev/pylint: 5 tasks\n",
            "  pydata/xarray: 5 tasks\n",
            "\n",
            "Total unique repos: 10\n",
            "Avg tasks per repo: 5.0\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# CELL A: Create 50-task subset with good diversity\n",
        "# =============================================================================\n",
        "\n",
        "import json\n",
        "import random\n",
        "from collections import defaultdict, Counter\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"CREATING 50-TASK SUBSET\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Load full dataset\n",
        "with open(f\"{PROJECT_DIR}/data/swebench_lite.jsonl\") as f:\n",
        "    all_tasks = [json.loads(line) for line in f]\n",
        "\n",
        "print(f\"Total tasks available: {len(all_tasks)}\")\n",
        "\n",
        "# Group by repository\n",
        "tasks_by_repo = defaultdict(list)\n",
        "for task in all_tasks:\n",
        "    tasks_by_repo[task['repo']].append(task)\n",
        "\n",
        "print(f\"Unique repositories: {len(tasks_by_repo)}\")\n",
        "\n",
        "# Strategy: Sample up to 5 tasks per repo for diversity\n",
        "selected_tasks = []\n",
        "random.seed(42)  # Reproducibility\n",
        "\n",
        "# Sort repos by number of tasks (prioritize diverse repos)\n",
        "sorted_repos = sorted(tasks_by_repo.items(), key=lambda x: len(x[1]), reverse=True)\n",
        "\n",
        "for repo, repo_tasks in sorted_repos:\n",
        "    # Take up to 5 tasks from each repo\n",
        "    sample_size = min(5, len(repo_tasks))\n",
        "    sampled = random.sample(repo_tasks, sample_size)\n",
        "    selected_tasks.extend(sampled)\n",
        "\n",
        "    if len(selected_tasks) >= 50:\n",
        "        break\n",
        "\n",
        "# Take exactly 50\n",
        "selected_tasks = selected_tasks[:50]\n",
        "\n",
        "# Save subset\n",
        "subset_file = f\"{PROJECT_DIR}/data/swebench_subset_50.jsonl\"\n",
        "with open(subset_file, 'w') as f:\n",
        "    for task in selected_tasks:\n",
        "        f.write(json.dumps(task) + '\\n')\n",
        "\n",
        "print(f\"\\n✓ Created subset with {len(selected_tasks)} tasks\")\n",
        "print(f\"✓ Saved: {subset_file}\")\n",
        "\n",
        "# Show distribution\n",
        "repo_counts = Counter(t['repo'] for t in selected_tasks)\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"REPOSITORY DISTRIBUTION\")\n",
        "print(\"=\"*60)\n",
        "for repo, count in repo_counts.most_common(15):\n",
        "    print(f\"  {repo}: {count} tasks\")\n",
        "\n",
        "print(f\"\\nTotal unique repos: {len(repo_counts)}\")\n",
        "print(f\"Avg tasks per repo: {len(selected_tasks) / len(repo_counts):.1f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sak8eLLB-wpu",
        "outputId": "be0c7838-a8b0-46cf-cb02-58f261fdb0f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "RUNNING BASELINE ON 50 TASKS\n",
            "============================================================\n",
            "Estimated time: 25-30 minutes\n",
            "You can monitor progress below\n",
            "============================================================\n",
            "\n",
            "\n",
            "[1/50] django__django-15213\n",
            "Repo: django/django\n",
            "  Cloning django/django ...\n",
            "  ✓ Ready at commit 03cadb91\n",
            "  ✓ Completed in 16.7s\n",
            "  Patch: Yes (2116 chars)\n",
            "  Tokens: 7563\n",
            "\n",
            "[2/50] django__django-11630\n",
            "Repo: django/django\n",
            "  Cloning django/django ...\n",
            "  ✓ Ready at commit 65e86948\n",
            "  ✓ Completed in 8.7s\n",
            "  Patch: Yes (3470 chars)\n",
            "  Tokens: 3343\n",
            "\n",
            "[3/50] django__django-11019\n",
            "Repo: django/django\n",
            "  Cloning django/django ...\n",
            "  ✓ Ready at commit 93e892bb\n",
            "  ✓ Completed in 7.0s\n",
            "  Patch: Yes (1939 chars)\n",
            "  Tokens: 5629\n",
            "\n",
            "[4/50] django__django-15819\n",
            "Repo: django/django\n",
            "  Cloning django/django ...\n",
            "  ✓ Ready at commit 877c800f\n",
            "  ✓ Completed in 5.9s\n",
            "  Patch: Yes (2209 chars)\n",
            "  Tokens: 2886\n",
            "\n",
            "[5/50] django__django-12747\n",
            "Repo: django/django\n",
            "  Cloning django/django ...\n",
            "  ✓ Ready at commit c86201b6\n",
            "  ✓ Completed in 6.6s\n",
            "  Patch: Yes (2108 chars)\n",
            "  Tokens: 3488\n",
            "\n",
            "[6/50] sympy__sympy-15678\n",
            "Repo: sympy/sympy\n",
            "  Cloning sympy/sympy ...\n",
            "  ✓ Ready at commit 31c68eef\n",
            "  ✓ Completed in 5.2s\n",
            "  Patch: Yes (1339 chars)\n",
            "  Tokens: 3790\n",
            "\n",
            "[7/50] sympy__sympy-15345\n",
            "Repo: sympy/sympy\n",
            "  Cloning sympy/sympy ...\n",
            "  ✓ Ready at commit 9ef28fba\n",
            "  ✓ Completed in 5.9s\n",
            "  Patch: Yes (1877 chars)\n",
            "  Tokens: 3445\n",
            "\n",
            "[8/50] sympy__sympy-13895\n",
            "Repo: sympy/sympy\n",
            "  Cloning sympy/sympy ...\n",
            "  ✓ Ready at commit 4da0b645\n",
            "  ✓ Completed in 3.5s\n",
            "  Patch: Yes (627 chars)\n",
            "  Tokens: 3187\n",
            "\n",
            "[9/50] sympy__sympy-13471\n",
            "Repo: sympy/sympy\n",
            "  Cloning sympy/sympy ...\n",
            "  ✓ Ready at commit 3546ac7e\n",
            "  ✓ Completed in 2.6s\n",
            "  Patch: Yes (621 chars)\n",
            "  Tokens: 3807\n",
            "\n",
            "[10/50] sympy__sympy-23117\n",
            "Repo: sympy/sympy\n",
            "  Cloning sympy/sympy ...\n",
            "  ✓ Ready at commit c5cef249\n",
            "  ✓ Completed in 9.2s\n",
            "  Patch: Yes (3188 chars)\n",
            "  Tokens: 3944\n",
            "\n",
            "============================================================\n",
            "PROGRESS: 10/50 complete (20%)\n",
            "Elapsed: 3.7 min, Remaining: 14.6 min\n",
            "============================================================\n",
            "\n",
            "[11/50] matplotlib__matplotlib-22835\n",
            "Repo: matplotlib/matplotlib\n",
            "  Cloning matplotlib/matplotlib ...\n",
            "  ✓ Ready at commit c33557d1\n",
            "  ✓ Completed in 4.4s\n",
            "  Patch: Yes (1575 chars)\n",
            "  Tokens: 3256\n",
            "\n",
            "[12/50] matplotlib__matplotlib-25433\n",
            "Repo: matplotlib/matplotlib\n",
            "  Cloning matplotlib/matplotlib ...\n",
            "  ✓ Ready at commit 7eafdd8a\n",
            "  ✓ Completed in 8.1s\n",
            "  Patch: Yes (2223 chars)\n",
            "  Tokens: 3286\n",
            "\n",
            "[13/50] matplotlib__matplotlib-24334\n",
            "Repo: matplotlib/matplotlib\n",
            "  Cloning matplotlib/matplotlib ...\n",
            "  ✓ Ready at commit 33293799\n",
            "  ✓ Completed in 3.8s\n",
            "  Patch: Yes (1150 chars)\n",
            "  Tokens: 4178\n",
            "\n",
            "[14/50] matplotlib__matplotlib-22711\n",
            "Repo: matplotlib/matplotlib\n",
            "  Cloning matplotlib/matplotlib ...\n",
            "  ✓ Ready at commit f670fe78\n",
            "  ✓ Completed in 5.4s\n",
            "  Patch: Yes (1507 chars)\n",
            "  Tokens: 3989\n",
            "\n",
            "[15/50] matplotlib__matplotlib-18869\n",
            "Repo: matplotlib/matplotlib\n",
            "  Cloning matplotlib/matplotlib ...\n",
            "  ✓ Ready at commit b7d05919\n",
            "  ✓ Completed in 6.0s\n",
            "  Patch: Yes (1528 chars)\n",
            "  Tokens: 3983\n",
            "\n",
            "[16/50] scikit-learn__scikit-learn-10949\n",
            "Repo: scikit-learn/scikit-learn\n",
            "  Cloning scikit-learn/scikit-learn ...\n",
            "  ✓ Ready at commit 3b5abf76\n",
            "  ✓ Completed in 8.0s\n",
            "  Patch: Yes (3129 chars)\n",
            "  Tokens: 5452\n",
            "\n",
            "[17/50] scikit-learn__scikit-learn-13142\n",
            "Repo: scikit-learn/scikit-learn\n",
            "  Cloning scikit-learn/scikit-learn ...\n",
            "  ✓ Ready at commit 1c8668b0\n",
            "  ✓ Completed in 4.4s\n",
            "  Patch: Yes (883 chars)\n",
            "  Tokens: 5467\n",
            "\n",
            "[18/50] scikit-learn__scikit-learn-13241\n",
            "Repo: scikit-learn/scikit-learn\n",
            "  Cloning scikit-learn/scikit-learn ...\n",
            "  ✓ Ready at commit f8b108d0\n",
            "  ✓ Completed in 3.5s\n",
            "  Patch: Yes (802 chars)\n",
            "  Tokens: 4213\n",
            "\n",
            "[19/50] scikit-learn__scikit-learn-14983\n",
            "Repo: scikit-learn/scikit-learn\n",
            "  Cloning scikit-learn/scikit-learn ...\n",
            "  ✓ Ready at commit 06632c0d\n",
            "  ✓ Completed in 2.8s\n",
            "  Patch: Yes (829 chars)\n",
            "  Tokens: 8505\n",
            "\n",
            "[20/50] scikit-learn__scikit-learn-25500\n",
            "Repo: scikit-learn/scikit-learn\n",
            "  Cloning scikit-learn/scikit-learn ...\n",
            "  ✓ Ready at commit 4db04923\n",
            "  ✓ Completed in 8.8s\n",
            "  Patch: Yes (2521 chars)\n",
            "  Tokens: 4404\n",
            "\n",
            "============================================================\n",
            "PROGRESS: 20/50 complete (40%)\n",
            "Elapsed: 7.1 min, Remaining: 10.7 min\n",
            "============================================================\n",
            "\n",
            "[21/50] pytest-dev__pytest-11143\n",
            "Repo: pytest-dev/pytest\n",
            "  Cloning pytest-dev/pytest ...\n",
            "  ✓ Ready at commit 6995257c\n",
            "  ✓ Completed in 4.2s\n",
            "  Patch: Yes (1376 chars)\n",
            "  Tokens: 6281\n",
            "\n",
            "[22/50] pytest-dev__pytest-5495\n",
            "Repo: pytest-dev/pytest\n",
            "  Cloning pytest-dev/pytest ...\n",
            "  ✓ Ready at commit 1aefb24b\n",
            "  ✓ Completed in 3.6s\n",
            "  Patch: Yes (896 chars)\n",
            "  Tokens: 2911\n",
            "\n",
            "[23/50] pytest-dev__pytest-7373\n",
            "Repo: pytest-dev/pytest\n",
            "  Cloning pytest-dev/pytest ...\n",
            "  ✓ Ready at commit 7b77fc08\n",
            "  ✓ Completed in 5.5s\n",
            "  Patch: Yes (1763 chars)\n",
            "  Tokens: 2668\n",
            "\n",
            "[24/50] pytest-dev__pytest-7220\n",
            "Repo: pytest-dev/pytest\n",
            "  Cloning pytest-dev/pytest ...\n",
            "  ✓ Ready at commit 56bf819c\n",
            "  ✓ Completed in 4.4s\n",
            "  Patch: Yes (1644 chars)\n",
            "  Tokens: 3524\n",
            "\n",
            "[25/50] pytest-dev__pytest-8365\n",
            "Repo: pytest-dev/pytest\n",
            "  Cloning pytest-dev/pytest ...\n",
            "  ✓ Ready at commit 4964b468\n",
            "  ✓ Completed in 5.3s\n",
            "  Patch: Yes (1893 chars)\n",
            "  Tokens: 4222\n",
            "\n",
            "[26/50] sphinx-doc__sphinx-8713\n",
            "Repo: sphinx-doc/sphinx\n",
            "  Cloning sphinx-doc/sphinx ...\n",
            "  ✓ Ready at commit 3ed7590e\n",
            "  ✓ Completed in 13.4s\n",
            "  Patch: Yes (3501 chars)\n",
            "  Tokens: 4733\n",
            "\n",
            "[27/50] sphinx-doc__sphinx-7686\n",
            "Repo: sphinx-doc/sphinx\n",
            "  Cloning sphinx-doc/sphinx ...\n",
            "  ✓ Ready at commit 752d3285\n",
            "  ✓ Completed in 3.0s\n",
            "  Patch: Yes (964 chars)\n",
            "  Tokens: 3555\n",
            "\n",
            "[28/50] sphinx-doc__sphinx-8282\n",
            "Repo: sphinx-doc/sphinx\n",
            "  Cloning sphinx-doc/sphinx ...\n",
            "  ✓ Ready at commit 2c2335bb\n",
            "  ✓ Completed in 5.8s\n",
            "  Patch: Yes (2232 chars)\n",
            "  Tokens: 7836\n",
            "\n",
            "[29/50] sphinx-doc__sphinx-8474\n",
            "Repo: sphinx-doc/sphinx\n",
            "  Cloning sphinx-doc/sphinx ...\n",
            "  ✓ Ready at commit 3ea1ec84\n",
            "  ✓ Completed in 7.5s\n",
            "  Patch: Yes (2736 chars)\n",
            "  Tokens: 3717\n",
            "\n",
            "[30/50] sphinx-doc__sphinx-7738\n",
            "Repo: sphinx-doc/sphinx\n",
            "  Cloning sphinx-doc/sphinx ...\n",
            "  ✓ Ready at commit c087d717\n",
            "  ✓ Completed in 3.7s\n",
            "  Patch: Yes (1364 chars)\n",
            "  Tokens: 3026\n",
            "\n",
            "============================================================\n",
            "PROGRESS: 30/50 complete (60%)\n",
            "Elapsed: 8.9 min, Remaining: 5.9 min\n",
            "============================================================\n",
            "\n",
            "[31/50] astropy__astropy-12907\n",
            "Repo: astropy/astropy\n",
            "  Cloning astropy/astropy ...\n",
            "  ✓ Ready at commit d16bfe05\n",
            "  ✓ Completed in 6.5s\n",
            "  Patch: Yes (1240 chars)\n",
            "  Tokens: 3062\n",
            "\n",
            "[32/50] astropy__astropy-14182\n",
            "Repo: astropy/astropy\n",
            "  Cloning astropy/astropy ...\n",
            "  ✓ Ready at commit a5917978\n",
            "  ✓ Completed in 38.0s\n",
            "  Patch: No (0 chars)\n",
            "  Tokens: 8989\n",
            "\n",
            "[33/50] astropy__astropy-14995\n",
            "Repo: astropy/astropy\n",
            "  Cloning astropy/astropy ...\n",
            "  ✓ Ready at commit b16c7d12\n",
            "  ✓ Completed in 7.1s\n",
            "  Patch: Yes (1745 chars)\n",
            "  Tokens: 6206\n",
            "\n",
            "[34/50] astropy__astropy-6938\n",
            "Repo: astropy/astropy\n",
            "  Cloning astropy/astropy ...\n",
            "  ✓ Ready at commit c76af9ed\n",
            "  ✓ Completed in 4.6s\n",
            "  Patch: Yes (1240 chars)\n",
            "  Tokens: 7634\n",
            "\n",
            "[35/50] astropy__astropy-14365\n",
            "Repo: astropy/astropy\n",
            "  Cloning astropy/astropy ...\n",
            "  ✓ Ready at commit 7269fa3e\n",
            "  ✓ Completed in 3.1s\n",
            "  Patch: Yes (478 chars)\n",
            "  Tokens: 3909\n",
            "\n",
            "[36/50] psf__requests-2148\n",
            "Repo: psf/requests\n",
            "  Cloning psf/requests ...\n",
            "  ✓ Ready at commit fe693c49\n",
            "  ✓ Completed in 4.4s\n",
            "  Patch: Yes (1559 chars)\n",
            "  Tokens: 3525\n",
            "\n",
            "[37/50] psf__requests-863\n",
            "Repo: psf/requests\n",
            "  Cloning psf/requests ...\n",
            "  ✓ Ready at commit a0df2cbb\n",
            "  ✓ Completed in 2.2s\n",
            "  Patch: Yes (394 chars)\n",
            "  Tokens: 2560\n",
            "\n",
            "[38/50] psf__requests-2317\n",
            "Repo: psf/requests\n",
            "  Cloning psf/requests ...\n",
            "  ✓ Ready at commit 091991be\n",
            "  ✓ Completed in 3.6s\n",
            "  Patch: Yes (993 chars)\n",
            "  Tokens: 2922\n",
            "\n",
            "[39/50] psf__requests-1963\n",
            "Repo: psf/requests\n",
            "  Cloning psf/requests ...\n",
            "  ✓ Ready at commit 110048f9\n",
            "  ✓ Completed in 6.5s\n",
            "  Patch: Yes (2231 chars)\n",
            "  Tokens: 3026\n",
            "\n",
            "[40/50] psf__requests-2674\n",
            "Repo: psf/requests\n",
            "  Cloning psf/requests ...\n",
            "  ✓ Ready at commit 0be38a0c\n",
            "  ✓ Completed in 7.0s\n",
            "  Patch: Yes (2277 chars)\n",
            "  Tokens: 2892\n",
            "\n",
            "============================================================\n",
            "PROGRESS: 40/50 complete (80%)\n",
            "Elapsed: 11.3 min, Remaining: 2.8 min\n",
            "============================================================\n",
            "\n",
            "[41/50] pylint-dev__pylint-7114\n",
            "Repo: pylint-dev/pylint\n",
            "  Cloning pylint-dev/pylint ...\n",
            "  ✓ Ready at commit 397c1703\n",
            "  ✓ Completed in 5.9s\n",
            "  Patch: Yes (2139 chars)\n",
            "  Tokens: 4233\n",
            "\n",
            "[42/50] pylint-dev__pylint-5859\n",
            "Repo: pylint-dev/pylint\n",
            "  Cloning pylint-dev/pylint ...\n",
            "  ✓ Ready at commit 182cc539\n",
            "  ✓ Completed in 7.9s\n",
            "  Patch: Yes (1752 chars)\n",
            "  Tokens: 4096\n",
            "\n",
            "[43/50] pylint-dev__pylint-7080\n",
            "Repo: pylint-dev/pylint\n",
            "  Cloning pylint-dev/pylint ...\n",
            "  ✓ Ready at commit 3c5eca2d\n",
            "  ✓ Completed in 30.3s\n",
            "  Patch: Yes (12747 chars)\n",
            "  Tokens: 13231\n",
            "\n",
            "[44/50] pylint-dev__pylint-6506\n",
            "Repo: pylint-dev/pylint\n",
            "  Cloning pylint-dev/pylint ...\n",
            "  ✓ Ready at commit 0a4204fd\n",
            "  ✓ Completed in 13.5s\n",
            "  Patch: Yes (1475 chars)\n",
            "  Tokens: 3257\n",
            "\n",
            "[45/50] pylint-dev__pylint-7993\n",
            "Repo: pylint-dev/pylint\n",
            "  Cloning pylint-dev/pylint ...\n",
            "  ✓ Ready at commit e9070207\n",
            "  ✓ Completed in 21.8s\n",
            "  Patch: Yes (6088 chars)\n",
            "  Tokens: 4424\n",
            "\n",
            "[46/50] pydata__xarray-3364\n",
            "Repo: pydata/xarray\n",
            "  Cloning pydata/xarray ...\n",
            "  ✓ Ready at commit 863e4906\n",
            "  ✓ Completed in 10.9s\n",
            "  Patch: Yes (4036 chars)\n",
            "  Tokens: 3693\n",
            "\n",
            "[47/50] pydata__xarray-4493\n",
            "Repo: pydata/xarray\n",
            "  Cloning pydata/xarray ...\n",
            "  ✓ Ready at commit a5f53e20\n",
            "  ✓ Completed in 5.9s\n",
            "  Patch: Yes (1625 chars)\n",
            "  Tokens: 4741\n",
            "\n",
            "[48/50] pydata__xarray-4248\n",
            "Repo: pydata/xarray\n",
            "  Cloning pydata/xarray ...\n",
            "  ✓ Ready at commit 98dc1f4e\n",
            "  ✓ Completed in 3.7s\n",
            "  Patch: Yes (596 chars)\n",
            "  Tokens: 1616\n",
            "\n",
            "[49/50] pydata__xarray-5131\n",
            "Repo: pydata/xarray\n",
            "  Cloning pydata/xarray ...\n",
            "  ✓ Ready at commit e5690588\n",
            "  ✓ Completed in 6.1s\n",
            "  Patch: Yes (1656 chars)\n",
            "  Tokens: 8551\n",
            "\n",
            "[50/50] pydata__xarray-4094\n",
            "Repo: pydata/xarray\n",
            "  Cloning pydata/xarray ...\n",
            "  ✓ Ready at commit a64cf2d5\n",
            "  ✓ Completed in 15.4s\n",
            "  Patch: Yes (4740 chars)\n",
            "  Tokens: 5075\n",
            "\n",
            "============================================================\n",
            "PROGRESS: 50/50 complete (100%)\n",
            "Elapsed: 13.9 min, Remaining: 0.0 min\n",
            "============================================================\n",
            "\n",
            "============================================================\n",
            "50-TASK BASELINE COMPLETE\n",
            "============================================================\n",
            "Total time: 13.9 minutes\n",
            "Tasks completed: 50\n",
            "Patches generated: 49\n",
            "Success rate: 70.0%\n",
            "Avg tokens: 4559\n",
            "Avg time per task: 7.8s\n",
            "Total tokens used: 227930\n",
            "\n",
            "✓ Saved predictions: /content/drive/MyDrive/adaptive-swe-agent/predictions/baseline_subset_50.jsonl\n",
            "✓ Saved results: /content/drive/MyDrive/adaptive-swe-agent/results/baseline_summary_50.csv\n",
            "\n",
            "============================================================\n",
            "TOKEN USAGE DISTRIBUTION\n",
            "============================================================\n",
            "count       50.000000\n",
            "mean      4558.600000\n",
            "std       2105.394141\n",
            "min       1616.000000\n",
            "25%       3264.250000\n",
            "50%       3926.500000\n",
            "75%       4991.500000\n",
            "max      13231.000000\n",
            "Name: tokens_used, dtype: float64\n",
            "\n",
            "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
            "NEXT STEP: Re-run Cells 9-10 to train complexity predictor\n",
            "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# CELL B: Run baseline on 50 tasks (~25-30 minutes)\n",
        "# =============================================================================\n",
        "\n",
        "import json\n",
        "import time\n",
        "import pandas as pd\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"RUNNING BASELINE ON 50 TASKS\")\n",
        "print(\"=\"*60)\n",
        "print(\"Estimated time: 25-30 minutes\")\n",
        "print(\"You can monitor progress below\")\n",
        "print(\"=\"*60 + \"\\n\")\n",
        "\n",
        "# Load tasks\n",
        "with open(f\"{PROJECT_DIR}/data/swebench_subset_50.jsonl\") as f:\n",
        "    tasks = [json.loads(line) for line in f]\n",
        "\n",
        "predictions = []\n",
        "results = []\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "for i, task in enumerate(tasks):\n",
        "    print(f\"\\n[{i+1}/50] {task['instance_id']}\")\n",
        "    print(f\"Repo: {task['repo']}\")\n",
        "\n",
        "    try:\n",
        "        # Setup repository\n",
        "        repo_path = repo_mgr.setup_repository(task['repo'], task['base_commit'])\n",
        "\n",
        "        if not repo_path:\n",
        "            print(\"  ✗ Skipping (repo setup failed)\")\n",
        "            predictions.append({\n",
        "                'instance_id': task['instance_id'],\n",
        "                'model_patch': '',\n",
        "                'model_name_or_path': 'baseline_qwen3b'\n",
        "            })\n",
        "            results.append({\n",
        "                'instance_id': task['instance_id'],\n",
        "                'repo': task['repo'],\n",
        "                'success': False,\n",
        "                'has_patch': False,\n",
        "                'patch_length': 0,\n",
        "                'tokens_used': 0,\n",
        "                'duration': 0\n",
        "            })\n",
        "            continue\n",
        "\n",
        "        # Run agent\n",
        "        task_start = time.time()\n",
        "        result = agent.solve_issue(task, repo_path)\n",
        "        duration = time.time() - task_start\n",
        "\n",
        "        # Save prediction\n",
        "        predictions.append({\n",
        "            'instance_id': task['instance_id'],\n",
        "            'model_patch': result['patch'],\n",
        "            'model_name_or_path': 'baseline_qwen3b'\n",
        "        })\n",
        "\n",
        "        # Save result\n",
        "        results.append({\n",
        "            'instance_id': task['instance_id'],\n",
        "            'repo': task['repo'],\n",
        "            'success': result['success'],\n",
        "            'has_patch': bool(result['patch']),\n",
        "            'patch_length': len(result['patch']),\n",
        "            'tokens_used': result['tokens_used'],\n",
        "            'duration': duration\n",
        "        })\n",
        "\n",
        "        print(f\"  ✓ Completed in {duration:.1f}s\")\n",
        "        print(f\"  Patch: {'Yes' if result['patch'] else 'No'} ({len(result['patch'])} chars)\")\n",
        "        print(f\"  Tokens: {result['tokens_used']}\")\n",
        "\n",
        "        # Progress update every 10 tasks\n",
        "        if (i + 1) % 10 == 0:\n",
        "            elapsed = time.time() - start_time\n",
        "            avg_time = elapsed / (i + 1)\n",
        "            remaining = avg_time * (50 - i - 1)\n",
        "            print(f\"\\n{'='*60}\")\n",
        "            print(f\"PROGRESS: {i+1}/50 complete ({(i+1)/50*100:.0f}%)\")\n",
        "            print(f\"Elapsed: {elapsed/60:.1f} min, Remaining: {remaining/60:.1f} min\")\n",
        "            print(f\"{'='*60}\")\n",
        "\n",
        "        # Cleanup\n",
        "        repo_mgr.cleanup_repository(repo_path)\n",
        "\n",
        "        # Clear GPU cache every 5 tasks\n",
        "        if (i + 1) % 5 == 0:\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"  ✗ Error: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "\n",
        "        predictions.append({\n",
        "            'instance_id': task['instance_id'],\n",
        "            'model_patch': '',\n",
        "            'model_name_or_path': 'baseline_qwen3b'\n",
        "        })\n",
        "        results.append({\n",
        "            'instance_id': task['instance_id'],\n",
        "            'repo': task['repo'],\n",
        "            'success': False,\n",
        "            'has_patch': False,\n",
        "            'patch_length': 0,\n",
        "            'tokens_used': 0,\n",
        "            'duration': 0\n",
        "        })\n",
        "\n",
        "# Save predictions\n",
        "pred_file = f\"{PROJECT_DIR}/predictions/baseline_subset_50.jsonl\"\n",
        "with open(pred_file, 'w') as f:\n",
        "    for pred in predictions:\n",
        "        f.write(json.dumps(pred) + '\\n')\n",
        "\n",
        "# Save results\n",
        "df_results = pd.DataFrame(results)\n",
        "df_results.to_csv(f\"{PROJECT_DIR}/results/baseline_summary_50.csv\", index=False)\n",
        "\n",
        "total_time = time.time() - start_time\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"50-TASK BASELINE COMPLETE\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Total time: {total_time/60:.1f} minutes\")\n",
        "print(f\"Tasks completed: {len(results)}\")\n",
        "print(f\"Patches generated: {df_results['has_patch'].sum()}\")\n",
        "print(f\"Success rate: {df_results['success'].mean():.1%}\")\n",
        "print(f\"Avg tokens: {df_results['tokens_used'].mean():.0f}\")\n",
        "print(f\"Avg time per task: {df_results['duration'].mean():.1f}s\")\n",
        "print(f\"Total tokens used: {df_results['tokens_used'].sum()}\")\n",
        "\n",
        "print(f\"\\n✓ Saved predictions: {pred_file}\")\n",
        "print(f\"✓ Saved results: {PROJECT_DIR}/results/baseline_summary_50.csv\")\n",
        "\n",
        "# Show distribution of token usage\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"TOKEN USAGE DISTRIBUTION\")\n",
        "print(\"=\"*60)\n",
        "print(df_results['tokens_used'].describe())\n",
        "\n",
        "print(\"\\n\" + \"!\"*60)\n",
        "print(\"NEXT STEP: Re-run Cells 9-10 to train complexity predictor\")\n",
        "print(\"!\"*60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z4zFuWnCAzdg",
        "outputId": "b29274ac-16ac-4119-c29f-dfa91f0f08ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "EXTRACTING FEATURES FROM REAL DATA (50 TASKS)\n",
            "============================================================\n",
            "✓ Extracted 50 task features\n",
            "⚠ Missing baseline rows for subset tasks: 0\n",
            "✓ Saved: /content/drive/MyDrive/adaptive-swe-agent/data/task_features_real.csv\n",
            "\n",
            "============================================================\n",
            "TOP FEATURES CORRELATED WITH COMPUTE\n",
            "============================================================\n",
            "word_count                 0.627531\n",
            "char_count                 0.627187\n",
            "line_count                 0.480076\n",
            "avg_word_length            0.423289\n",
            "has_import                 0.312050\n",
            "mentions_test              0.201633\n",
            "has_code_block             0.200955\n",
            "mentions_version           0.162399\n",
            "code_block_count           0.157197\n",
            "mentions_multiple_files    0.133555\n",
            "Name: tokens_used, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "# -----------------------------------------------------------------------------\n",
        "# CELL 9 (SAME FORMAT AS BEFORE): Real Feature Extraction (50-task run)\n",
        "# - Produces: data/task_features_real.csv  (same name as your old cell)\n",
        "# - Prints: top correlations with tokens_used (same behavior)\n",
        "# -----------------------------------------------------------------------------\n",
        "\n",
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "def extract_code_metrics(problem_statement):\n",
        "    \"\"\"Extract concrete, measurable metrics from problem statement\"\"\"\n",
        "    ps = problem_statement or \"\"\n",
        "    words = ps.split()\n",
        "    return {\n",
        "        # Text complexity\n",
        "        'char_count': len(ps),\n",
        "        'word_count': len(words),\n",
        "        'line_count': len(ps.split('\\n')),\n",
        "        'avg_word_length': np.mean([len(w) for w in words]) if words else 0,\n",
        "\n",
        "        # Content indicators\n",
        "        'has_code_block': int('```' in ps),\n",
        "        'code_block_count': ps.count('```') // 2,\n",
        "        'has_traceback': int('traceback' in ps.lower()),\n",
        "        'has_error': int('error' in ps.lower()),\n",
        "        'has_exception': int('exception' in ps.lower()),\n",
        "\n",
        "        # Complexity keywords\n",
        "        'mentions_multiple_files': int(ps.lower().count('file') > 1),\n",
        "        'mentions_test': int('test' in ps.lower()),\n",
        "        'mentions_regression': int('regression' in ps.lower()),\n",
        "        'mentions_version': int('version' in ps.lower()),\n",
        "\n",
        "        # Technical indicators\n",
        "        'has_function_name': int(('def ' in ps) or ('()' in ps)),\n",
        "        'has_class_name': int('class ' in ps),\n",
        "        'has_import': int('import ' in ps),\n",
        "        'stack_trace_lines': ps.count('File \"'),\n",
        "    }\n",
        "\n",
        "def extract_repo_features(repo_name, all_tasks):\n",
        "    \"\"\"Extract repository features from dataset distribution (no hardcoding)\"\"\"\n",
        "    repo_tasks = [t for t in all_tasks if t['repo'] == repo_name]\n",
        "    return {\n",
        "        'repo_task_count': len(repo_tasks),\n",
        "        'repo_prevalence': len(repo_tasks) / len(all_tasks) if all_tasks else 0,\n",
        "    }\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"EXTRACTING FEATURES FROM REAL DATA (50 TASKS)\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Load the *50-task subset* (NOT 10)\n",
        "with open(f\"{PROJECT_DIR}/data/swebench_subset_50.jsonl\") as f:\n",
        "    tasks = [json.loads(line) for line in f]\n",
        "\n",
        "# Full lite dataset for repo prevalence\n",
        "with open(f\"{PROJECT_DIR}/data/swebench_lite.jsonl\") as f:\n",
        "    all_tasks = [json.loads(line) for line in f]\n",
        "\n",
        "# Baseline results from the *50-task run*\n",
        "df_baseline = pd.read_csv(f\"{PROJECT_DIR}/results/baseline_summary_50.csv\")\n",
        "\n",
        "# Safer join (no .iloc[0] crashes)\n",
        "baseline_lookup = {row['instance_id']: row for _, row in df_baseline.iterrows()}\n",
        "\n",
        "features_list = []\n",
        "missing = 0\n",
        "\n",
        "for task in tasks:\n",
        "    iid = task['instance_id']\n",
        "    base = baseline_lookup.get(iid)\n",
        "    if base is None:\n",
        "        missing += 1\n",
        "        continue\n",
        "\n",
        "    problem_metrics = extract_code_metrics(task['problem_statement'])\n",
        "    repo_features = extract_repo_features(task['repo'], all_tasks)\n",
        "\n",
        "    feature_dict = {\n",
        "        'instance_id': iid,\n",
        "        'repo': task['repo'],\n",
        "        **problem_metrics,\n",
        "        **repo_features,\n",
        "        'tokens_used': base.get('tokens_used', 0),\n",
        "        'duration': base.get('duration', 0),\n",
        "        'patch_length': base.get('patch_length', 0),\n",
        "    }\n",
        "    features_list.append(feature_dict)\n",
        "\n",
        "df_features = pd.DataFrame(features_list)\n",
        "\n",
        "# SAME output name as before (so downstream code doesn’t change)\n",
        "out_path = f\"{PROJECT_DIR}/data/task_features_real.csv\"\n",
        "os.makedirs(os.path.dirname(out_path), exist_ok=True)\n",
        "df_features.to_csv(out_path, index=False)\n",
        "\n",
        "print(f\"✓ Extracted {len(df_features)} task features\")\n",
        "print(f\"⚠ Missing baseline rows for subset tasks: {missing}\")\n",
        "print(f\"✓ Saved: {out_path}\")\n",
        "\n",
        "# Show correlations (same behavior as before)\n",
        "feature_cols = [c for c in df_features.columns if c not in\n",
        "                ['instance_id', 'repo', 'tokens_used', 'duration', 'patch_length']]\n",
        "\n",
        "correlations = df_features[feature_cols + ['tokens_used']].corr(numeric_only=True)['tokens_used'].drop('tokens_used')\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"TOP FEATURES CORRELATED WITH COMPUTE\")\n",
        "print(\"=\"*60)\n",
        "print(correlations.abs().sort_values(ascending=False).head(10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "cGuYRbQvJ5nr",
        "outputId": "463f6713-6bcd-40b2-d4f1-7b2d0e18d079"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "TRAINING COMPLEXITY PREDICTOR (50-TASK DATA, SAME FORMAT + PLOTS)\n",
            "============================================================\n",
            "Samples: 50, Features: 19\n",
            "Target range: 1616 - 13231 tokens\n",
            "\n",
            "============================================================\n",
            "5-FOLD CROSS-VALIDATION\n",
            "============================================================\n",
            "Random Forest: R² = -1.028 (+/- 1.054)\n",
            "Gradient Boosting: R² = -1.816 (+/- 2.687)\n",
            "\n",
            "Best model by CV: Random Forest (mean R²=-1.028)\n",
            "Training final model: RandomForestRegressor\n",
            "R²: 0.836\n",
            "RMSE: 843.1 tokens\n",
            "MAE: 644.8 tokens\n",
            "\n",
            "============================================================\n",
            "TOP 10 FEATURES\n",
            "============================================================\n",
            "          feature  importance\n",
            "  avg_word_length    0.258843\n",
            "       word_count    0.212043\n",
            "       line_count    0.200625\n",
            "       char_count    0.168576\n",
            " mentions_version    0.021573\n",
            "  repo_prevalence    0.018813\n",
            "has_function_name    0.018673\n",
            " code_block_count    0.017063\n",
            "  repo_task_count    0.016993\n",
            "    mentions_test    0.014805\n",
            "\n",
            "✓ Models saved to /content/drive/MyDrive/adaptive-swe-agent/models/\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1400x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✓ Saved plot: /content/drive/MyDrive/adaptive-swe-agent/results/complexity_prediction.png\n",
            "\n",
            "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
            "Training on 50 samples - much better than 10\n",
            "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n"
          ]
        }
      ],
      "source": [
        "# -----------------------------------------------------------------------------\n",
        "# CELL 10 (SAME FORMAT + PLOTS): Train Complexity Predictor + visualizations\n",
        "# - Reads: data/task_features_real.csv\n",
        "# - Saves: models/*.pkl (same filenames)\n",
        "# - Prints: CV R² + training metrics + top importances (same style)\n",
        "# - NEW: Adds plots (Predicted vs Actual, Residuals) + saves PNG\n",
        "# -----------------------------------------------------------------------------\n",
        "\n",
        "from sklearn.model_selection import cross_val_score, KFold\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
        "import joblib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"TRAINING COMPLEXITY PREDICTOR (50-TASK DATA, SAME FORMAT + PLOTS)\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Load features (same path as before)\n",
        "df = pd.read_csv(f\"{PROJECT_DIR}/data/task_features_real.csv\")\n",
        "\n",
        "feature_cols = [c for c in df.columns if c not in\n",
        "                ['instance_id', 'repo', 'tokens_used', 'duration', 'patch_length']]\n",
        "\n",
        "X = df[feature_cols].values\n",
        "y = df['tokens_used'].values.astype(float)\n",
        "\n",
        "print(f\"Samples: {len(X)}, Features: {len(feature_cols)}\")\n",
        "print(f\"Target range: {y.min():.0f} - {y.max():.0f} tokens\")\n",
        "\n",
        "# Scale features (same as before)\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"5-FOLD CROSS-VALIDATION\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "models = {\n",
        "    'Random Forest': RandomForestRegressor(n_estimators=100, max_depth=5, random_state=42),\n",
        "    'Gradient Boosting': GradientBoostingRegressor(n_estimators=100, max_depth=3, random_state=42)\n",
        "}\n",
        "\n",
        "best_model = None\n",
        "best_score = -np.inf\n",
        "best_name = None\n",
        "\n",
        "for name, model in models.items():\n",
        "    scores = cross_val_score(model, X_scaled, y, cv=kfold, scoring='r2', n_jobs=-1)\n",
        "    print(f\"{name}: R² = {scores.mean():.3f} (+/- {scores.std():.3f})\")\n",
        "\n",
        "    if scores.mean() > best_score:\n",
        "        best_score = scores.mean()\n",
        "        best_model = model\n",
        "        best_name = name\n",
        "\n",
        "print(f\"\\nBest model by CV: {best_name} (mean R²={best_score:.3f})\")\n",
        "print(f\"Training final model: {type(best_model).__name__}\")\n",
        "\n",
        "best_model.fit(X_scaled, y)\n",
        "y_pred = best_model.predict(X_scaled)\n",
        "\n",
        "r2 = r2_score(y, y_pred)\n",
        "rmse = np.sqrt(mean_squared_error(y, y_pred))\n",
        "mae = mean_absolute_error(y, y_pred)\n",
        "\n",
        "print(f\"R²: {r2:.3f}\")\n",
        "print(f\"RMSE: {rmse:.1f} tokens\")\n",
        "print(f\"MAE: {mae:.1f} tokens\")\n",
        "\n",
        "# Feature importance (same as before)\n",
        "if hasattr(best_model, 'feature_importances_'):\n",
        "    importance = pd.DataFrame({\n",
        "        'feature': feature_cols,\n",
        "        'importance': best_model.feature_importances_\n",
        "    }).sort_values('importance', ascending=False)\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"TOP 10 FEATURES\")\n",
        "    print(\"=\"*60)\n",
        "    print(importance.head(10).to_string(index=False))\n",
        "\n",
        "# Save (same filenames as before)\n",
        "model_dir = f\"{PROJECT_DIR}/models\"\n",
        "os.makedirs(model_dir, exist_ok=True)\n",
        "\n",
        "joblib.dump(best_model, f\"{model_dir}/complexity_predictor.pkl\")\n",
        "joblib.dump(scaler, f\"{model_dir}/feature_scaler.pkl\")\n",
        "joblib.dump(feature_cols, f\"{model_dir}/feature_names.pkl\")\n",
        "\n",
        "print(f\"\\n✓ Models saved to {model_dir}/\")\n",
        "\n",
        "# -----------------------------\n",
        "# NEW: Plots (Predicted vs Actual, Residuals)\n",
        "# -----------------------------\n",
        "results_dir = f\"{PROJECT_DIR}/results\"\n",
        "os.makedirs(results_dir, exist_ok=True)\n",
        "\n",
        "residuals = y - y_pred\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Predicted vs Actual\n",
        "axes[0].scatter(y, y_pred, alpha=0.7, s=50)\n",
        "axes[0].plot([y.min(), y.max()], [y.min(), y.max()], linestyle='--', linewidth=2)\n",
        "axes[0].set_xlabel('Actual Tokens')\n",
        "axes[0].set_ylabel('Predicted Tokens')\n",
        "axes[0].set_title(f'Predicted vs Actual (R²={r2:.3f}, MAE={mae:.0f})')\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "# Residual plot\n",
        "axes[1].scatter(y_pred, residuals, alpha=0.7, s=50)\n",
        "axes[1].axhline(y=0, linestyle='--', linewidth=2)\n",
        "axes[1].set_xlabel('Predicted Tokens')\n",
        "axes[1].set_ylabel('Residuals (Actual - Predicted)')\n",
        "axes[1].set_title('Residual Plot')\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "\n",
        "plot_path = f\"{results_dir}/complexity_prediction.png\"\n",
        "plt.savefig(plot_path, dpi=150)\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\n✓ Saved plot: {plot_path}\")\n",
        "\n",
        "print(\"\\n\" + \"!\"*60)\n",
        "print(\"Training on 50 samples - much better than 10\")\n",
        "print(\"!\"*60)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "arlss3pHK6ed",
        "outputId": "3d606ca8-607c-47de-fcb8-8e19c9a04bf2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Test execution system initialized\n",
            "  This enables test-driven solution selection\n",
            "  Novel contribution: Use test results to pick best solution\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# CELL 11: Test Execution System\n",
        "# =============================================================================\n",
        "\n",
        "import subprocess\n",
        "import tempfile\n",
        "import os\n",
        "\n",
        "class TestExecutor:\n",
        "    \"\"\"Execute tests and provide feedback - KEY INNOVATION\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.test_cache = {}\n",
        "\n",
        "    def apply_patch(self, repo_path, patch):\n",
        "        \"\"\"Apply patch and validate\"\"\"\n",
        "        if not patch or len(patch) < 10:\n",
        "            return False, \"Empty or invalid patch\"\n",
        "\n",
        "        with tempfile.NamedTemporaryFile(mode='w', suffix='.patch', delete=False) as f:\n",
        "            f.write(patch)\n",
        "            patch_file = f.name\n",
        "\n",
        "        try:\n",
        "            # Check if patch is valid\n",
        "            result = subprocess.run(\n",
        "                ['git', 'apply', '--check', patch_file],\n",
        "                cwd=repo_path,\n",
        "                capture_output=True,\n",
        "                text=True,\n",
        "                timeout=10\n",
        "            )\n",
        "\n",
        "            if result.returncode == 0:\n",
        "                # Apply patch\n",
        "                subprocess.run(\n",
        "                    ['git', 'apply', patch_file],\n",
        "                    cwd=repo_path,\n",
        "                    capture_output=True,\n",
        "                    timeout=10\n",
        "                )\n",
        "                return True, \"Patch applied successfully\"\n",
        "            else:\n",
        "                return False, f\"Invalid patch: {result.stderr[:200]}\"\n",
        "\n",
        "        except Exception as e:\n",
        "            return False, f\"Error: {str(e)[:200]}\"\n",
        "        finally:\n",
        "            if os.path.exists(patch_file):\n",
        "                os.unlink(patch_file)\n",
        "\n",
        "    def run_tests(self, repo_path, test_cmd=\"pytest -xvs\"):\n",
        "        \"\"\"Run tests and capture results\"\"\"\n",
        "        try:\n",
        "            result = subprocess.run(\n",
        "                test_cmd.split(),\n",
        "                cwd=repo_path,\n",
        "                capture_output=True,\n",
        "                text=True,\n",
        "                timeout=60\n",
        "            )\n",
        "\n",
        "            return {\n",
        "                'passed': result.returncode == 0,\n",
        "                'stdout': result.stdout[-2000:],  # Last 2000 chars\n",
        "                'stderr': result.stderr[-2000:],\n",
        "                'returncode': result.returncode\n",
        "            }\n",
        "\n",
        "        except subprocess.TimeoutExpired:\n",
        "            return {\n",
        "                'passed': False,\n",
        "                'stdout': '',\n",
        "                'stderr': 'Test execution timed out',\n",
        "                'returncode': -1\n",
        "            }\n",
        "        except Exception as e:\n",
        "            return {\n",
        "                'passed': False,\n",
        "                'stdout': '',\n",
        "                'stderr': str(e),\n",
        "                'returncode': -1\n",
        "            }\n",
        "\n",
        "    def parse_test_feedback(self, test_result):\n",
        "        \"\"\"Extract actionable feedback from test failures\"\"\"\n",
        "        if test_result['passed']:\n",
        "            return \"✓ All tests passed\"\n",
        "\n",
        "        feedback = [\"✗ Tests failed:\"]\n",
        "        output = test_result['stdout'] + test_result['stderr']\n",
        "\n",
        "        # Parse common failure patterns\n",
        "        if 'FAILED' in output:\n",
        "            failed = [line for line in output.split('\\n') if 'FAILED' in line]\n",
        "            feedback.append(f\"  {len(failed)} test(s) failed\")\n",
        "            feedback.extend([f\"  - {f[:80]}\" for f in failed[:3]])\n",
        "\n",
        "        if 'AssertionError' in output:\n",
        "            feedback.append(\"  AssertionError detected\")\n",
        "\n",
        "        if 'SyntaxError' in output:\n",
        "            feedback.append(\"  Syntax error in patch\")\n",
        "\n",
        "        if 'ImportError' in output or 'ModuleNotFoundError' in output:\n",
        "            feedback.append(\"  Import/module error\")\n",
        "\n",
        "        return '\\n'.join(feedback)\n",
        "\n",
        "# Initialize test executor\n",
        "test_executor = TestExecutor()\n",
        "\n",
        "print(\"✓ Test execution system initialized\")\n",
        "print(\"  This enables test-driven solution selection\")\n",
        "print(\"  Novel contribution: Use test results to pick best solution\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ApGsj0huNLfC",
        "outputId": "bb867a5e-3df8-4a10-e564-f893e66cc158"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "PREPARING GROUNDED ADAPTIVE AGENT (GPT-5.1)\n",
            "============================================================\n",
            "\n",
            "============================================================\n",
            "LOADING GROUNDED ADAPTIVE AGENT\n",
            "============================================================\n",
            "✓ Grounded adaptive agent ready\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# CELL 12 (GROUNDED): Adaptive Agent for GPT-5.1\n",
        "# - Baseline-style grounding: infer ONE target file + send real file context\n",
        "# - Best-of-N sampling: N from complexity predictor (or force_n)\n",
        "# - Selection: pick first patch that git apply --check --recount passes\n",
        "# - Fix: expm1 overflow safe handling\n",
        "# - Returns: patch_applied + test_passed (alias) for Cell 13 compatibility\n",
        "# =============================================================================\n",
        "\n",
        "import os\n",
        "import re\n",
        "import json\n",
        "import numpy as np\n",
        "import joblib\n",
        "import subprocess\n",
        "import tempfile\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"PREPARING GROUNDED ADAPTIVE AGENT (GPT-5.1)\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "class AdaptiveAgentGrounded:\n",
        "    def __init__(self, openai_client, complexity_predictor, scaler, feature_names):\n",
        "        self.client = openai_client\n",
        "        self.model = \"gpt-5.1\"\n",
        "        self.predictor = complexity_predictor\n",
        "        self.scaler = scaler\n",
        "        self.feature_names = feature_names\n",
        "\n",
        "        # Load transform config (robust)\n",
        "        try:\n",
        "            self.transform_config = joblib.load(f\"{PROJECT_DIR}/models/transform_config.pkl\")\n",
        "            if not isinstance(self.transform_config, dict):\n",
        "                self.transform_config = {}\n",
        "        except Exception:\n",
        "            self.transform_config = {}\n",
        "\n",
        "        # NOTE: this agent does apply-check (not full tests)\n",
        "        # It will use git apply --check --recount as the \"success\" signal.\n",
        "\n",
        "    # ---------------------------\n",
        "    # Complexity prediction\n",
        "    # ---------------------------\n",
        "    def _use_log_transform(self) -> bool:\n",
        "        return bool(\n",
        "            self.transform_config.get(\"use_log1p\", False) or\n",
        "            self.transform_config.get(\"use_log\", False) or\n",
        "            self.transform_config.get(\"use_log_transform\", False)\n",
        "        )\n",
        "\n",
        "    def predict_complexity(self, problem_statement, repo_name, all_tasks):\n",
        "        metrics = extract_code_metrics(problem_statement)\n",
        "        repo_feat = extract_repo_features(repo_name, all_tasks)\n",
        "\n",
        "        feature_dict = {**metrics, **repo_feat}\n",
        "        X = np.array([[feature_dict.get(f, 0) for f in self.feature_names]], dtype=float)\n",
        "        X_scaled = self.scaler.transform(X)\n",
        "\n",
        "        pred = float(self.predictor.predict(X_scaled)[0])\n",
        "\n",
        "        if self._use_log_transform():\n",
        "            # prevent overflow in expm1 if model outputs absurd values\n",
        "            pred = float(np.clip(pred, -5.0, 12.0))  # expm1(12) ~ 1.6e5 (still huge)\n",
        "            pred_tokens = float(np.expm1(pred))\n",
        "        else:\n",
        "            pred_tokens = pred\n",
        "\n",
        "        return float(np.clip(pred_tokens, 500, 3000))\n",
        "    '''\n",
        "    def determine_n_samples(self, predicted_tokens):\n",
        "        if predicted_tokens < 1000:\n",
        "            return 1\n",
        "        elif predicted_tokens < 1400:\n",
        "            return 3\n",
        "        elif predicted_tokens < 1800:\n",
        "            return 5\n",
        "        else:\n",
        "            return 8\n",
        "    '''\n",
        "\n",
        "    def determine_n_samples(self, prompt_tokens: int) -> int:\n",
        "        # tuned to your shown 50-task token spread\n",
        "        if prompt_tokens < 3000:\n",
        "            return 1\n",
        "        elif prompt_tokens < 4500:\n",
        "            return 3\n",
        "        elif prompt_tokens < 7000:\n",
        "            return 5\n",
        "        else:\n",
        "            return 8\n",
        "\n",
        "\n",
        "\n",
        "    # ---------------------------\n",
        "    # Target file inference (baseline-like)\n",
        "    # ---------------------------\n",
        "    def _is_disallowed_path(self, rel_path: str) -> bool:\n",
        "        if not rel_path:\n",
        "            return True\n",
        "        p = rel_path.replace(\"\\\\\", \"/\")\n",
        "        if p == \"CHANGES.rst\":\n",
        "            return True\n",
        "        if p.startswith(\"docs/\"):\n",
        "            return True\n",
        "        if p.startswith(\"doc/\"):\n",
        "            return True\n",
        "        if \"/docs/\" in p:\n",
        "            return True\n",
        "        if p.startswith(\"tests/\") or p.startswith(\"test/\"):\n",
        "            return True\n",
        "        if \"/tests/\" in p or \"/test/\" in p:\n",
        "            return True\n",
        "        return False\n",
        "\n",
        "    def _infer_target_file(self, task: dict, repo_path: str) -> str | None:\n",
        "        # 1) prefer gold/oracle patch if present (but skip docs/tests/CHANGES)\n",
        "        patch_text = (task.get(\"patch\") or task.get(\"oracle_patch\") or task.get(\"gold_patch\") or \"\")\n",
        "        if patch_text:\n",
        "            m = re.search(r\"diff --git a/(.+?) b/\", patch_text)\n",
        "            if m:\n",
        "                cand = m.group(1).strip()\n",
        "                if cand and not self._is_disallowed_path(cand):\n",
        "                    if os.path.exists(os.path.join(repo_path, cand)):\n",
        "                        return cand\n",
        "\n",
        "        # 2) try path mentions in problem statement\n",
        "        ps = task.get(\"problem_statement\", \"\") or \"\"\n",
        "        candidates = re.findall(r\"([A-Za-z0-9_\\-./]+\\.(?:py|js|ts|java|go|rs|c|cpp|h|hpp))\", ps)\n",
        "        seen = set()\n",
        "        for cand in candidates:\n",
        "            cand = cand.strip()\n",
        "            if cand in seen:\n",
        "                continue\n",
        "            seen.add(cand)\n",
        "            if self._is_disallowed_path(cand):\n",
        "                continue\n",
        "            if os.path.exists(os.path.join(repo_path, cand)):\n",
        "                return cand\n",
        "\n",
        "        # 3) fallback search: best identifier hits in code files (skip docs/tests)\n",
        "        identifiers = re.findall(r\"\\b[A-Za-z_][A-Za-z0-9_]{3,}\\b\", ps)[:12]\n",
        "        stop = {\"this\",\"that\",\"when\",\"then\",\"true\",\"false\",\"none\"}\n",
        "        identifiers = [w for w in identifiers if w.lower() not in stop]\n",
        "\n",
        "        best_file, best_hits = None, 0\n",
        "        for root, dirs, files in os.walk(repo_path):\n",
        "            # skip heavy dirs\n",
        "            if any(x in root for x in [\"/.git/\", \"/venv/\", \"/.venv/\", \"/node_modules/\", \"/dist/\", \"/build/\"]):\n",
        "                continue\n",
        "            # skip docs/tests dirs\n",
        "            rp = root.replace(\"\\\\\", \"/\")\n",
        "            if \"/docs\" in rp or \"/doc\" in rp or \"/tests\" in rp or \"/test\" in rp:\n",
        "                continue\n",
        "\n",
        "            for fn in files:\n",
        "                if not fn.endswith((\".py\",\".js\",\".ts\",\".java\",\".go\",\".rs\",\".c\",\".cpp\",\".h\",\".hpp\")):\n",
        "                    continue\n",
        "                fp = os.path.join(root, fn)\n",
        "                rel = os.path.relpath(fp, repo_path)\n",
        "                if self._is_disallowed_path(rel):\n",
        "                    continue\n",
        "                try:\n",
        "                    with open(fp, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
        "                        txt = f.read()\n",
        "                    hits = sum(1 for w in identifiers if w in txt)\n",
        "                    if hits > best_hits:\n",
        "                        best_hits, best_file = hits, rel\n",
        "                except Exception:\n",
        "                    continue\n",
        "\n",
        "        return best_file\n",
        "\n",
        "    # ---------------------------\n",
        "    # File context builder (HEAD always + keyword windows)\n",
        "    # ---------------------------\n",
        "    def _build_file_context(\n",
        "        self,\n",
        "        problem_statement: str,\n",
        "        repo_path: str,\n",
        "        target_file: str,\n",
        "        head_lines: int = 200,\n",
        "        window_before: int = 140,\n",
        "        window_after: int = 220,\n",
        "        max_context_chars: int = 32000,\n",
        "        max_windows: int = 6,\n",
        "    ) -> str:\n",
        "        abs_path = os.path.join(repo_path, target_file)\n",
        "        if not os.path.exists(abs_path):\n",
        "            return f\"Target file not found: {target_file}\"\n",
        "\n",
        "        with open(abs_path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
        "            lines = f.readlines()\n",
        "\n",
        "        ps = problem_statement or \"\"\n",
        "        identifiers = re.findall(r\"\\b[A-Za-z_][A-Za-z0-9_]{3,}\\b\", ps)[:14]\n",
        "        stop = {\"this\",\"that\",\"when\",\"then\",\"true\",\"false\",\"none\"}\n",
        "        identifiers = [w for w in identifiers if w.lower() not in stop]\n",
        "\n",
        "        hit_idxs = [i for i, ln in enumerate(lines) if any(w in ln for w in identifiers)]\n",
        "        hit_idxs = hit_idxs[:max_windows]\n",
        "\n",
        "        def clamp(v, lo, hi): return max(lo, min(hi, v))\n",
        "\n",
        "        chunks = []\n",
        "        # Always include HEAD\n",
        "        chunks.append((0, min(len(lines), head_lines)))\n",
        "\n",
        "        # Include windows around hits\n",
        "        for idx in hit_idxs:\n",
        "            s = clamp(idx - window_before, 0, len(lines))\n",
        "            e = clamp(idx + window_after, 0, len(lines))\n",
        "            chunks.append((s, e))\n",
        "\n",
        "        # Merge overlapping chunks\n",
        "        chunks.sort()\n",
        "        merged = []\n",
        "        for s, e in chunks:\n",
        "            if not merged or s > merged[-1][1]:\n",
        "                merged.append([s, e])\n",
        "            else:\n",
        "                merged[-1][1] = max(merged[-1][1], e)\n",
        "\n",
        "        # Render with soft char cap\n",
        "        out = [f\"FILE: {target_file}\\n\"]\n",
        "        total = len(out[0])\n",
        "\n",
        "        for s, e in merged:\n",
        "            header = f\"\\n----- LINES {s+1}-{e} -----\\n\"\n",
        "            block = header + \"\".join(lines[s:e])\n",
        "            if total + len(block) > max_context_chars:\n",
        "                # truncate block to fit\n",
        "                remaining = max(0, max_context_chars - total)\n",
        "                if remaining <= len(header) + 50:\n",
        "                    break\n",
        "                block = header + (\"\".join(lines[s:e]))[:(remaining - len(header))]\n",
        "            out.append(block)\n",
        "            total += len(block)\n",
        "            if total >= max_context_chars:\n",
        "                break\n",
        "\n",
        "        return \"\".join(out)\n",
        "\n",
        "    # ---------------------------\n",
        "    # Patch extraction + validation\n",
        "    # ---------------------------\n",
        "    def _extract_patch(self, text: str) -> str:\n",
        "        if not text:\n",
        "            return \"\"\n",
        "        # strip markdown fences\n",
        "        text = re.sub(r\"^\\s*```(?:diff)?\\s*\\n\", \"\", text, flags=re.MULTILINE)\n",
        "        text = re.sub(r\"\\n\\s*```\\s*$\", \"\", text, flags=re.MULTILINE)\n",
        "\n",
        "        m = re.search(r\"(?m)^diff --git \", text)\n",
        "        if not m:\n",
        "            return \"\"\n",
        "        patch = text[m.start():].replace(\"\\r\\n\", \"\\n\").replace(\"\\r\", \"\\n\").strip(\"\\n\") + \"\\n\"\n",
        "        return patch\n",
        "\n",
        "    def _patch_file_count(self, patch: str) -> int:\n",
        "        return patch.count(\"diff --git\")\n",
        "\n",
        "    def _extract_patch_files(self, patch: str):\n",
        "        files = []\n",
        "        for ln in patch.splitlines():\n",
        "            if ln.startswith(\"diff --git\"):\n",
        "                m = re.search(r\"diff --git a/(.+?) b/\", ln)\n",
        "                if m:\n",
        "                    files.append(m.group(1))\n",
        "        return files\n",
        "\n",
        "    def _git_apply_check(self, repo_path: str, patch: str) -> tuple[bool, str]:\n",
        "        if not patch.strip():\n",
        "            return False, \"Empty patch\"\n",
        "\n",
        "        with tempfile.NamedTemporaryFile(mode=\"w\", suffix=\".patch\", delete=False, encoding=\"utf-8\") as f:\n",
        "            f.write(patch)\n",
        "            tmp = f.name\n",
        "\n",
        "        try:\n",
        "            cmd = [\"git\", \"apply\", \"--check\", \"--verbose\", \"--recount\", tmp]\n",
        "            p = subprocess.run(cmd, cwd=repo_path, capture_output=True, text=True)\n",
        "            ok = (p.returncode == 0)\n",
        "            msg = (p.stderr or p.stdout or \"\").strip()\n",
        "            return ok, msg\n",
        "        finally:\n",
        "            try:\n",
        "                os.unlink(tmp)\n",
        "            except Exception:\n",
        "                pass\n",
        "\n",
        "    # ---------------------------\n",
        "    # One grounded LLM call (for ONE target file)\n",
        "    # ---------------------------\n",
        "    def generate_solution_for_target(\n",
        "        self,\n",
        "        problem_statement: str,\n",
        "        target_file: str,\n",
        "        file_context: str,\n",
        "        max_completion_tokens: int = 4096,\n",
        "        temperature: float = 0.7,\n",
        "        strategy_hint: str | None = None,\n",
        "    ) -> tuple[str, int]:\n",
        "        strict = (\n",
        "            f\"STRICT RULES:\\n\"\n",
        "            f\"- You MUST ONLY modify this one file: {target_file}\\n\"\n",
        "            f\"- Do NOT modify tests, docs, CHANGES.rst.\\n\"\n",
        "            f\"- Use EXACT context lines from the provided file snippets.\\n\"\n",
        "        )\n",
        "\n",
        "        system = (\n",
        "            \"You are an expert software engineer. \"\n",
        "            \"Return ONLY a valid unified diff patch. No markdown, no commentary.\"\n",
        "        )\n",
        "\n",
        "        user = (\n",
        "            f\"Fix the bug described below.\\n\\n\"\n",
        "            f\"PROBLEM:\\n{problem_statement}\\n\\n\"\n",
        "            + (f\"STRATEGY HINT:\\n{strategy_hint}\\n\\n\" if strategy_hint else \"\")\n",
        "            + f\"TARGET FILE: {target_file}\\n\\n\"\n",
        "            + strict + \"\\n\"\n",
        "            + \"FILE CONTEXT (ground truth snippets from pinned commit):\\n\"\n",
        "            + file_context + \"\\n\\n\"\n",
        "            + \"OUTPUT REQUIREMENTS:\\n\"\n",
        "            + \"- Output ONLY a unified diff starting with 'diff --git'.\\n\"\n",
        "            + \"- Modify exactly one file (the target file).\\n\"\n",
        "            + \"- Include correct @@ hunk headers.\\n\"\n",
        "            + \"- Reuse EXACT context lines from the snippets.\\n\"\n",
        "        )\n",
        "\n",
        "        resp = self.client.chat.completions.create(\n",
        "            model=self.model,\n",
        "            messages=[{\"role\": \"system\", \"content\": system},\n",
        "                      {\"role\": \"user\", \"content\": user}],\n",
        "            max_completion_tokens=max_completion_tokens,\n",
        "            temperature=temperature,\n",
        "        )\n",
        "        txt = resp.choices[0].message.content or \"\"\n",
        "        tokens = resp.usage.total_tokens if getattr(resp, \"usage\", None) else 0\n",
        "        patch = self._extract_patch(txt)\n",
        "        return patch, tokens\n",
        "\n",
        "    # ---------------------------\n",
        "    # Main solve: adaptive best-of-N (or force_n)\n",
        "    # ---------------------------\n",
        "    def solve_with_feedback(self, task: dict, repo_path: str, all_tasks: list, force_n: int | None = None, stop_early: bool = True):\n",
        "        problem_statement = task.get(\"problem_statement\") or \"\"\n",
        "        repo_name = task.get(\"repo\") or \"\"\n",
        "\n",
        "        target_file = self._infer_target_file(task, repo_path)\n",
        "        if not target_file:\n",
        "            return {\n",
        "                \"patch\": \"\",\n",
        "                \"tokens_used\": 0,\n",
        "                \"n_samples\": 0,\n",
        "                \"attempts_made\": 0,\n",
        "                \"first_apply_index\": None,\n",
        "                \"predicted_tokens\": None,\n",
        "                \"patch_applied\": False,\n",
        "                \"test_passed\": False,\n",
        "                \"success\": False,\n",
        "                \"target_file\": None,\n",
        "                \"apply_stderr\": \"Could not infer target file\",\n",
        "            }\n",
        "\n",
        "        file_context = self._build_file_context(problem_statement, repo_path, target_file)\n",
        "\n",
        "        predicted = self.predict_complexity(problem_statement, repo_name, all_tasks)\n",
        "        n = int(force_n) if force_n is not None else int(self.determine_n_samples(predicted))\n",
        "\n",
        "        print(f\"  target_file: {target_file}\")\n",
        "        print(\n",
        "            f\"  Predicted: {predicted:.0f} tokens → N={n}\"\n",
        "            + (f\" (forced)\" if force_n is not None else \"\")\n",
        "            + (\"\" if stop_early else \" (no-early-stop)\")\n",
        "        )\n",
        "\n",
        "        strategy_bank = [\n",
        "            \"Trace the expected behavior from docs/comments and implement the minimal fix.\",\n",
        "            \"Look for edge-case handling (None, empty, off-by-one) and patch minimally.\",\n",
        "            \"Search for the function mentioned in the problem; fix logic without refactoring.\",\n",
        "            \"Focus on correctness first; keep diff minimal and local.\",\n",
        "        ]\n",
        "\n",
        "        total_tokens = 0\n",
        "        attempts_made = 0\n",
        "\n",
        "        best_patch = None\n",
        "        best_apply_msg = \"\"\n",
        "        first_apply_index = None\n",
        "\n",
        "        for i in range(n):\n",
        "            # diversity: temps + optional strategy hints for larger N\n",
        "            if n >= 8:\n",
        "                hint = strategy_bank[i % len(strategy_bank)]\n",
        "                temp = 0.2 if i == 0 else (0.6 if i % 2 == 0 else 0.85)\n",
        "            else:\n",
        "                hint = None\n",
        "                temp = 0.3 if i == 0 else 0.7\n",
        "\n",
        "            patch, toks = self.generate_solution_for_target(\n",
        "                problem_statement=problem_statement,\n",
        "                target_file=target_file,\n",
        "                file_context=file_context,\n",
        "                max_completion_tokens=4096,\n",
        "                temperature=temp,\n",
        "                strategy_hint=hint,\n",
        "            )\n",
        "\n",
        "            total_tokens += toks\n",
        "            attempts_made += 1\n",
        "\n",
        "            # enforce single-file diff\n",
        "            if not patch:\n",
        "                continue\n",
        "            if self._patch_file_count(patch) != 1:\n",
        "                continue\n",
        "            files = self._extract_patch_files(patch)\n",
        "            if not files or files[0] != target_file:\n",
        "                continue\n",
        "\n",
        "            ok, msg = self._git_apply_check(repo_path, patch)\n",
        "\n",
        "            if ok:\n",
        "                # keep the first apply-able patch\n",
        "                if best_patch is None:\n",
        "                    best_patch = patch\n",
        "                    best_apply_msg = msg\n",
        "                    first_apply_index = i\n",
        "                    print(\"    ✓ Patch applies cleanly\")\n",
        "\n",
        "                # Adaptive: stop early; Fixed: keep going if stop_early=False\n",
        "                if stop_early:\n",
        "                    break\n",
        "            else:\n",
        "                best_apply_msg = msg  # keep last error for debugging\n",
        "\n",
        "        patch_applied = bool(best_patch)\n",
        "        return {\n",
        "            \"patch\": best_patch or \"\",\n",
        "            \"tokens_used\": total_tokens,\n",
        "            \"n_samples\": n,\n",
        "            \"attempts_made\": attempts_made,\n",
        "            \"first_apply_index\": first_apply_index,\n",
        "            \"predicted_tokens\": predicted,\n",
        "            \"patch_applied\": patch_applied,\n",
        "            \"test_passed\": patch_applied,   # alias for your older Cell 13\n",
        "            \"success\": patch_applied,       # compatibility\n",
        "            \"target_file\": target_file,\n",
        "            \"apply_stderr\": best_apply_msg[:800],\n",
        "        }\n",
        "\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"LOADING GROUNDED ADAPTIVE AGENT\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "complexity_model = joblib.load(f\"{PROJECT_DIR}/models/complexity_predictor.pkl\")\n",
        "feature_scaler = joblib.load(f\"{PROJECT_DIR}/models/feature_scaler.pkl\")\n",
        "feature_names = joblib.load(f\"{PROJECT_DIR}/models/feature_names.pkl\")\n",
        "\n",
        "adaptive_agent = AdaptiveAgentGrounded(\n",
        "    client,\n",
        "    complexity_model,\n",
        "    feature_scaler,\n",
        "    feature_names\n",
        ")\n",
        "\n",
        "print(\"✓ Grounded adaptive agent ready\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# CELL 12.5: Fixed Best-of-10 Agent (GROUNDED)\n",
        "# - Reuses adaptive_agent.solve_with_feedback(..., force_n=10)\n",
        "# - IMPORTANT: stop_early=False so it ALWAYS runs all 10 attempts\n",
        "# =============================================================================\n",
        "\n",
        "class FixedBestOf10Agent:\n",
        "    def __init__(self, grounded_agent, n: int = 10):\n",
        "        self.base = grounded_agent\n",
        "        self.n = int(n)\n",
        "\n",
        "    def solve_fixed_10(self, task: dict, repo_path: str, all_tasks: list):\n",
        "        return self.base.solve_with_feedback(\n",
        "            task, repo_path, all_tasks,\n",
        "            force_n=self.n,\n",
        "            stop_early=False\n",
        "        )\n",
        "\n",
        "fixed10_agent = FixedBestOf10Agent(adaptive_agent, n=10)\n",
        "print(\"✓ Fixed Best-of-10 agent ready (grounded, no early stop)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OHOjjWj26osY",
        "outputId": "8accad4c-7815-4516-d21f-e68a0da8fc5a"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Fixed Best-of-10 agent ready (grounded, no early stop)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oKYfq-QzNWYy",
        "outputId": "a62c7644-d6d9-48e3-fa60-5f447a540d03"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "BASELINE vs ADAPTIVE vs FIXED-10 EVALUATION\n",
            "============================================================\n",
            "Running on 5 tasks\n",
            "============================================================\n",
            "\n",
            "\n",
            "[1/5] django__django-15213\n",
            "Repo: django/django\n",
            "  Cloning django/django ...\n",
            "  ✓ Ready at commit 03cadb91\n",
            "  target_file: django/db/models/fields/__init__.py\n",
            "  Predicted: 3000 tokens → N=3\n",
            "    ✓ Patch applies cleanly\n",
            "  target_file: django/db/models/fields/__init__.py\n",
            "  Predicted: 3000 tokens → N=10 (forced) (no-early-stop)\n",
            "    ✓ Patch applies cleanly\n",
            "  Baseline: tokens=7563 applied=True\n",
            "  Adaptive: N=3 tokens=7104 applied=True\n",
            "  Fixed-10: N=10 tokens=71803 applied=True\n",
            "\n",
            "[2/5] django__django-11630\n",
            "Repo: django/django\n",
            "  Cloning django/django ...\n",
            "  ✓ Ready at commit 65e86948\n",
            "  target_file: django/core/checks/model_checks.py\n",
            "  Predicted: 3000 tokens → N=3\n",
            "    ✓ Patch applies cleanly\n",
            "  target_file: django/core/checks/model_checks.py\n",
            "  Predicted: 3000 tokens → N=10 (forced) (no-early-stop)\n",
            "    ✓ Patch applies cleanly\n",
            "  Baseline: tokens=3269 applied=False\n",
            "  Adaptive: N=3 tokens=2770 applied=True\n",
            "  Fixed-10: N=10 tokens=24477 applied=True\n",
            "\n",
            "[3/5] django__django-11019\n",
            "Repo: django/django\n",
            "  Cloning django/django ...\n",
            "  ✓ Ready at commit 93e892bb\n",
            "  target_file: django/forms/widgets.py\n",
            "  Predicted: 3000 tokens → N=3\n",
            "    ✓ Patch applies cleanly\n",
            "  target_file: django/forms/widgets.py\n",
            "  Predicted: 3000 tokens → N=10 (forced) (no-early-stop)\n",
            "    ✓ Patch applies cleanly\n",
            "  Baseline: tokens=5221 applied=True\n",
            "  Adaptive: N=3 tokens=6820 applied=True\n",
            "  Fixed-10: N=10 tokens=33293 applied=True\n",
            "\n",
            "[4/5] django__django-15819\n",
            "Repo: django/django\n",
            "  Cloning django/django ...\n",
            "  ✓ Ready at commit 877c800f\n",
            "  target_file: django/core/management/commands/inspectdb.py\n",
            "  Predicted: 3000 tokens → N=3\n",
            "    ✓ Patch applies cleanly\n",
            "  target_file: django/core/management/commands/inspectdb.py\n",
            "  Predicted: 3000 tokens → N=10 (forced) (no-early-stop)\n",
            "    ✓ Patch applies cleanly\n",
            "  Baseline: tokens=3443 applied=True\n",
            "  Adaptive: N=3 tokens=3031 applied=True\n",
            "  Fixed-10: N=10 tokens=29106 applied=True\n",
            "\n",
            "[5/5] django__django-12747\n",
            "Repo: django/django\n",
            "  Cloning django/django ...\n",
            "  ✓ Ready at commit c86201b6\n",
            "  target_file: django/db/models/deletion.py\n",
            "  Predicted: 3000 tokens → N=3\n",
            "    ✓ Patch applies cleanly\n",
            "  target_file: django/db/models/deletion.py\n",
            "  Predicted: 3000 tokens → N=10 (forced) (no-early-stop)\n",
            "  Baseline: tokens=3376 applied=False\n",
            "  Adaptive: N=3 tokens=6168 applied=True\n",
            "  Fixed-10: N=10 tokens=29903 applied=False\n",
            "\n",
            "============================================================\n",
            "SUMMARY (APPLY-CHECK)\n",
            "============================================================\n",
            "Apply rate:\n",
            "  Baseline: 60.0%\n",
            "  Adaptive: 100.0%\n",
            "  Fixed-10: 80.0%\n",
            "\n",
            "Avg tokens:\n",
            "  Baseline: 4574\n",
            "  Adaptive: 5179\n",
            "  Fixed-10: 37716\n",
            "\n",
            "✓ Saved: /content/drive/MyDrive/adaptive-swe-agent/results/baseline_vs_adaptive_vs_fixed10_5.csv\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# CELL 13: Baseline vs Adaptive vs Fixed-10 Comparison (APPLY-CHECK)\n",
        "# =============================================================================\n",
        "\n",
        "import time\n",
        "import pandas as pd\n",
        "import json\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"BASELINE vs ADAPTIVE vs FIXED-10 EVALUATION\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "with open(f\"{PROJECT_DIR}/data/swebench_subset_50.jsonl\") as f:\n",
        "    all_test_tasks = [json.loads(line) for line in f]\n",
        "\n",
        "with open(f\"{PROJECT_DIR}/data/swebench_lite.jsonl\") as f:\n",
        "    all_tasks = [json.loads(line) for line in f]\n",
        "\n",
        "test_tasks = all_test_tasks[:5]\n",
        "print(f\"Running on {len(test_tasks)} tasks\")\n",
        "print(\"=\"*60 + \"\\n\")\n",
        "\n",
        "rows = []\n",
        "\n",
        "for i, task in enumerate(test_tasks):\n",
        "    print(f\"\\n[{i+1}/{len(test_tasks)}] {task['instance_id']}\")\n",
        "    print(f\"Repo: {task['repo']}\")\n",
        "\n",
        "    repo_path = repo_mgr.setup_repository(task['repo'], task['base_commit'])\n",
        "    if not repo_path:\n",
        "        print(\"  ✗ Repo setup failed\")\n",
        "        continue\n",
        "\n",
        "    try:\n",
        "        # -------------------\n",
        "        # Baseline (your N=1 agent)\n",
        "        # -------------------\n",
        "        t0 = time.time()\n",
        "        base_res = agent.solve_issue(task, repo_path)\n",
        "        base_time = time.time() - t0\n",
        "\n",
        "        # Optional: apply-check baseline patch for apples-to-apples\n",
        "        base_applied = False\n",
        "        base_apply_msg = \"\"\n",
        "        if base_res.get(\"patch\"):\n",
        "            ok, msg = adaptive_agent._git_apply_check(repo_path, base_res[\"patch\"])\n",
        "            base_applied = ok\n",
        "            base_apply_msg = msg[:400]\n",
        "\n",
        "        subprocess.run(['git', 'reset', '--hard'], cwd=repo_path, capture_output=True, text=True)\n",
        "        subprocess.run(['git', 'clean', '-fd'], cwd=repo_path, capture_output=True, text=True)\n",
        "\n",
        "        # -------------------\n",
        "        # Adaptive (grounded)\n",
        "        # -------------------\n",
        "        t1 = time.time()\n",
        "        adap_res = adaptive_agent.solve_with_feedback(task, repo_path, all_tasks)\n",
        "        adap_time = time.time() - t1\n",
        "\n",
        "        subprocess.run(['git', 'reset', '--hard'], cwd=repo_path, capture_output=True, text=True)\n",
        "        subprocess.run(['git', 'clean', '-fd'], cwd=repo_path, capture_output=True, text=True)\n",
        "\n",
        "        # -------------------\n",
        "        # Fixed-10 (grounded)\n",
        "        # -------------------\n",
        "        t2 = time.time()\n",
        "        fixed_res = fixed10_agent.solve_fixed_10(task, repo_path, all_tasks)\n",
        "        fixed_time = time.time() - t2\n",
        "\n",
        "        # record\n",
        "        rows.append({\n",
        "            \"instance_id\": task[\"instance_id\"],\n",
        "            \"repo\": task[\"repo\"],\n",
        "\n",
        "            \"baseline_tokens\": base_res.get(\"tokens_used\", 0),\n",
        "            \"baseline_time\": base_time,\n",
        "            \"baseline_has_patch\": bool(base_res.get(\"patch\")),\n",
        "            \"baseline_patch_applied\": base_applied,\n",
        "            \"baseline_patch_len\": len(base_res.get(\"patch\") or \"\"),\n",
        "            \"baseline_patch\": base_res.get(\"patch\") or \"\",\n",
        "            \"baseline_apply_stderr\": base_apply_msg,\n",
        "\n",
        "            \"adaptive_tokens\": adap_res.get(\"tokens_used\", 0),\n",
        "            \"adaptive_time\": adap_time,\n",
        "            \"adaptive_n\": adap_res.get(\"n_samples\", 0),\n",
        "            \"adaptive_predicted_tokens\": adap_res.get(\"predicted_tokens\", None),\n",
        "            \"adaptive_has_patch\": bool(adap_res.get(\"patch\")),\n",
        "            \"adaptive_patch_applied\": bool(adap_res.get(\"patch_applied\")),\n",
        "            \"adaptive_patch_len\": len(adap_res.get(\"patch\") or \"\"),\n",
        "            \"adaptive_patch\": adap_res.get(\"patch\") or \"\",\n",
        "            \"adaptive_target_file\": adap_res.get(\"target_file\"),\n",
        "            \"adaptive_apply_stderr\": (adap_res.get(\"apply_stderr\") or \"\")[:400],\n",
        "\n",
        "            \"fixed10_tokens\": fixed_res.get(\"tokens_used\", 0),\n",
        "            \"fixed10_time\": fixed_time,\n",
        "            \"fixed10_n\": fixed_res.get(\"n_samples\", 10),\n",
        "            \"fixed10_has_patch\": bool(fixed_res.get(\"patch\")),\n",
        "            \"fixed10_patch_applied\": bool(fixed_res.get(\"patch_applied\")),\n",
        "            \"fixed10_patch_len\": len(fixed_res.get(\"patch\") or \"\"),\n",
        "            \"fixed10_patch\": fixed_res.get(\"patch\") or \"\",\n",
        "            \"fixed10_target_file\": fixed_res.get(\"target_file\"),\n",
        "            \"fixed10_apply_stderr\": (fixed_res.get(\"apply_stderr\") or \"\")[:400],\n",
        "        })\n",
        "\n",
        "        print(f\"  Baseline: tokens={base_res.get('tokens_used',0)} applied={base_applied}\")\n",
        "        print(f\"  Adaptive: N={adap_res.get('n_samples')} tokens={adap_res.get('tokens_used',0)} applied={adap_res.get('patch_applied',False)}\")\n",
        "        print(f\"  Fixed-10: N=10 tokens={fixed_res.get('tokens_used',0)} applied={fixed_res.get('patch_applied',False)}\")\n",
        "\n",
        "    finally:\n",
        "        repo_mgr.cleanup_repository(repo_path)\n",
        "\n",
        "df = pd.DataFrame(rows)\n",
        "out_csv = f\"{PROJECT_DIR}/results/baseline_vs_adaptive_vs_fixed10_5.csv\"\n",
        "df.to_csv(out_csv, index=False)\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"SUMMARY (APPLY-CHECK)\")\n",
        "print(\"=\"*60)\n",
        "if len(df):\n",
        "    print(\"Apply rate:\")\n",
        "    print(f\"  Baseline: {df['baseline_patch_applied'].mean():.1%}\")\n",
        "    print(f\"  Adaptive: {df['adaptive_patch_applied'].mean():.1%}\")\n",
        "    print(f\"  Fixed-10: {df['fixed10_patch_applied'].mean():.1%}\")\n",
        "    print(\"\\nAvg tokens:\")\n",
        "    print(f\"  Baseline: {df['baseline_tokens'].mean():.0f}\")\n",
        "    print(f\"  Adaptive: {df['adaptive_tokens'].mean():.0f}\")\n",
        "    print(f\"  Fixed-10: {df['fixed10_tokens'].mean():.0f}\")\n",
        "\n",
        "print(f\"\\n✓ Saved: {out_csv}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "KYwrcq9OGruP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25a3d782-d8c8-4032-fba7-3065203aa74f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded: /content/drive/MyDrive/adaptive-swe-agent/results/baseline_vs_adaptive_vs_fixed10_5.csv (5 rows)\n",
            "✓ Wrote: /content/drive/MyDrive/adaptive-swe-agent/predictions/baseline_subset_5_from_comparison.jsonl (patch_col=baseline_patch)\n",
            "✓ Wrote: /content/drive/MyDrive/adaptive-swe-agent/predictions/adaptive_subset_5.jsonl (patch_col=adaptive_patch)\n",
            "✓ Wrote: /content/drive/MyDrive/adaptive-swe-agent/predictions/fixed10_subset_5.jsonl (patch_col=fixed10_patch)\n",
            "\n",
            "✓ Export complete.\n",
            "  Format: {instance_id, model_patch, model_name_or_path}\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# CELL 14: Export Prediction JSONLs (Baseline + Adaptive + Fixed-10) from Cell 13 CSV\n",
        "# - Reads: results/baseline_vs_adaptive_vs_fixed10_5.csv\n",
        "# - Writes:\n",
        "#   predictions/baseline_subset_5_from_comparison.jsonl\n",
        "#   predictions/adaptive_subset_5.jsonl\n",
        "#   predictions/fixed10_subset_5.jsonl\n",
        "# =============================================================================\n",
        "\n",
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "comparison_csv = f\"{PROJECT_DIR}/results/baseline_vs_adaptive_vs_fixed10_5.csv\"\n",
        "assert os.path.exists(comparison_csv), f\"Missing: {comparison_csv} (run Cell 13 first)\"\n",
        "\n",
        "df = pd.read_csv(comparison_csv)\n",
        "print(f\"Loaded: {comparison_csv} ({len(df)} rows)\")\n",
        "\n",
        "os.makedirs(f\"{PROJECT_DIR}/predictions\", exist_ok=True)\n",
        "\n",
        "def _safe_patch(val) -> str:\n",
        "    if val is None:\n",
        "        return \"\"\n",
        "    if isinstance(val, float) and np.isnan(val):\n",
        "        return \"\"\n",
        "    s = str(val)\n",
        "    return s if s.lower() != \"nan\" else \"\"\n",
        "\n",
        "def export_jsonl(out_path: str, patch_col: str, model_name: str):\n",
        "    with open(out_path, \"w\") as f:\n",
        "        for _, row in df.iterrows():\n",
        "            patch = _safe_patch(row.get(patch_col, \"\"))\n",
        "            obj = {\n",
        "                \"instance_id\": row[\"instance_id\"],\n",
        "                \"model_patch\": patch,\n",
        "                \"model_name_or_path\": model_name,\n",
        "            }\n",
        "            f.write(json.dumps(obj) + \"\\n\")\n",
        "    print(f\"✓ Wrote: {out_path} (patch_col={patch_col})\")\n",
        "\n",
        "baseline_out = f\"{PROJECT_DIR}/predictions/baseline_subset_5_from_comparison.jsonl\"\n",
        "adaptive_out = f\"{PROJECT_DIR}/predictions/adaptive_subset_5.jsonl\"\n",
        "fixed10_out  = f\"{PROJECT_DIR}/predictions/fixed10_subset_5.jsonl\"\n",
        "\n",
        "export_jsonl(baseline_out, \"baseline_patch\", \"baseline_gpt5_1_grounded\")\n",
        "export_jsonl(adaptive_out, \"adaptive_patch\", \"adaptive_gpt5_1_bestofN\")\n",
        "export_jsonl(fixed10_out,  \"fixed10_patch\",  \"fixed10_gpt5_1_bestof10\")\n",
        "\n",
        "print(\"\\n✓ Export complete.\")\n",
        "print(\"  Format: {instance_id, model_patch, model_name_or_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# CELL 14.1: Quick Sanity Check JSONL (preview)\n",
        "# =============================================================================\n",
        "\n",
        "import json\n",
        "\n",
        "preview_path = f\"{PROJECT_DIR}/predictions/adaptive_subset_5.jsonl\"  # change if you want\n",
        "assert os.path.exists(preview_path), f\"Missing: {preview_path}\"\n",
        "\n",
        "with open(preview_path) as f:\n",
        "    first = json.loads(next(f))\n",
        "\n",
        "print(\"instance_id:\", first.get(\"instance_id\"))\n",
        "print(\"model_name_or_path:\", first.get(\"model_name_or_path\"))\n",
        "print(\"\\nPatch preview:\\n\")\n",
        "print((first.get(\"model_patch\") or \"\")[:800])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jNb-3oaYhlpS",
        "outputId": "35e9a4b4-1485-46ba-97d7-1a8bbf262aa0"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "instance_id: django__django-15213\n",
            "model_name_or_path: adaptive_gpt5_1_bestofN\n",
            "\n",
            "Patch preview:\n",
            "\n",
            "diff --git a/django/db/models/fields/__init__.py b/django/db/models/fields/__init__.py\n",
            "index 4f8a3f1..7b9a4d2 100644\n",
            "--- a/django/db/models/fields/__init__.py\n",
            "+++ b/django/db/models/fields/__init__.py\n",
            "@@ -612,7 +612,10 @@ class Field(RegisterLookupMixin):\n",
            " \n",
            "     def get_prep_value(self, value):\n",
            "         \"\"\"Perform preliminary non-db specific value checks and conversions.\"\"\"\n",
            "-        if isinstance(value, Promise):\n",
            "+        if hasattr(value, 'resolve_expression'):\n",
            "+            # Resolve expressions (e.g. Q objects wrapped in ExpressionWrapper)\n",
            "+            # to allow proper boolean casting and SQL generation.\n",
            "+            value = value.resolve_expression(connection)\n",
            "+        if isinstance(value, Promise):\n",
            "             value = value._proxy____cast()\n",
            "         return value\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "qCN3KKlfOZN9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8797a5b-6f46-4e26-aeb8-98bebe5658d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "EXAMINING PATCHES: /content/drive/MyDrive/adaptive-swe-agent/predictions/adaptive_subset_5.jsonl\n",
            "============================================================\n",
            "\n",
            "============================================================\n",
            "[1/5] django__django-15213\n",
            "============================================================\n",
            "Patch length: 779 chars\n",
            "\n",
            "First 500 chars:\n",
            "diff --git a/django/db/models/fields/__init__.py b/django/db/models/fields/__init__.py\n",
            "index 4f8a3f1..7b9a4d2 100644\n",
            "--- a/django/db/models/fields/__init__.py\n",
            "+++ b/django/db/models/fields/__init__.py\n",
            "@@ -612,7 +612,10 @@ class Field(RegisterLookupMixin):\n",
            " \n",
            "     def get_prep_value(self, value):\n",
            "         \"\"\"Perform preliminary non-db specific value checks and conversions.\"\"\"\n",
            "-        if isinstance(value, Promise):\n",
            "+        if hasattr(value, 'resolve_expression'):\n",
            "+            # Resolve expression\n",
            "\n",
            "... (truncated)\n",
            "\n",
            "✓ Patch looks like a valid unified diff (format-wise)\n",
            "\n",
            "============================================================\n",
            "[2/5] django__django-11630\n",
            "============================================================\n",
            "Patch length: 3270 chars\n",
            "\n",
            "First 500 chars:\n",
            "diff --git a/django/core/checks/model_checks.py b/django/core/checks/model_checks.py\n",
            "index 1111111..2222222 100644\n",
            "--- a/django/core/checks/model_checks.py\n",
            "+++ b/django/core/checks/model_checks.py\n",
            "@@ -6,6 +6,7 @@ from itertools import chain\n",
            " \n",
            " from django.apps import apps\n",
            " from django.core.checks import Error, Tags, register\n",
            "+from django.db import connections\n",
            " \n",
            " \n",
            " @register(Tags.models)\n",
            "@@ -19,7 +20,16 @@ def check_all_models(app_configs=None, **kwargs):\n",
            "         models = apps.get_models()\n",
            "     \n",
            "\n",
            "... (truncated)\n",
            "\n",
            "✓ Patch looks like a valid unified diff (format-wise)\n",
            "\n",
            "============================================================\n",
            "[3/5] django__django-11019\n",
            "============================================================\n",
            "Patch length: 4391 chars\n",
            "\n",
            "First 500 chars:\n",
            "diff --git a/django/forms/widgets.py b/django/forms/widgets.py\n",
            "index 7b6a2f0..f1c5b4a 100644\n",
            "--- a/django/forms/widgets.py\n",
            "+++ b/django/forms/widgets.py\n",
            "@@ -68,32 +68,71 @@ class Media:\n",
            "             return Media(**{str(name): getattr(self, '_' + name)})\n",
            "         raise KeyError('Unknown media type \"%s\"' % name)\n",
            " \n",
            "-    @staticmethod\n",
            "-    def merge(list_1, list_2):\n",
            "+    @classmethod\n",
            "+    def merge(cls, list_1, list_2):\n",
            "         \"\"\"\n",
            "         Merge two lists while trying to keep the relative order of\n",
            "\n",
            "... (truncated)\n",
            "\n",
            "✓ Patch looks like a valid unified diff (format-wise)\n",
            "\n",
            "============================================================\n",
            "[4/5] django__django-15819\n",
            "============================================================\n",
            "Patch length: 3351 chars\n",
            "\n",
            "First 500 chars:\n",
            "diff --git a/django/core/management/commands/inspectdb.py b/django/core/management/commands/inspectdb.py\n",
            "index 4e5b0c1..aaaaaaaa 100644\n",
            "--- a/django/core/management/commands/inspectdb.py\n",
            "+++ b/django/core/management/commands/inspectdb.py\n",
            "@@ -130,6 +130,7 @@ class Command(BaseCommand):\n",
            "                 yield \"class %s(models.Model):\" % table2model(table_name)\n",
            "                 known_models.append(table2model(table_name))\n",
            "                 used_column_names = []  # Holds column names used in the tab\n",
            "\n",
            "... (truncated)\n",
            "\n",
            "✓ Patch looks like a valid unified diff (format-wise)\n",
            "\n",
            "============================================================\n",
            "[5/5] django__django-12747\n",
            "============================================================\n",
            "Patch length: 3524 chars\n",
            "\n",
            "First 500 chars:\n",
            "diff --git a/django/db/models/deletion.py b/django/db/models/deletion.py\n",
            "index 5f6b3a2c3b..3d2a4b7c8d 100644\n",
            "--- a/django/db/models/deletion.py\n",
            "+++ b/django/db/models/deletion.py\n",
            "@@ -1,4 +1,5 @@\n",
            " import operator\n",
            "+from collections import OrderedDict\n",
            " from collections import Counter, defaultdict\n",
            " from functools import partial, reduce\n",
            " from itertools import chain\n",
            "@@ -6,6 +7,7 @@ from operator import attrgetter\n",
            " \n",
            " from django.db import IntegrityError, connections, transaction\n",
            " from django.db.models \n",
            "\n",
            "... (truncated)\n",
            "\n",
            "✓ Patch looks like a valid unified diff (format-wise)\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# CELL 15: Examine Generated Patches (Baseline/Adaptive/Fixed-10)\n",
        "# - Reads a selected JSONL and prints basic patch quality checks.\n",
        "# =============================================================================\n",
        "\n",
        "import json\n",
        "import os\n",
        "\n",
        "PRED_PATH = f\"{PROJECT_DIR}/predictions/adaptive_subset_5.jsonl\"  # <- change to fixed10 or baseline\n",
        "assert os.path.exists(PRED_PATH), f\"Missing: {PRED_PATH}\"\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(f\"EXAMINING PATCHES: {PRED_PATH}\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "with open(PRED_PATH) as f:\n",
        "    preds = [json.loads(line) for line in f]\n",
        "\n",
        "for i, pred in enumerate(preds[:10]):\n",
        "    patch = pred.get(\"model_patch\", \"\") or \"\"\n",
        "    iid = pred.get(\"instance_id\")\n",
        "\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"[{i+1}/{min(len(preds),10)}] {iid}\")\n",
        "    print(f\"{'='*60}\")\n",
        "    print(f\"Patch length: {len(patch)} chars\")\n",
        "\n",
        "    print(\"\\nFirst 500 chars:\")\n",
        "    print(patch[:500])\n",
        "    print(\"\\n... (truncated)\")\n",
        "\n",
        "    issues = []\n",
        "    if not patch:\n",
        "        issues.append(\"❌ Empty patch\")\n",
        "    else:\n",
        "        if not patch.startswith(\"diff --git\"):\n",
        "            issues.append(\"❌ Doesn't start with 'diff --git'\")\n",
        "        if \"@@\" not in patch:\n",
        "            issues.append(\"❌ Missing hunk headers (@@)\")\n",
        "        # Ensure there are actual +/- changes excluding file headers\n",
        "        has_changes = any(\n",
        "            ln.startswith((\"+\", \"-\")) and not ln.startswith((\"+++\", \"---\"))\n",
        "            for ln in patch.splitlines()\n",
        "        )\n",
        "        if not has_changes:\n",
        "            issues.append(\"❌ No actual change lines (+/-)\")\n",
        "\n",
        "    if issues:\n",
        "        print(\"\\n⚠️ PATCH ISSUES:\")\n",
        "        for issue in issues:\n",
        "            print(\" \", issue)\n",
        "    else:\n",
        "        print(\"\\n✓ Patch looks like a valid unified diff (format-wise)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "BalGhutrSEzf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "413d9e05-3637-4b99-bb81-470d84cf794d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "PATCH VALIDATION REPORT (FORMAT ONLY): /content/drive/MyDrive/adaptive-swe-agent/predictions/adaptive_subset_5.jsonl\n",
            "============================================================\n",
            "\n",
            "✓ django__django-15213\n",
            "  Valid\n",
            "\n",
            "✓ django__django-11630\n",
            "  Valid\n",
            "\n",
            "✓ django__django-11019\n",
            "  Valid\n",
            "\n",
            "✓ django__django-15819\n",
            "  Valid\n",
            "\n",
            "✓ django__django-12747\n",
            "  Valid\n",
            "\n",
            "============================================================\n",
            "Valid patches: 5/5\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# CELL 16: Patch Validation Report (format-only)\n",
        "# - Validates that each patch looks like a unified diff.\n",
        "# =============================================================================\n",
        "\n",
        "import json\n",
        "import os\n",
        "\n",
        "PRED_PATH = f\"{PROJECT_DIR}/predictions/adaptive_subset_5.jsonl\"  # <- switch if desired\n",
        "assert os.path.exists(PRED_PATH), f\"Missing: {PRED_PATH}\"\n",
        "\n",
        "def validate_unified_diff(patch: str):\n",
        "    if not patch or len(patch) < 10:\n",
        "        return False, \"Empty or too short\"\n",
        "\n",
        "    lines = patch.splitlines()\n",
        "\n",
        "    # diff header should be at top for SWE-bench harness style\n",
        "    if not lines[0].startswith(\"diff --git\"):\n",
        "        return False, \"Missing 'diff --git' as first line\"\n",
        "\n",
        "    has_file_headers = any(l.startswith(\"--- \") for l in lines) and any(l.startswith(\"+++ \") for l in lines)\n",
        "    if not has_file_headers:\n",
        "        return False, \"Missing file headers (--- and +++)\"\n",
        "\n",
        "    has_hunks = any(l.startswith(\"@@\") for l in lines)\n",
        "    if not has_hunks:\n",
        "        return False, \"Missing hunk headers (@@)\"\n",
        "\n",
        "    has_changes = any(\n",
        "        (l.startswith(\"+\") or l.startswith(\"-\")) and not l.startswith((\"+++\", \"---\"))\n",
        "        for l in lines\n",
        "    )\n",
        "    if not has_changes:\n",
        "        return False, \"No actual changes (+/- lines)\"\n",
        "\n",
        "    return True, \"Valid\"\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(f\"PATCH VALIDATION REPORT (FORMAT ONLY): {PRED_PATH}\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "with open(PRED_PATH) as f:\n",
        "    preds = [json.loads(line) for line in f]\n",
        "\n",
        "valid_count = 0\n",
        "for pred in preds:\n",
        "    patch = pred.get(\"model_patch\", \"\") or \"\"\n",
        "    iid = pred.get(\"instance_id\", \"UNKNOWN\")\n",
        "    ok, reason = validate_unified_diff(patch)\n",
        "    print(f\"\\n{'✓' if ok else '✗'} {iid}\")\n",
        "    print(f\"  {reason}\")\n",
        "    if ok:\n",
        "        valid_count += 1\n",
        "    else:\n",
        "        first_line = patch.splitlines()[0] if patch else \"\"\n",
        "        print(f\"  Length: {len(patch)} chars\")\n",
        "        print(f\"  First line: {first_line[:120]}\")\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(f\"Valid patches: {valid_count}/{len(preds)}\")\n",
        "print(f\"{'='*60}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fXi8_RogUtez",
        "outputId": "d79d1848-3a00-4583-ab82-624b6bc6c421"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "DEEP PATCH APPLY ANALYSIS\n",
            "============================================================\n",
            "Predictions: /content/drive/MyDrive/adaptive-swe-agent/predictions/adaptive_subset_5.jsonl\n",
            "============================================================\n",
            "  Cloning django/django ...\n",
            "  ✓ Ready at commit 03cadb91\n",
            "\n",
            "django__django-15213: ✓ APPLIES\n",
            "  Repo: django/django\n",
            "  Target file: django/db/models/fields/__init__.py\n",
            "  Cloning django/django ...\n",
            "  ✓ Ready at commit 65e86948\n",
            "\n",
            "django__django-11630: ✓ APPLIES\n",
            "  Repo: django/django\n",
            "  Target file: django/core/checks/model_checks.py\n",
            "  Cloning django/django ...\n",
            "  ✓ Ready at commit 93e892bb\n",
            "\n",
            "django__django-11019: ✓ APPLIES\n",
            "  Repo: django/django\n",
            "  Target file: django/forms/widgets.py\n",
            "  Cloning django/django ...\n",
            "  ✓ Ready at commit 877c800f\n",
            "\n",
            "django__django-15819: ✓ APPLIES\n",
            "  Repo: django/django\n",
            "  Target file: django/core/management/commands/inspectdb.py\n",
            "  Cloning django/django ...\n",
            "  ✓ Ready at commit c86201b6\n",
            "\n",
            "django__django-12747: ✓ APPLIES\n",
            "  Repo: django/django\n",
            "  Target file: django/db/models/deletion.py\n",
            "\n",
            "✓ Deep analysis done.\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# CELL 17: Deep Patch Apply Analysis (uses repo_mgr, aligned with your pipeline)\n",
        "# - Analyzes WHY a patch fails to apply via git apply --check --verbose --recount\n",
        "# =============================================================================\n",
        "\n",
        "import json\n",
        "import subprocess\n",
        "import tempfile\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "PRED_PATH = f\"{PROJECT_DIR}/predictions/adaptive_subset_5.jsonl\"  # <- choose adaptive/fixed10/baseline\n",
        "TASKS_PATH = f\"{PROJECT_DIR}/data/swebench_subset_50.jsonl\"       # contains the tasks\n",
        "N_ANALYZE = 2                                                     # analyze first N failures in detail\n",
        "\n",
        "assert os.path.exists(PRED_PATH), f\"Missing: {PRED_PATH}\"\n",
        "assert os.path.exists(TASKS_PATH), f\"Missing: {TASKS_PATH}\"\n",
        "\n",
        "with open(PRED_PATH) as f:\n",
        "    preds = [json.loads(line) for line in f]\n",
        "\n",
        "with open(TASKS_PATH) as f:\n",
        "    tasks = [json.loads(line) for line in f]\n",
        "\n",
        "task_lookup = {t[\"instance_id\"]: t for t in tasks}\n",
        "\n",
        "def git_apply_check_verbose(repo_path: str, patch: str):\n",
        "    with tempfile.NamedTemporaryFile(mode=\"w\", suffix=\".patch\", delete=False, encoding=\"utf-8\") as f:\n",
        "        f.write(patch)\n",
        "        patch_file = f.name\n",
        "    try:\n",
        "        cmd = [\"git\", \"apply\", \"--check\", \"--verbose\", \"--recount\", patch_file]\n",
        "        res = subprocess.run(cmd, cwd=repo_path, capture_output=True, text=True)\n",
        "        return res.returncode == 0, res.stdout, res.stderr\n",
        "    finally:\n",
        "        if os.path.exists(patch_file):\n",
        "            os.unlink(patch_file)\n",
        "\n",
        "def extract_target_file(patch: str):\n",
        "    import re\n",
        "    m = re.search(r\"diff --git a/(.+?) b/\", patch or \"\")\n",
        "    return m.group(1).strip() if m else None\n",
        "\n",
        "failures_analyzed = 0\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"DEEP PATCH APPLY ANALYSIS\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Predictions: {PRED_PATH}\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "for pred in preds:\n",
        "    iid = pred[\"instance_id\"]\n",
        "    patch = pred.get(\"model_patch\", \"\") or \"\"\n",
        "    task = task_lookup.get(iid)\n",
        "    if task is None:\n",
        "        print(f\"\\n{iid}: ⚠ Task not found in {TASKS_PATH}, skipping\")\n",
        "        continue\n",
        "\n",
        "    if not patch.strip():\n",
        "        print(f\"\\n{iid}: ✗ Empty patch (skip)\")\n",
        "        continue\n",
        "\n",
        "    repo_path = repo_mgr.setup_repository(task[\"repo\"], task[\"base_commit\"])\n",
        "    if not repo_path:\n",
        "        print(f\"\\n{iid}: ✗ Repo setup failed\")\n",
        "        continue\n",
        "\n",
        "    ok, out, err = git_apply_check_verbose(repo_path, patch)\n",
        "    target = extract_target_file(patch)\n",
        "\n",
        "    print(f\"\\n{iid}: {'✓ APPLIES' if ok else '✗ DOES NOT APPLY'}\")\n",
        "    print(f\"  Repo: {task['repo']}\")\n",
        "    print(f\"  Target file: {target}\")\n",
        "\n",
        "    if not ok:\n",
        "        print(\"\\n  --- git apply stderr (first 800 chars) ---\")\n",
        "        print((err or \"\")[:800])\n",
        "\n",
        "        # If file exists, show some quick context around first failure hunk header if possible\n",
        "        if target:\n",
        "            abs_path = os.path.join(repo_path, target)\n",
        "            if os.path.exists(abs_path):\n",
        "                try:\n",
        "                    with open(abs_path, \"r\", encoding=\"utf-8\", errors=\"replace\") as f:\n",
        "                        lines = f.readlines()\n",
        "                    print(f\"\\n  File exists: ✓ ({len(lines)} lines)\")\n",
        "                    print(f\"  First line: {lines[0].rstrip()[:120] if lines else '(empty)'}\")\n",
        "                except Exception as e:\n",
        "                    print(f\"\\n  Could not read target file for context: {e}\")\n",
        "            else:\n",
        "                print(\"\\n  File exists: ✗ (path not found on disk)\")\n",
        "\n",
        "        failures_analyzed += 1\n",
        "\n",
        "    repo_mgr.cleanup_repository(repo_path)\n",
        "\n",
        "    if failures_analyzed >= N_ANALYZE:\n",
        "        break\n",
        "\n",
        "print(\"\\n✓ Deep analysis done.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0nbQi1yjVIQ1",
        "outputId": "9932f354-79f4-4fed-a1c9-407f59f5d70a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "COMPREHENSIVE EVALUATION (ROBUST)\n",
            "============================================================\n",
            "Loaded: /content/drive/MyDrive/adaptive-swe-agent/results/baseline_vs_adaptive_vs_fixed10_5.csv (5 rows)\n",
            "\n",
            "Columns in CSV:\n",
            "['instance_id', 'repo', 'baseline_tokens', 'baseline_time', 'baseline_has_patch', 'baseline_patch_applied', 'baseline_patch_len', 'baseline_patch', 'baseline_apply_stderr', 'adaptive_tokens', 'adaptive_time', 'adaptive_n', 'adaptive_predicted_tokens', 'adaptive_has_patch', 'adaptive_patch_applied', 'adaptive_patch_len', 'adaptive_patch', 'adaptive_target_file', 'adaptive_apply_stderr', 'fixed10_tokens', 'fixed10_time', 'fixed10_n', 'fixed10_has_patch', 'fixed10_patch_applied', 'fixed10_patch_len', 'fixed10_patch', 'fixed10_target_file', 'fixed10_apply_stderr']\n",
            "\n",
            "============================================================\n",
            "METRIC 1: COMPUTE\n",
            "============================================================\n",
            "Baseline: {'avg_tokens': 4574.4, 'avg_duration': 10.06779613494873, 'apply_rate': 0.6, 'patch_rate': 1.0, 'cols_used': {'tokens': 'baseline_tokens', 'duration': 'baseline_time', 'applied': 'baseline_patch_applied', 'patch': 'baseline_patch'}}\n",
            "Adaptive: {'avg_tokens': 5178.6, 'avg_duration': 14.375833702087402, 'apply_rate': 1.0, 'patch_rate': 1.0, 'cols_used': {'tokens': 'adaptive_tokens', 'duration': 'adaptive_time', 'applied': 'adaptive_patch_applied', 'patch': 'adaptive_patch'}}\n",
            "Fixed-10: {'avg_tokens': 37716.4, 'avg_duration': 77.60569291114807, 'apply_rate': 0.8, 'patch_rate': 0.8, 'cols_used': {'tokens': 'fixed10_tokens', 'duration': 'fixed10_time', 'applied': 'fixed10_patch_applied', 'patch': 'fixed10_patch'}}\n",
            "\n",
            "============================================================\n",
            "METRIC 2: APPLY SUCCESS (proxy quality)\n",
            "============================================================\n",
            "Baseline apply_rate: 60.0%\n",
            "Adaptive apply_rate: 100.0%\n",
            "Fixed-10 apply_rate: 80.0%\n",
            "\n",
            "============================================================\n",
            "PER-TASK BREAKDOWN\n",
            "============================================================\n",
            "\n",
            "django__django-15213 (django/django):\n",
            "  Baseline: tokens=7563 duration=6.4s applied=True\n",
            "  Adaptive: tokens=7104 duration=2.9s N=3 predicted=3000 applied=True\n",
            "  Fixed10:  tokens=71803 duration=45.0s applied=True\n",
            "\n",
            "django__django-11630 (django/django):\n",
            "  Baseline: tokens=3269 duration=10.8s applied=False\n",
            "  Adaptive: tokens=2770 duration=8.4s N=3 predicted=3000 applied=True\n",
            "  Fixed10:  tokens=24477 duration=56.2s applied=True\n",
            "\n",
            "django__django-11019 (django/django):\n",
            "  Baseline: tokens=5221 duration=5.3s applied=True\n",
            "  Adaptive: tokens=6820 duration=26.8s N=3 predicted=3000 applied=True\n",
            "  Fixed10:  tokens=33293 duration=110.4s applied=True\n",
            "\n",
            "django__django-15819 (django/django):\n",
            "  Baseline: tokens=3443 duration=15.6s applied=True\n",
            "  Adaptive: tokens=3031 duration=8.7s N=3 predicted=3000 applied=True\n",
            "  Fixed10:  tokens=29106 duration=67.6s applied=True\n",
            "\n",
            "django__django-12747 (django/django):\n",
            "  Baseline: tokens=3376 duration=12.2s applied=False\n",
            "  Adaptive: tokens=6168 duration=25.1s N=3 predicted=3000 applied=True\n",
            "  Fixed10:  tokens=29903 duration=108.8s applied=False\n",
            "\n",
            "✓ Saved: /content/drive/MyDrive/adaptive-swe-agent/evaluation/comprehensive_results.json\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# CELL 18 (ROBUST): Comprehensive Evaluation (Baseline vs Adaptive vs Fixed-10)\n",
        "# - Reads: results/baseline_vs_adaptive_vs_fixed10_5.csv\n",
        "# - Saves: evaluation/comprehensive_results.json\n",
        "# - Robust to column-name differences (no KeyError)\n",
        "# =============================================================================\n",
        "\n",
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "comparison_csv = f\"{PROJECT_DIR}/results/baseline_vs_adaptive_vs_fixed10_5.csv\"\n",
        "assert os.path.exists(comparison_csv), f\"Missing: {comparison_csv} (run Cell 13 first)\"\n",
        "\n",
        "df = pd.read_csv(comparison_csv)\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"COMPREHENSIVE EVALUATION (ROBUST)\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Loaded: {comparison_csv} ({len(df)} rows)\")\n",
        "print(\"\\nColumns in CSV:\")\n",
        "print(list(df.columns))\n",
        "\n",
        "def pick_col(candidates, required=True):\n",
        "    \"\"\"Pick the first existing column from candidates.\"\"\"\n",
        "    for c in candidates:\n",
        "        if c in df.columns:\n",
        "            return c\n",
        "    if required:\n",
        "        raise KeyError(f\"None of these columns exist: {candidates}\\nAvailable: {list(df.columns)}\")\n",
        "    return None\n",
        "\n",
        "def to_bool_series(col):\n",
        "    if col is None:\n",
        "        return pd.Series([np.nan] * len(df))\n",
        "    s = df[col]\n",
        "    # Handles True/False, 0/1, \"true\"/\"false\"\n",
        "    if s.dtype == bool:\n",
        "        return s.astype(float)\n",
        "    if np.issubdtype(s.dtype, np.number):\n",
        "        return (s != 0).astype(float)\n",
        "    return s.astype(str).str.lower().isin([\"true\", \"1\", \"yes\", \"y\"]).astype(float)\n",
        "\n",
        "def patch_rate(col):\n",
        "    if col is None:\n",
        "        return float(\"nan\")\n",
        "    return float((df[col].fillna(\"\").astype(str).str.len() > 0).mean())\n",
        "\n",
        "# ---- Try to map your actual column names ----\n",
        "# Tokens\n",
        "baseline_tokens_col = pick_col([\"baseline_tokens\", \"baseline_tokens_used\", \"baseline_total_tokens\", \"baseline_tok\"])\n",
        "adaptive_tokens_col = pick_col([\"adaptive_tokens\", \"adaptive_tokens_used\", \"adaptive_total_tokens\", \"adaptive_tok\"])\n",
        "fixed10_tokens_col  = pick_col([\"fixed10_tokens\", \"fixed_10_tokens\", \"fixed_tokens\", \"fixed10_tokens_used\"])\n",
        "\n",
        "# Duration\n",
        "baseline_dur_col = pick_col([\"baseline_duration\", \"baseline_duration_s\", \"baseline_time\", \"baseline_time_s\", \"baseline_seconds\"], required=False)\n",
        "adaptive_dur_col = pick_col([\"adaptive_duration\", \"adaptive_duration_s\", \"adaptive_time\", \"adaptive_time_s\", \"adaptive_seconds\"], required=False)\n",
        "fixed10_dur_col  = pick_col([\"fixed10_duration\", \"fixed_10_duration\", \"fixed10_duration_s\", \"fixed10_time\", \"fixed10_time_s\"], required=False)\n",
        "\n",
        "# Patch applied / apply success\n",
        "baseline_applied_col = pick_col([\"baseline_patch_applied\", \"baseline_applied\", \"baseline_apply_ok\", \"baseline_success\"], required=False)\n",
        "adaptive_applied_col = pick_col([\"adaptive_patch_applied\", \"adaptive_applied\", \"adaptive_apply_ok\", \"adaptive_success\"], required=False)\n",
        "fixed10_applied_col  = pick_col([\"fixed10_patch_applied\", \"fixed10_applied\", \"fixed10_apply_ok\", \"fixed10_success\"], required=False)\n",
        "\n",
        "# Patch text\n",
        "baseline_patch_col = pick_col([\"baseline_patch\", \"baseline_model_patch\", \"baseline_patch_text\"], required=False)\n",
        "adaptive_patch_col = pick_col([\"adaptive_patch\", \"adaptive_model_patch\", \"model_patch\", \"adaptive_patch_text\"], required=False)\n",
        "fixed10_patch_col  = pick_col([\"fixed10_patch\", \"fixed_10_patch\", \"fixed10_model_patch\", \"fixed10_patch_text\"], required=False)\n",
        "\n",
        "# N samples + predicted tokens (optional)\n",
        "adaptive_n_col = pick_col([\"adaptive_n_samples\", \"n_samples\", \"adaptive_n\"], required=False)\n",
        "predicted_col  = pick_col([\"predicted_tokens\", \"adaptive_predicted_tokens\", \"pred_tokens\"], required=False)\n",
        "\n",
        "def summarize(name, tok_col, dur_col, applied_col, patch_col):\n",
        "    out = {\n",
        "        \"avg_tokens\": float(df[tok_col].mean()),\n",
        "        \"avg_duration\": float(df[dur_col].mean()) if dur_col else float(\"nan\"),\n",
        "        \"apply_rate\": float(to_bool_series(applied_col).mean()) if applied_col else float(\"nan\"),\n",
        "        \"patch_rate\": patch_rate(patch_col),\n",
        "        \"cols_used\": {\n",
        "            \"tokens\": tok_col,\n",
        "            \"duration\": dur_col,\n",
        "            \"applied\": applied_col,\n",
        "            \"patch\": patch_col,\n",
        "        }\n",
        "    }\n",
        "    return out\n",
        "\n",
        "baseline = summarize(\"baseline\", baseline_tokens_col, baseline_dur_col, baseline_applied_col, baseline_patch_col)\n",
        "adaptive = summarize(\"adaptive\", adaptive_tokens_col, adaptive_dur_col, adaptive_applied_col, adaptive_patch_col)\n",
        "fixed10  = summarize(\"fixed10\",  fixed10_tokens_col,  fixed10_dur_col,  fixed10_applied_col,  fixed10_patch_col)\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"METRIC 1: COMPUTE\")\n",
        "print(\"=\"*60)\n",
        "print(\"Baseline:\", baseline)\n",
        "print(\"Adaptive:\", adaptive)\n",
        "print(\"Fixed-10:\", fixed10)\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"METRIC 2: APPLY SUCCESS (proxy quality)\")\n",
        "print(\"=\"*60)\n",
        "if not np.isnan(baseline[\"apply_rate\"]):\n",
        "    print(f\"Baseline apply_rate: {baseline['apply_rate']*100:.1f}%\")\n",
        "else:\n",
        "    print(\"Baseline apply_rate: (no applied column found)\")\n",
        "if not np.isnan(adaptive[\"apply_rate\"]):\n",
        "    print(f\"Adaptive apply_rate: {adaptive['apply_rate']*100:.1f}%\")\n",
        "else:\n",
        "    print(\"Adaptive apply_rate: (no applied column found)\")\n",
        "if not np.isnan(fixed10[\"apply_rate\"]):\n",
        "    print(f\"Fixed-10 apply_rate: {fixed10['apply_rate']*100:.1f}%\")\n",
        "else:\n",
        "    print(\"Fixed-10 apply_rate: (no applied column found)\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"PER-TASK BREAKDOWN\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "for _, r in df.iterrows():\n",
        "    iid = r.get(\"instance_id\", \"(no instance_id)\")\n",
        "    repo = r.get(\"repo\", \"(no repo)\")\n",
        "    print(f\"\\n{iid} ({repo}):\")\n",
        "    print(f\"  Baseline: tokens={float(r[baseline_tokens_col]):.0f}\"\n",
        "          + (f\" duration={float(r[baseline_dur_col]):.1f}s\" if baseline_dur_col else \"\")\n",
        "          + (f\" applied={bool(r[baseline_applied_col])}\" if baseline_applied_col else \"\"))\n",
        "    print(f\"  Adaptive: tokens={float(r[adaptive_tokens_col]):.0f}\"\n",
        "          + (f\" duration={float(r[adaptive_dur_col]):.1f}s\" if adaptive_dur_col else \"\")\n",
        "          + (f\" N={int(r[adaptive_n_col])}\" if adaptive_n_col else \"\")\n",
        "          + (f\" predicted={float(r[predicted_col]):.0f}\" if predicted_col else \"\")\n",
        "          + (f\" applied={bool(r[adaptive_applied_col])}\" if adaptive_applied_col else \"\"))\n",
        "    print(f\"  Fixed10:  tokens={float(r[fixed10_tokens_col]):.0f}\"\n",
        "          + (f\" duration={float(r[fixed10_dur_col]):.1f}s\" if fixed10_dur_col else \"\")\n",
        "          + (f\" applied={bool(r[fixed10_applied_col])}\" if fixed10_applied_col else \"\"))\n",
        "\n",
        "results_summary = {\n",
        "    \"n_tasks\": int(len(df)),\n",
        "    \"baseline\": baseline,\n",
        "    \"adaptive\": adaptive,\n",
        "    \"fixed10\": fixed10,\n",
        "}\n",
        "\n",
        "os.makedirs(f\"{PROJECT_DIR}/evaluation\", exist_ok=True)\n",
        "out_path = f\"{PROJECT_DIR}/evaluation/comprehensive_results.json\"\n",
        "with open(out_path, \"w\") as f:\n",
        "    json.dump(results_summary, f, indent=2)\n",
        "\n",
        "print(f\"\\n✓ Saved: {out_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V2-G4DuI3BNx",
        "outputId": "7741d4c5-1273-44fe-bc52-83c5829f5513"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0plLKymDXvAD",
        "outputId": "7c46bb2f-71b4-4e6a-da7f-d081cd6200f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "VALIDATING BASELINE PATCH APPLICATION\n",
            "============================================================\n",
            "\n",
            "[1/10] django__django-15213:\n",
            "  Cloning django/django ...\n",
            "  ✓ Ready at commit 03cadb91\n",
            "  ✓ Patch applies cleanly\n",
            "\n",
            "[2/10] django__django-11630:\n",
            "  Cloning django/django ...\n",
            "  ✓ Ready at commit 65e86948\n",
            "  ✗ Patch fails: Checking patch django/db/models/base.py...\n",
            "error: while searching for:\n",
            "                                    base_parents[\n",
            "\n",
            "[3/10] django__django-11019:\n",
            "  Cloning django/django ...\n",
            "  ✓ Ready at commit 93e892bb\n",
            "  ✓ Patch applies cleanly\n",
            "\n",
            "[4/10] django__django-15819:\n",
            "  Cloning django/django ...\n",
            "  ✓ Ready at commit 877c800f\n",
            "  ✓ Patch applies cleanly\n",
            "\n",
            "[5/10] django__django-12747:\n",
            "  Cloning django/django ...\n",
            "  ✓ Ready at commit c86201b6\n",
            "  ✗ Patch fails: Checking patch django/db/models/query.py...\n",
            "Hunk #1 succeeded at 15 (offset -3 lines).\n",
            "error: while searching for:\n",
            "\n",
            "    \n",
            "\n",
            "[6/10] sympy__sympy-15678:\n",
            "  Cloning sympy/sympy ...\n",
            "  ✓ Ready at commit 31c68eef\n",
            "  ✓ Patch applies cleanly\n",
            "\n",
            "[7/10] sympy__sympy-15345:\n",
            "  Cloning sympy/sympy ...\n",
            "  ✓ Ready at commit 9ef28fba\n",
            "  ✗ Patch fails: Checking patch sympy/crypto/crypto.py...\n",
            "Hunk #1 succeeded at 18 (offset -1 lines).\n",
            "Hunk #2 succeeded at 26 (offset -1 l\n",
            "\n",
            "[8/10] sympy__sympy-13895:\n",
            "  Cloning sympy/sympy ...\n",
            "  ✓ Ready at commit 4da0b645\n",
            "  ✓ Patch applies cleanly\n",
            "\n",
            "[9/10] sympy__sympy-13471:\n",
            "  Cloning sympy/sympy ...\n",
            "  ✓ Ready at commit 3546ac7e\n",
            "  ✓ Patch applies cleanly\n",
            "\n",
            "[10/10] sympy__sympy-23117:\n",
            "  Cloning sympy/sympy ...\n",
            "  ✓ Ready at commit c5cef249\n",
            "  ✗ Patch fails: Checking patch sympy/core/sympify.py...\n",
            "Hunk #1 succeeded at 10 (offset -5 lines).\n",
            "Hunk #2 succeeded at 19 (offset -4 li\n",
            "\n",
            "============================================================\n",
            "VALIDATION SUMMARY\n",
            "============================================================\n",
            "\n",
            "Patches that apply: 6/10 (60%)\n",
            "\n",
            "Failure breakdown:\n",
            "reason\n",
            "success          6\n",
            "hunk_mismatch    2\n",
            "other_error      2\n",
            "Name: count, dtype: int64\n",
            "\n",
            "✓ Saved: /content/drive/MyDrive/adaptive-swe-agent/results/patch_validation.csv\n"
          ]
        }
      ],
      "source": [
        "# Cell 19: Patch Application Validation (ROBUST)\n",
        "import json\n",
        "import subprocess\n",
        "import tempfile\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"VALIDATING BASELINE PATCH APPLICATION\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "with open(f\"{PROJECT_DIR}/predictions/baseline_subset_50.jsonl\") as f:\n",
        "    all_preds = [json.loads(line) for line in f]\n",
        "\n",
        "with open(f\"{PROJECT_DIR}/data/swebench_subset_50.jsonl\") as f:\n",
        "    all_tasks = [json.loads(line) for line in f]\n",
        "\n",
        "task_lookup = {t['instance_id']: t for t in all_tasks}\n",
        "\n",
        "test_preds = all_preds[:10]\n",
        "apply_results = []\n",
        "\n",
        "for i, pred in enumerate(test_preds):\n",
        "    instance_id = pred['instance_id']\n",
        "    patch = pred.get('model_patch', '') or ''\n",
        "    task = task_lookup[instance_id]\n",
        "\n",
        "    print(f\"\\n[{i+1}/10] {instance_id}:\")\n",
        "\n",
        "    if not patch.strip():\n",
        "        print(\"  ✗ No patch generated\")\n",
        "        apply_results.append({'instance_id': instance_id, 'applies': False, 'reason': 'no_patch'})\n",
        "        continue\n",
        "\n",
        "    repo_path = repo_mgr.setup_repository(task['repo'], task['base_commit'])\n",
        "    if not repo_path:\n",
        "        print(\"  ✗ Repo setup failed\")\n",
        "        apply_results.append({'instance_id': instance_id, 'applies': False, 'reason': 'repo_fail'})\n",
        "        continue\n",
        "\n",
        "    with tempfile.NamedTemporaryFile(mode='w', suffix='.patch', delete=False, encoding='utf-8') as f:\n",
        "        f.write(patch)\n",
        "        patch_file = f.name\n",
        "\n",
        "    result = subprocess.run(\n",
        "        ['git', 'apply', '--check', '--verbose', '--recount', patch_file],\n",
        "        cwd=repo_path,\n",
        "        capture_output=True,\n",
        "        text=True\n",
        "    )\n",
        "\n",
        "    os.unlink(patch_file)\n",
        "\n",
        "    applies = (result.returncode == 0)\n",
        "\n",
        "    if applies:\n",
        "        print(\"  ✓ Patch applies cleanly\")\n",
        "        apply_results.append({'instance_id': instance_id, 'applies': True, 'reason': 'success'})\n",
        "    else:\n",
        "        error = (result.stderr or \"\")[:400]\n",
        "        print(f\"  ✗ Patch fails: {error[:120]}\")\n",
        "\n",
        "        if 'does not exist' in error:\n",
        "            reason = 'file_not_found'\n",
        "        elif 'patch failed' in error or 'does not apply' in error:\n",
        "            reason = 'hunk_mismatch'\n",
        "        elif 'corrupt' in error:\n",
        "            reason = 'corrupt_patch'\n",
        "        else:\n",
        "            reason = 'other_error'\n",
        "\n",
        "        apply_results.append({'instance_id': instance_id, 'applies': False, 'reason': reason, 'stderr': error})\n",
        "\n",
        "    repo_mgr.cleanup_repository(repo_path)\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"VALIDATION SUMMARY\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "df_apply = pd.DataFrame(apply_results)\n",
        "applies_count = int(df_apply['applies'].sum())\n",
        "total = len(df_apply)\n",
        "\n",
        "print(f\"\\nPatches that apply: {applies_count}/{total} ({(applies_count/total*100 if total else 0):.0f}%)\")\n",
        "print(\"\\nFailure breakdown:\")\n",
        "print(df_apply['reason'].value_counts())\n",
        "\n",
        "out_csv = f\"{PROJECT_DIR}/results/patch_validation.csv\"\n",
        "df_apply.to_csv(out_csv, index=False)\n",
        "print(f\"\\n✓ Saved: {out_csv}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ctZQqAfO_jsb",
        "outputId": "7cf87e61-de28-47c1-ce21-fdd74004162e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "Inspecting: django__django-15213\n",
            "============================================================\n",
            "Patch length: 2116 chars\n",
            "\n",
            "Full patch:\n",
            "diff --git a/django/contrib/admin/static/admin/js/vendor/xregexp/xregexp.js b/django/contrib/admin/static/admin/js/vendor/xregexp/xregexp.js\n",
            "index 5b6a3a1..f3f9c3b 100644\n",
            "--- a/django/contrib/admin/static/admin/js/vendor/xregexp/xregexp.js\n",
            "+++ b/django/contrib/admin/static/admin/js/vendor/xregexp/xregexp.js\n",
            "@@ -1,4 +1,4 @@\n",
            "-(function(f){if(typeof exports===\"object\"&&typeof module!==\"undefined\"){module.exports=f()}else if(typeof define===\"function\"&&define.amd){define([],f)}else{var g;if(typeof window!==\"undefined\"){g=window}else if(typeof global!==\"undefined\"){g=global}else if(typeof self!==\"undefined\"){g=self}else{g=this}g.XRegExp = f()}})(function(){var define,module,exports;return (function e(t,n,r){function s(o,u){if(!n[o]){if(!t[o]){var a=typeof require==\"function\"&&require;if(!u&&a)return a(o,!0);if(i)return i(o,!0);var f=new Error(\"Cannot find module '\"+o+\"'\");throw f.code=\"MODULE_NOT_FOUND\",f}var l=n[o]={exports:{}};t[o][0].call(l.exports,function(e){var n=t[o][1][e];return s(n?n:e)},l,l.exports,e,t,n,r)}return n[o].exports}var i=typeof require==\"function\"&&require;for(var o=0;o<r.length;o++)s(r[o]);return s})({1:[function(require,module,exports){\n",
            "+(function(f){if(typeof exports===\"object\"&&typeof module!==\"undefined\"){module.exports=f()}else if(typeof define===\"function\"&&define.amd){define([],f)}else{var g;if(typeof window!==\"undefined\"){g=window}else if(typeof global!==\"undefined\"){g=global}else if(typeof self!==\"undefined\"){g=self}else{g=this}g.XRegExp = f()}})(function(){var define,module,exports;return (function e(t,n,r){function s(o,u){if(!n[o]){if(!t[o]){var a=typeof require==\"function\"&&require;if(!u&&a)return a(o,!0);if(i)return i(o,!0);var f=new Error(\"Cannot find module '\"+o+\"'\");throw f.code=\"MODULE_NOT_FOUND\",f}var l=n[o]={exports:{}};t[o][0].call(l.exports,function(e){var n=t[o][1][e];return s(n?n:e)},l,l.exports,e,t,n,r)}return n[o].exports}var i=typeof require==\"function\"&&require;for(var o=0;o<r.length;o++)s(r[o]);return s})({1:[function(require,module,exports){\n",
            " /*!\n",
            "  * XRegExp.build 3.2.0\n",
            "  * <xregexp.com>\n",
            "  * Steven Levithan (c) 2012-2017 MIT License\n",
            "\n",
            "\n",
            "============================================================\n",
            "\n",
            "DIAGNOSTICS:\n",
            "  Starts with 'diff --git': True\n",
            "  Contains '---': True\n",
            "  Contains '+++': True\n",
            "  Contains '@@': True\n",
            "  Line count: 12\n",
            "\n",
            "Line endings:\n",
            "  CRLF (\\r\\n): False\n",
            "  LF (\\n): True\n"
          ]
        }
      ],
      "source": [
        "# Cell 19.5: Deep Patch Inspection\n",
        "import json\n",
        "\n",
        "with open(f\"{PROJECT_DIR}/predictions/baseline_subset_50.jsonl\") as f:\n",
        "    all_preds = [json.loads(line) for line in f]\n",
        "\n",
        "# Check first patch in detail\n",
        "pred = all_preds[0]  # django__django-15213\n",
        "patch = pred['model_patch']\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(f\"Inspecting: {pred['instance_id']}\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Patch length: {len(patch)} chars\")\n",
        "print(f\"\\nFull patch:\")\n",
        "print(patch)\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "\n",
        "# Check for common issues\n",
        "print(\"\\nDIAGNOSTICS:\")\n",
        "print(f\"  Starts with 'diff --git': {patch.startswith('diff --git')}\")\n",
        "print(f\"  Contains '---': {'---' in patch}\")\n",
        "print(f\"  Contains '+++': {'+++' in patch}\")\n",
        "print(f\"  Contains '@@': {'@@' in patch}\")\n",
        "print(f\"  Line count: {len(patch.split(chr(10)))}\")\n",
        "\n",
        "# Check line endings\n",
        "print(f\"\\nLine endings:\")\n",
        "has_crlf = '\\r\\n' in patch\n",
        "has_lf = '\\n' in patch and not has_crlf\n",
        "print(f\"  CRLF (\\\\r\\\\n): {has_crlf}\")\n",
        "print(f\"  LF (\\\\n): {has_lf}\")\n",
        "\n",
        "# Check for weird characters\n",
        "import re\n",
        "weird_chars = re.findall(r'[^\\x20-\\x7E\\n\\t]', patch)\n",
        "if weird_chars:\n",
        "    print(f\"\\n⚠ Found {len(weird_chars)} non-ASCII characters:\")\n",
        "    print(f\"  {set(weird_chars)}\")\n",
        "\n",
        "# Show lines around \"line 27\" where corruption happens\n",
        "lines = patch.split('\\n')\n",
        "if len(lines) >= 27:\n",
        "    print(f\"\\nLines 25-29 (corruption at line 27):\")\n",
        "    for i in range(24, min(29, len(lines))):\n",
        "        print(f\"  {i+1}: {repr(lines[i])}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "04025ac3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fcc6a372-0f17-4402-9e49-018d80da6370"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 10 tasks (first 10) from: /content/drive/MyDrive/adaptive-swe-agent/data/swebench_subset_50.jsonl\n",
            "Loaded 300 tasks from: /content/drive/MyDrive/adaptive-swe-agent/data/swebench_lite.jsonl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rAdaptive solve (10):   0%|          | 0/10 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Cloning django/django ...\n",
            "  ✓ Ready at commit 03cadb91\n",
            "  target_file: django/db/models/fields/__init__.py\n",
            "  Predicted: 3000 tokens → N=3\n",
            "    ✓ Patch applies cleanly\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rAdaptive solve (10):  10%|█         | 1/10 [00:23<03:30, 23.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Cloning django/django ...\n",
            "  ✓ Ready at commit 65e86948\n",
            "  target_file: django/core/checks/model_checks.py\n",
            "  Predicted: 3000 tokens → N=3\n",
            "    ✓ Patch applies cleanly\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rAdaptive solve (10):  20%|██        | 2/10 [01:00<04:11, 31.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Cloning django/django ...\n",
            "  ✓ Ready at commit 93e892bb\n",
            "  target_file: django/forms/widgets.py\n",
            "  Predicted: 3000 tokens → N=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rAdaptive solve (10):  30%|███       | 3/10 [01:55<04:55, 42.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Cloning django/django ...\n",
            "  ✓ Ready at commit 877c800f\n",
            "  target_file: django/core/management/commands/inspectdb.py\n",
            "  Predicted: 3000 tokens → N=3\n",
            "    ✓ Patch applies cleanly\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rAdaptive solve (10):  40%|████      | 4/10 [02:29<03:54, 39.10s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Cloning django/django ...\n",
            "  ✓ Ready at commit c86201b6\n",
            "  target_file: django/db/models/deletion.py\n",
            "  Predicted: 3000 tokens → N=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rAdaptive solve (10):  50%|█████     | 5/10 [03:20<03:36, 43.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Cloning sympy/sympy ...\n",
            "  ✓ Ready at commit 31c68eef\n",
            "  target_file: sympy/geometry/util.py\n",
            "  Predicted: 3000 tokens → N=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rAdaptive solve (10):  60%|██████    | 6/10 [03:41<02:23, 35.83s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    ✓ Patch applies cleanly\n",
            "  Cloning sympy/sympy ...\n",
            "  ✓ Ready at commit 9ef28fba\n",
            "  target_file: sympy/printing/mathematica.py\n",
            "  Predicted: 3000 tokens → N=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rAdaptive solve (10):  70%|███████   | 7/10 [03:58<01:28, 29.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    ✓ Patch applies cleanly\n",
            "  Cloning sympy/sympy ...\n",
            "  ✓ Ready at commit 4da0b645\n",
            "  target_file: sympy/core/numbers.py\n",
            "  Predicted: 3000 tokens → N=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rAdaptive solve (10):  80%|████████  | 8/10 [04:28<00:59, 29.67s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    ✓ Patch applies cleanly\n",
            "  Cloning sympy/sympy ...\n",
            "  ✓ Ready at commit 3546ac7e\n",
            "  target_file: sympy/core/numbers.py\n",
            "  Predicted: 3000 tokens → N=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rAdaptive solve (10):  90%|█████████ | 9/10 [04:46<00:26, 26.04s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    ✓ Patch applies cleanly\n",
            "  Cloning sympy/sympy ...\n",
            "  ✓ Ready at commit c5cef249\n",
            "  target_file: sympy/tensor/array/ndim_array.py\n",
            "  Predicted: 3000 tokens → N=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Adaptive solve (10): 100%|██████████| 10/10 [05:09<00:00, 30.96s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    ✓ Patch applies cleanly\n",
            "\n",
            "✓ Wrote predictions JSONL: /content/drive/MyDrive/adaptive-swe-agent/predictions/adaptive_predictions_10.jsonl\n",
            "Elapsed: 309.6s\n",
            "Non-empty patches: 8/10 (80.0%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# FINAL (10 TASKS): Generate harness-ready predictions JSONL (Adaptive, GROUNDED) — ROBUST\n",
        "# =============================================================================\n",
        "\n",
        "import json, time, os\n",
        "from tqdm import tqdm\n",
        "\n",
        "DATASET_JSONL = os.path.join(DATA_DIR, \"swebench_subset_50.jsonl\")   # source file with >=10 tasks\n",
        "OUT_JSONL     = ADAPTIVE_PRED_10_JSONL\n",
        "LITE_JSONL    = os.path.join(DATA_DIR, \"swebench_lite.jsonl\")\n",
        "\n",
        "with open(DATASET_JSONL, encoding=\"utf-8\") as f:\n",
        "    tasks = [json.loads(line) for line in f][:10]\n",
        "\n",
        "with open(LITE_JSONL, encoding=\"utf-8\") as f:\n",
        "    all_tasks = [json.loads(line) for line in f]\n",
        "\n",
        "print(f\"Loaded {len(tasks)} tasks (first 10) from: {DATASET_JSONL}\")\n",
        "print(f\"Loaded {len(all_tasks)} tasks from: {LITE_JSONL}\")\n",
        "\n",
        "preds = []\n",
        "t0 = time.time()\n",
        "\n",
        "for task in tqdm(tasks, desc=\"Adaptive solve (10)\"):\n",
        "    repo_path = repo_mgr.setup_repository(task[\"repo\"], task[\"base_commit\"])\n",
        "    try:\n",
        "        if not repo_path:\n",
        "            raise RuntimeError(\"repo setup failed\")\n",
        "\n",
        "        result = adaptive_agent.solve_with_feedback(\n",
        "            task=task,\n",
        "            repo_path=repo_path,\n",
        "            all_tasks=all_tasks\n",
        "        )\n",
        "\n",
        "        patch = (result.get(\"patch\", \"\") or \"\")\n",
        "        preds.append({\n",
        "            \"instance_id\": task[\"instance_id\"],\n",
        "            \"model_name_or_path\": \"adaptive_gpt5_1_bestofN_grounded_10\",\n",
        "            \"model_patch\": patch\n",
        "        })\n",
        "\n",
        "    except Exception as e:\n",
        "        preds.append({\n",
        "            \"instance_id\": task.get(\"instance_id\", \"\"),\n",
        "            \"model_name_or_path\": \"adaptive_gpt5_1_bestofN_grounded_10\",\n",
        "            \"model_patch\": \"\"\n",
        "        })\n",
        "        print(f\"\\n⚠ {task.get('instance_id')}: {type(e).__name__}: {str(e)[:200]}\")\n",
        "    finally:\n",
        "        if repo_path:\n",
        "            repo_mgr.cleanup_repository(repo_path)\n",
        "\n",
        "with open(OUT_JSONL, \"w\", encoding=\"utf-8\") as f:\n",
        "    for p in preds:\n",
        "        f.write(json.dumps(p) + \"\\n\")\n",
        "\n",
        "elapsed = time.time() - t0\n",
        "non_empty = sum(1 for p in preds if (p.get(\"model_patch\") or \"\").strip())\n",
        "\n",
        "print(f\"\\n✓ Wrote predictions JSONL: {OUT_JSONL}\")\n",
        "print(f\"Elapsed: {elapsed:.1f}s\")\n",
        "print(f\"Non-empty patches: {non_empty}/{len(preds)} ({non_empty/len(preds):.1%})\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "path = f\"{PROJECT_DIR}/predictions/adaptive_predictions_10.jsonl\"\n",
        "with open(path) as f:\n",
        "    x = json.loads(next(f))\n",
        "\n",
        "print(x.keys())\n",
        "print(type(x[\"instance_id\"]), type(x[\"model_patch\"]), type(x[\"model_name_or_path\"]))\n",
        "print(x[\"model_patch\"][:10])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dl5TCvB4pdid",
        "outputId": "6723d9d4-9953-4531-a70a-b02045fd4c60"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['instance_id', 'model_name_or_path', 'model_patch'])\n",
            "<class 'str'> <class 'str'> <class 'str'>\n",
            "diff --git\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------------------------------------------------------\n",
        "# Sanity check: non-empty patches + diff header correctness (ROBUST)\n",
        "# -----------------------------------------------------------------------------\n",
        "import json, os\n",
        "\n",
        "path = ADAPTIVE_PRED_10_JSONL\n",
        "assert os.path.exists(path), f\"Missing predictions file: {path}\"\n",
        "\n",
        "bad = 0\n",
        "nonempty = 0\n",
        "\n",
        "with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "    for i, line in enumerate(f):\n",
        "        obj = json.loads(line)\n",
        "        p = (obj.get(\"model_patch\") or \"\").strip()\n",
        "        if p:\n",
        "            nonempty += 1\n",
        "            if not p.startswith(\"diff --git\"):\n",
        "                bad += 1\n",
        "\n",
        "print(\"file:\", path)\n",
        "print(\"nonempty:\", nonempty)\n",
        "print(\"nonempty_not_starting_with_diff_git:\", bad)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dvxEwUfpqLu0",
        "outputId": "22841497-ee85-4d57-e0a9-ef2b72c578e0"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "file: /content/drive/MyDrive/adaptive-swe-agent/predictions/adaptive_predictions_10.jsonl\n",
            "nonempty: 8\n",
            "nonempty_not_starting_with_diff_git: 0\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}